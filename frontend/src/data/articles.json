[
  {
    "id": 25,
    "title": "Warning: Target URL returned error 403: Forbidden",
    "content": "Warning: Target URL returned error 403: Forbidden\nWarning: This page contains iframe that are currently hidden, consider enabling iframe processing.\nWarning: This page maybe requiring CAPTCHA, please make sure you are authorized to access this page.\n\nJust a moment...\n===============\n\ntowardsdatascience.com\n======================\n\nVerifying you are human. This may take a few seconds.\n\ntowardsdatascience.com needs to review the security of your connection before proceeding.\n\nVerification successful\n\nWaiting for towardsdatascience.com to respond...\n\nRay ID: `922ba20d7bebe82d`\n\nPerformance & security by [Cloudflare](https://www.cloudflare.com/?utm_source=challenge&utm_campaign=j)\n",
    "created_at": "2025-03-19T08:34:32Z",
    "updated_at": "2025-03-19T08:34:56Z",
    "labels": [],
    "url": "https://github.com/kaozb/ai-arctl/issues/25"
  },
  {
    "id": 24,
    "title": "Cline：最强开源AI编程智能体",
    "content": "\n\n引言\n--\n\n在当今快速发展的软件开发领域，提高编程效率和代码质量一直是开发者们追求的目标。随着人工智能技术的进步，各种智能编程助手应运而生。本文将为您介绍一款号称超越Cursor的开源VSCode编程插件——Cline（原名Claude Dev），它不仅能够执行复杂的软件开发任务，还能根据用户需求任意切换模型选项，俨然已成为开发者的得力助手。\n\nCline的主要功能和特点\n-------------\n\n![Image 3: Image](https://mmbiz.qpic.cn/mmbiz_svg/47CicbLQOxtXwniaGSxwgokib0cmFJTCZovLXsTAlNzBpkkAgpA6eHrMsJxhyd9bqFZy2ognpJR62Q4nJHaJOaVZK4rnKoREyIF/640?wx_fmt=svg&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)\n\nCline 功能概览\n\nCline作为VSCode的插件，为开发者提供了一系列强大的功能：\n\n1.  智能代码分析与生成\n    \n\n*   Cline能够分析项目的文件结构和源代码抽象语法树（AST）\n    \n*   通过正则表达式搜索和读取相关文件，快速了解现有项目\n    \n*   能够处理复杂的软件开发任务，逐步完成\n    \n\n3.  文件操作与错误处理\n    \n\n*   可以创建和编辑文件\n    \n*   实时监控linter/编译器错误\n    \n*   能够主动修复诸如缺少导入和语法错误等问题\n    \n\n5.  终端命令执行\n    \n\n*   直接在用户终端中执行命令并监控输出\n    \n*   能够对开发服务器问题等进行反应和处理\n    \n\n7.  网页开发辅助\n    \n\n*   可以在无头浏览器中启动网站\n    \n*   捕获屏幕截图和控制台日志\n    \n*   帮助修复运行时错误和视觉bug\n    \n\n9.  多模型支持\n    \n\n*   支持多种API提供商，如OpenRouter、Anthropic、OpenAI、Google Gemini等\n    \n*   可配置任何兼容OpenAI的API\n    \n*   支持通过Ollama使用本地模型\n    \n\n11.  成本追踪\n    \n\n*   跟踪整个任务循环和单个请求的总token数和API使用成本\n    \n*   让用户随时了解开支情况\n    \n\nCline的这些功能使其成为一个全面的编程助手，能够在项目开发的各个阶段为开发者提供支持。尤其是对OpenRouter的支持，对开发者是非常友好的。我在《[号称LLM统一接口的OpenRouter可以做什么](http://mp.weixin.qq.com/s?__biz=MzkwODcyNjc2NQ==&mid=2247484420&idx=1&sn=89bca30ba8c9eaa23a3d609a8078e036&chksm=c0c4dc86f7b355902f80b0180a6c9ae5466a30338608b6449884930332d491b99fe89aa281a6&scene=21#wechat_redirect)》一文中对OpenRouter也有简单介绍。\n\nCline的使用方法和技术原理\n---------------\n\n### 安装和配置\n\n1.  安装：\n    \n\n*   在VSCode扩展市场搜索\"Cline\"并安装\n    \n*   或直接访问Cline (prev. Claude Dev) - Visual Studio Marketplace下载安装\n    \n\n3.  配置：\n    \n\n*   选择API提供商（如OpenAI Compatible）\n    \n*   设置Base URL（如api.deepseek.com）\n    \n*   输入API Key\n    \n*   选择Model ID（如deepseek-coder）\n    \n*   可以在Custom Instructions中添加额外的prompts\n    \n*   建议勾选\"Always allow read-only operations\"以提高效率\n    \n\n### 技术原理\n\nCline的核心技术原理包括：\n\n1.  上下文管理：\n    \n\n*   通过仔细管理添加到上下文中的信息，Cline能够在不超出上下文窗口的情况下为大型复杂项目提供有价值的帮助\n    \n\n3.  代码分析：\n    \n\n*   使用抽象语法树（AST）分析源代码结构\n    \n*   应用正则表达式进行代码搜索\n    \n\n5.  人机交互：\n    \n\n*   提供人机交互GUI，让用户批准每个文件更改和终端命令\n    \n*   在保证安全的同时，探索代理AI的潜力\n    \n\n7.  多模态技术：\n    \n\n*   支持图像分析（取决于使用的模型）\n    \n*   使用无头浏览器检查网站，捕获屏幕截图和控制台日志\n    \n\n9.  Shell集成：\n    \n\n*   利用VSCode v1.93中的新shell集成更新，直接在终端中执行命令并接收输出\n    \n\n11.  缓存机制：\n    \n\n*   实现输入Tokens的缓存命中，大幅降低API调用成本\n    \n\n通过这些技术，Cline能够深入理解项目结构，提供精准的代码建议和错误修复，同时保持高效的性能和较低的使用成本。\n\nCline模型成本对比案例\n-------------\n\n为了更好地理解Cline的实际应用价值，我做了一个模型成本对比测试，分别用Claude 3.5 Sonnet和DeepSeek来实现网页版的扫雷游戏：\n\n### Claude 3.5 Sonnet 成本分析：\n\n如下图所示，消耗47.7k输入tokens和4.2k输出tokens，花费$0.1299。\n\n![Image 4: Image](https://mmbiz.qpic.cn/mmbiz_png/Ox7oPciaTLvGMGhqwU0J22obOMXhWeaMQU5yKKWph5qnZicLuhjecCHiaMmoFPQrS52aDHtNasf2m3FEJzdpNYujQ/640?wx_fmt=png&from=appmsg)\n\nClaude 3.5 Sonnet项目成本\n\n### DeepSeek 成本分析：\n\n如下图所示，消耗66.1k输入tokens和5.1k输出tokens，花费$0.0026，可是比Claude的模型便宜了不少啊。\n\n![Image 5: Image](https://mmbiz.qpic.cn/mmbiz_png/Ox7oPciaTLvGMGhqwU0J22obOMXhWeaMQCfrY7cpLaZzcicbIVKxmTe0otVt7rkarMMho8Lyevm1eCAZuRLFtTQQ/640?wx_fmt=png&from=appmsg)\n\nDeepSeek项目成本\n\n所以现在无论是商用模型还是开源模型，Cline都能提供全面的支持，大大提高了开发效率。同时，开源模型DeepSeek以其低廉的使用成本也使得它成为开发者的另一个重要选择。不过从我测试的体验来看，DeepSeek的表现没有Claude那么丝滑，有时候可能不能一步到位，还需要用户进行错误的修正，而且DeepSeek不是多模态的，所以不能像Claude那样检查自己创造的作品，能力上相对有所限制。\n\nCline与其他AI编程助手的比较\n-----------------\n\n![Image 6: Image](https://mmbiz.qpic.cn/mmbiz_svg/47CicbLQOxtXwniaGSxwgokib0cmFJTCZov7ge2DMJe36Q6hZ7y4JLhX5ibYsIgPzztLuzcPBGNXQJ549L3KruPpB7BicnCdW3lcM/640?wx_fmt=svg&from=appmsg)\n\nCline vs Other AI Coding Assistants\n\n虽然市场上已有多种AI编程助手，但Cline在以下几个方面表现出独特的优势：\n\n1.  全面的项目支持\n    \n\n*   不仅提供代码补全，还能执行复杂的软件开发任务\n    \n*   从项目创建到文件编辑，再到终端命令执行，覆盖开发全流程\n    \n\n3.  灵活的模型选择\n    \n\n*   支持多种API提供商和模型\n    \n*   可以根据需求和预算选择最适合的模型\n    \n\n5.  成本效益高\n    \n\n*   特别是使用DeepSeek等模型时，成本显著降低\n    \n*   缓存机制进一步优化了token使用\n    \n\n7.  人机协作\n    \n\n*   每一步操作都需要用户确认，保证了安全性\n    \n*   同时保持了AI自主性和人工控制的平衡\n    \n\n9.  多模态能力\n    \n\n*   支持图像分析和网页检查\n    \n*   有助于解决视觉相关的开发问题\n    \n\n11.  深度集成VSCode\n    \n\n*   作为VSCode插件，与开发环境紧密结合\n    \n*   利用VSCode的新特性（如shell集成）提供更强大的功能\n    \n\n相比之下，许多其他AI编程助手可能只专注于代码补全或简单的问题解答，而缺乏Cline这样全面的项目开发支持能力。\n\n结论\n--\n\nCline作为一款强大的VSCode插件，为开发者提供了全面的AI辅助编程解决方案。它不仅能够进行智能代码分析与生成，还能执行文件操作、终端命令，甚至协助网页开发。通过支持多种模型和API提供商，Cline为用户提供了灵活的选择，同时其高效的缓存机制和成本追踪功能也确保了使用的经济性。\n\n从具体的应用案例中，我们可以看到Cline使用模型非常灵活。特别是在使用DeepSeek等模型时，Cline展现出极高的性价比，使得AI辅助编程变得更加经济实惠。\n\n与其他AI编程助手相比，Cline的全面项目支持、灵活模型选择、高成本效益、人机协作模式以及多模态能力等特点，使其成为一个独特而强大的开发工具。它不仅能够提高开发效率，还能帮助开发者学习新技术，探索AI在软件开发中的潜力。\n\n随着AI技术的不断进步，我们可以期待Cline在未来会有更多令人兴奋的功能和改进。对于希望提高编程效率、探索AI辅助开发的开发者来说，Cline无疑是一个值得尝试的强大工具。\n",
    "created_at": "2025-03-19T07:14:50Z",
    "updated_at": "2025-03-19T07:15:51Z",
    "labels": [],
    "url": "https://github.com/kaozb/ai-arctl/issues/24"
  },
  {
    "id": 23,
    "title": "别再为 RAG 文本分块发愁！Chonkie 让复杂操作轻松搞定",
    "content": "\n\n```\nhttps://github.com/chonkie-ai\n```\n\n1\\. 为啥文本分块这么重要？2\\. 搭建 RAG 应用时的 “分块困境”3\\. Chonkie 库4\\. Chonkie 库使用示例\n\n在自然语言处理（NLP）中，RAG（检索增强生成）技术可谓大放异彩。它能让模型借助大量文本数据，生成更精准、更丰富的内容。不过，在 RAG 的实际运用中，有个关键环节却常常让开发者们头疼不已，那就是文本分块（Chunking）。今天，就给大家介绍一款堪称 “救星” 的神器 ——Chonkie 库，让 RAG 中的文本分块难题迎刃而解！\n\n![Image 3: 图片](https://mmbiz.qpic.cn/sz_mmbiz_png/SaeK9tW7Bu9jDTJAUrIz6roozJxyvbWm2qUTfR6OqmSqoQxc2YiacZC8vlPmdeYLKpyjXrX3FB3T5IAhD1pTAlA/640?wx_fmt=png&from=appmsg&wxfrom=5&wx_lazy=1&wx_co=1&tp=webp)\n\n1\\. 为啥文本分块这么重要？\n===============\n\n简单来说，文本分块就是把长长的文本拆解成一个个小块，这些小块可以是词语、句子、段落，或者语义单元。这可不是多此一举，它的作用至关重要。\n\n1.  **适配模型输入限制**：大多数深度学习模型都有输入长度的 “门槛”。就拿 GPT-2 来说，它最多只能处理 1024 个 token 的输入。要是一股脑把超长文本塞进去，模型就会 “罢工”，不是内存告急，就是性能大幅下降。把文本分块后，每一块都能控制在模型可接受的范围内，模型运行起来自然更顺畅，效率也大大提高。\n    \n2.  **强化上下文理解**：文本的语义往往是连贯的，会跨越多个句子甚至段落。在 RAG 应用中，经常需要依据不同的文本块来检索信息。合理分块能保留清晰的上下文，让模型更好地把握语义关系，避免关键信息 “走失”。\n    \n3.  **提升 RAG 效果**：信息检索是 RAG 的核心步骤。通过文本分块，我们可以更精细地划定检索范围，让模型从分块中精准提取关键信息，生成的内容准确性和相关性都更上一层楼。\n    \n4.  **减轻计算负担**：处理海量文本数据时，如果直接将其整体丢给模型，不仅效率低下，还容易遭遇性能瓶颈。而分块处理后，模型可以并行处理多个小文本片段，计算效率实现飞跃。\n    \n\n2\\. 搭建 RAG 应用时的 “分块困境”\n======================\n\n虽然文本分块好处多多，但在搭建 RAG 应用的过程中，实现分块操作却困难重重。市面上的相关库和工具繁多，可要么安装流程繁琐得让人望而却步，要么实际运行效率低得让人抓狂。要是自己动手编写分块代码，不仅耗时费力，还不一定能达到理想效果。很多开发者都在苦苦寻觅一个既简单又高效的解决方案，却常常无功而返。\n\n3\\. Chonkie 库\n=============\n\nChonkie 库是一款专为 RAG 文本分块打造的宝藏工具，它的出现就是为了让分块操作变得轻松简单，能无缝集成到 RAG 应用中。\n\n*   **功能强大，满足多样需求**：Chonkie 支持多种分块方式，无论你是想按固定大小的 token 分块，还是按单词、句子分块，亦或是基于语义规则分块，它都能满足。\n    \n\n*   按固定大小 token 分块的 TokenChunker\n    \n*   按单词分块的 WordChunker\n    \n*   按句子分块的 SentenceChunker\n    \n*   基于可定制规则进行层次化语义分块的 RecursiveChunker\n    \n*   依据语义相似性分块的 SemanticChunker\n    \n*   基于语义双重合并方法分块的 SDPMChunker\n    \n*   实验性的先文本嵌入再分块以获取高质量 chunk 嵌入的 LateChunker\n    \n\n*   **简单易用，新手也能轻松上手**：Chonkie 的安装、导入和调用都极其简单\n    \n\n*   安装时，只需在命令行输入`pip install chonkie` 就搞定了。\n    \n*   如果还想使用更多分块器，输入`pip install chonkie[all]`即可。\n    \n*   不过，为了避免安装包过大，建议只安装自己需要的分块器。\n    \n\n*   **速度超快，性能卓越**：Chonkie 的运行速度快得惊人！\n    \n\n*   进行 Token Chunking 时，比最慢的替代方案快 33 倍；\n    \n*   Sentence Chunking 速度几乎是竞争对手的两倍；\n    \n*   Semantic Chunking 也比其他工具快最多 2.5 倍。\n    \n\n*   默认安装包仅有 15MB，相比其他动辄 80MB 到 171MB 的工具包，简直是 “轻量级选手”。\n    \n*   在实际性能上，它更是一骑绝尘。\n    \n\n*   **轻量精简，扩展性强**：Chonkie 只保留了最核心、最必要的功能，没有任何冗余代码，这使得它运行起来更加高效。而且，它能和各种常见的 tokenizer 完美兼容，开发者可以根据项目需求自由搭配，扩展性超强。\n    \n\n4\\. Chonkie 库使用示例\n=================\n\n下面，通过一个简单的代码示例，带大家感受下 Chonkie 的使用过程。\n\n```\nfrom chonkie import TokenChunker\n```\n\n在这段代码中，首先导入了`TokenChunker`，接着用预训练的 GPT-2 模型初始化`tokenizer`，创建`chunker`后，就能轻松对文本进行分块，并输出每个分块的具体内容和包含的 token 数量。\n\nChonkie 库为 RAG 文本分块带来了全新的解决方案，无论是功能、速度，还是易用性和扩展性，都表现得十分出色。如果大家正在为 RAG 应用中的文本分块问题烦恼，不妨试试 Chonkie 库。\n",
    "created_at": "2025-03-19T07:04:34Z",
    "updated_at": "2025-03-19T07:08:47Z",
    "labels": [],
    "url": "https://github.com/kaozb/ai-arctl/issues/23"
  },
  {
    "id": 12,
    "title": "Github收藏夹",
    "content": "# Github收藏夹  \n\n\n\n## RPC\n* [Dubbo](https://github.com/alibaba/dubbo) - 阿里出品的使用范围很广的一款高性能，基于 Java 的开源 RPC 框架\n* [Motan](https://github.com/weibocom/motan) - 微博出品的一款用于快速开发高性能分布式服务的跨语言 RPC 框架\n* [bRPC](https://github.com/brpc/brpc) - 百度出品的工业级 RPC 框架\n* [gRPC](https://github.com/grpc/grpc) - gRPC 是一个先进的，开源的，高性能的 RPC 框架，可以在任何地方运行。 gRPC 使客户端和服务器应用程序可以透明地进行通信，并简化了连接系统的构建\n* [Tars](https://github.com/Tencent/Tars) - 腾讯出品的高性能 RPC 框架\n* [sofa-rpc](https://github.com/alipay/sofa-rpc) - 蚂蚁金服出品的高可扩展性、高性能、生产级的 Java RPC 框架\n\n## 微服务\n* [fabric8](https://github.com/fabric8io/fabric8) - 基于 Docker，Kubernetes and Jenkins 的微服务平台\n*  [Axon](https://github.com/AxonFramework/AxonFramework) - 一款基于领域驱动设计的 CQRS 框架，用于构建事件驱动的微服务系统\n\n## 分布式协议\n* [sofa-jraft](https://github.com/sofastack/sofa-jraft) - 一个生产级别的 RAFT 的 Java 实现\n* [Ratis](https://github.com/apache/incubator-ratis) - Raft 共识协议的 Java 实现\n\n## 持续集成&交付\n* [Skaffold](https://github.com/GoogleContainerTools/skaffold) - Google 出品的一款命令行工具，用于促进 Kubernetes 应用程序的持续开发\n* [Travis](https://github.com/travis-ci/travis-ci) - 针对 Github 上项目的免费的持续集成平台\n* [Argo](https://github.com/argoproj/argo) - 用于 Kubernetes 的容器原生的工作流引擎\n* [Brigade](https://github.com/azure/brigade) - 基于事件的 Kubernetes 脚本。可以使用 JavaScript 编写简单或复杂的工作流程脚本。\n* [Buildkite](https://github.com/buildkite/agent) - Buildkite Agent 是一个用 Golang 编写的开源工具包，用于在任何设备或网络上安全地运行构建作业\n* [Concourse](https://github.com/concourse/concourse) - Concourse 是一个用 Go 编写的自动化系统. 它最常用于 CI/CD，可以扩展到任何类型的从简单到复杂自动化 pipline\n* [ContainerOps](https://github.com/Huawei/containerops) - Devops 编排工具\n* [Drone](https://github.com/drone/drone) - Drone是一个用Go写的基于Docker的持续交付平台\n* [Gitkube](https://github.com/hasura/gitkube) - Gitkube是一个使用git push在Kubernetes上构建和部署Docker镜像的工具\n* [GitLab](https://github.com/gitlabhq/gitlabhq) - Gitlab，第一款实现了完整的Devops生命周期的应用\n* [GoCD](https://github.com/gocd/gocd) - 持续交付的server，GoCD可帮助您自动化和简化构建测试 - 发布周期，从而无忧无虑地持续交付产品\n* [Habitus](https://github.com/cloud66-oss/habitus) - Habitus为Docker构建添加了工作流，这意味着您可以基于工作流创建一系列构建，并生成最终的Docker镜像\n* [Jenkins](https://github.com/jenkinsci/jenkins) - 最流行的CI/CD工具，提供多达上千种插件支持，几乎支持任何自动化构建\n* [JenkinsX](https://github.com/jenkins-x/jx) - Jenkins X使用Jenkins，Knative Build，Prow，Skaffold和Helm为Kubernetes提供自动CI + CD，并提供Pull Request的预览环境\n* [Spinnaker](https://github.com/spinnaker/spinnaker) - Spinnaker是一个开源的，Multi-Cloud的持续交付平台，以快速且高可用的方式发布软件\n* [Flux](https://github.com/weaveworks/flux) - 当在Continuous Delivery管道末端用作部署工具时，Flux最有用. Flux将确保您的新容器映像和配置更改传播到集群\n* [Wercker](https://github.com/wercker/wercker) - wercker是为wercker.com提供所有构建和部署作业的命令行工具，它在Docker的帮助下在本地计算机上运行\n* [Zuul CI](https://github.com/openstack-infra/zuul) - Zuul推动持续集成，交付和系统部署，重点关注project gating和相互关联的项目，此项目非Netflix的zuul\n* [CircleCI](https://github.com/marketplace/circleci) - 一款支持在 Github 上进行构建的商业 CI 工具\n* [TeamCity](https://www.jetbrains.com/teamcity/) - TeamCity 是 JetBrains 出品的构建管理和持续集成服务器\n\n## 数据库\n* [ShardingSphere](https://github.com/apache/shardingsphere) - 开源的分布式数据库中间件解决方案。它在 Java 的 JDBC 层以对业务应用零侵入的方式额外提供数据分片、读写分离、柔性事务、数据加密和分布式治理等能力。并在其基础上提供封装了常见数据库协议的服务端版本，用于完成对异构语言的支持。\n* [HikariCP](https://github.com/brettwooldridge/HikariCP) - 简单可靠的高性能 JDBC 连接池，号称 \"zero-overhead\" 生产就绪，lib 仅仅 130Kb 左右\n* [h2database](https://github.com/h2database/h2database) - 快速的，开源的，支持 JDBC API 的内存数据库\n* [mycat](https://github.com/MyCATApache/Mycat-Server) - 基于阿里cobar改良的分布式数据库中间件，官宣为一个模拟MySQL Server的超级数据库\n* [cobar](https://github.com/alibaba/cobar) - 阿里出品的支持 Sharding 的 Proxy(很久没有维护了)\n* [ignite](https://github.com/apache/ignite) - Apache旗下的一款以内存为中心，多模型的分布式数据库.号称可以以内存级别的速度处理 Pb 级别的数据.\n* [vitess](https://github.com/vitessio/vitess) - Vitess是一个用于MySQL水平扩展的数据库集群系统\n* [arangodb](https://github.com/arangodb/arangodb) - ArangoDB是一个原生的多模型数据库，具有文档，图形和键值的灵活数据模型。使用方便的类SQL查询语言或JavaScript扩展构建高性能应用程序\n* [bigchaindb](https://github.com/bigchaindb/bigchaindb) - BigchainDB 是区块链数据库\n* [CarbonData](https://github.com/apache/carbondata) - Apache CarbonData 是一种索引的柱状数据存储解决方案，用于在大数据平台上进行快速分析，例如 Apache Hadoop，Apache Spark 等\n* [Cassandra](https://github.com/apache/cassandra) - Apache Cassandra 是一套开源分布式 NoSQL 数据库系统。它最初由 Facebook 开发，用于储存收件箱等简单格式数据，集 Google BigTable 的数据模型与 Amazon Dynamo 的完全分布式的架构于一身。Facebook 于 2008 将 Cassandra 开源，此后，由于 Cassandra 良好的可扩放性，被 Digg、Twitter 等知名 Web 2.0 网站所采纳，成为了一种流行的分布式结构化数据存储方案\n* [Couchbase](https://github.com/couchbase/manifest) - 为Web时代而生的开源数据库\n* [CrateDB](https://github.com/crate/crate) - CrateDB 是一个分布式 SQL 数据库，可以轻松实时存储和分析大量机器数据\n* [Druid](https://github.com/apache/incubator-druid) - Apache Druid（孵化中）是一个用于事件驱动数据的高性能列簇数据库\n* [FoundationDB](https://github.com/apple/foundationdb) - FoundationDB 是一个分布式数据库，旨在处理跨商用服务器群集的大量结构化数据. 它将数据组织为有序的键值存储，并为所有操作使用 ACID 事务。它特别适用于读/写工作负载，但对写入密集型工作负载也具有出色的性能。用户使用 API​​ 语言绑定与数据库交互\n* [Hadoop](https://github.com/apache/hadoop) - Apache Hadoop 使用简单的编程模型跨计算机集群分布式处理大型数据集\n* [Hazelcast](https://github.com/hazelcast/hazelcast) - 企业级的开源框架，是一款功能丰富且对开发人员友好的内存数据网格解决方案\n* [Infinispan](https://github.com/infinispan/infinispan) - 一个开源数据网格平台和高度可扩展的NoSQL云数据存储\n* [MariaDB](https://github.com/MariaDB/server) - MariaDB Server 是社区开发的 MySQL Server 的分支，由原始 MySQL 团队的核心成员发起\n* [Fescar](https://github.com/alibaba/fescar) - 阿里出品的分布式事务解决方案，具有高性能和易于使用的微服务架构\n* [MongoDB](https://github.com/mongodb/mongo) - 一个文档数据库，由C++撰写而成\n* [MySQL](https://github.com/mysql/mysql-server) - 世界上最流行的开源数据库\n* [Neo4j](https://github.com/neo4j/neo4j) - 高性能的图形数据库，具有成熟和强大的数据库所需的所有功能，如友好的查询语言和ACID事务\n* [noms](https://github.com/attic-labs/noms) - 一款灵感来自于Git的去中心化的数据库\n* [OrientDB](https://github.com/orientechnologies/orientdb) - OrientDB 是最通用的 DBMS，在一个多模型产品中支持图形，文档，反应，全文，地理空间和键值模型。 OrientDB 可以运行分布式（Multi-Master），支持 SQL，ACID 事务，全文索引和反应查询\n* [Percona](https://github.com/percona/percona-server) - Percona Server 是 MySQL 8.0 的一个分支，带来更高的性能， 可靠性和更多功能\n* [Pilosa](https://github.com/pilosa/pilosa) - 分布式位图索引，可以显著加速跨多个海量数据集的查询\n* [PostgreSQL](https://github.com/postgres/postgres) - PostgreSQL 是一个功能强大的开源对象关系数据库系统，经过30多年的积极开发，在可靠性，功能稳健性和性能方面赢得了良好的声誉\n* [Presto](https://github.com/prestosql/presto) - Presto 是一个用于大数据的分布式 SQL 查询引擎\n* [RethinkDB](https://github.com/rethinkdb/rethinkdb) - RethinkDB是第一个为实时应用程序构建的开源可扩容数据库，它开拓了一种新型的数据访问模型，不同于拉取改变的数据，开发人员可以控制数据库不断地将更新的查询结果实时推送到应用程序\n* [Scylla](https://github.com/scylladb/scylla) - 使用seastar框架的NoSQL数据存储，与Apache Cassandra兼容\n* [stolon](https://github.com/sorintlab/stolon) - stolon是保证PostgreSQL高可用的云原生管理器\n* [TiDB](https://github.com/pingcap/tidb) - 国产的分布式HTAP数据库，兼容 MySQL 协议\n* [TiKV](https://github.com/tikv/tikv) - 分布式事务键值数据库，最初创建用于补充TiDB\n* [YugaByte DB](https://github.com/YugaByte/yugabyte-db) - YugaByte DB是一款开源的高性能SQL数据库，用于构建互联网规模的全球分布式应用程序\n* [hmily](https://github.com/yu199195/hmily) - 高性能异步分布式事务TCC框架\n* [flyway](https://github.com/flyway/flyway) - 使数据库迁移变得简单\n* [nebula](https://github.com/vesoft-inc/nebula) - Nebula Graph 是一款开源的图数据库，擅长处理千亿个顶点和万亿条边的超大规模数据集\n* [snowflake](https://github.com/snowflakedb) - Snowflake 是一家云存储技术开发公司，旨在搭建一个基于云服务的新型数据库和数据处理架构，以此满足用户和数据处理层面的需求\n* [Weaviate](https://github.com/semi-technologies/weaviate) - Weaviate 是一个矢量搜索引擎和矢量数据库\n* [SchemaHero](https://github.com/schemahero/schemahero) - SchemaHero 是一个 Kubernetes Operator，用于各种数据库的声明式管理。\n\n## 缓存\n* [Redis](https://github.com/antirez/redis) - 可以当成数据库，缓存，消息队列使用的内存数据结构存储工具\n* [KeyDB](https://github.com/JohnSully/KeyDB) - KeyDB是 Redis 的一个分支，专注于多线程，内存效率和高吞吐量\n* [Ehcache](https://github.com/ehcache/ehcache3) - 号称使用最为广泛的 Java 缓存\n\n## 流&消息\n* [Kafka](https://github.com/apache/kafka) - 隶属于Apache的分布式流平台\n* [RocketMQ](https://github.com/apache/rocketmq) - 隶属于Apache的分布式消息跟流平台，低延迟，高性能，高可靠，万亿级别容量，动态扩展\n* [ActiveMQ](https://github.com/apache/activemq) - 隶属于Apache的高性能消息队列\n* [NATS Server](https://github.com/nats-io/gnatsd) - NATS Server是一个简单，高性能的开源消息系统，适用于云原生应用程序，物联网消息传递和微服务架构。\n* [Heron](https://github.com/apache/incubator-heron) - Apache Heron(孵化中)是一款来自 Twitter 的实时，分布式，具有容错性的流处理引擎\n* [NiFi](https://github.com/apache/nifi) - Apache NiFi是一个易于使用，功能强大且可靠的系统，用于处理和分发数据\n* [Spark](https://github.com/apache/spark) - Apache Spark是一种快速通用的大数据集群计算系统. 提供Scala，Java，Python和R的高级API，以及支持数据分析的通用计算图的优化引擎\n* [Storm](https://github.com/apache/storm) - Apache Storm 是一个分布式实时计算系统. 类似于 Hadoop 提供一组用于批处理的通用基元，Storm 以此处理实时计算\n* [Beam](https://github.com/apache/beam) - Apache Beam是一个统一的模型，用于定义批处理和流数据并行处理管道，以及一组特定于语言的SDK，用于构建管道和Runners，用于在分布式处理后端上执行它们，包括Apache Apex，Apache Flink，Apache Spark和Google Cloud Dataflow。\n* [CloudEvents](https://github.com/cloudevents/spec) - CloudEvents是一项新的开放规范，用于对事件数据提供一致的描述标准. 该开放规范由 CNCF下设的 无服务器工作组（Serverless Working Group）提出，且CNCF已与多家云服务和云提供商建立了合作伙伴关系\n* [Flink](https://github.com/apache/flink) - Apache Flink是一个开源流处理框架，具有强大的流和批处理功能\n* [Open Messaging](https://github.com/openmessaging/openmessaging-java) - OpenMessaging，目的在于建立行业指南并且为消息传递，流媒体规范，为财务，电子商务，物联网和大数据领域提供通用框架. 设计原则是分布式异构环境中面向云，简单，灵活和独立于语言的原则. 符合这些规范将有可能在所有主要平台和操作系统上开发异构消息传递应用程序\n* [Pachyderm](https://github.com/pachyderm/pachyderm) - 数据版本控制，数据管道和数据沿袭工具\n* [Pulsar](https://github.com/apache/pulsar) - Pulsar是一个分布式pub-sub消息传递平台，具有非常灵活的消息传递模型和直观的客户端API\n* [RabbitMQ](https://github.com/rabbitmq/rabbitmq-server) - RabbitMQ是部署最广泛的开源message broker\n* [StreamSets](https://github.com/streamsets/datacollector) - StreamSets Data Collector是一个企业级，开源，持续的大数据摄取基础架构\n* [Strimzi](https://github.com/strimzi/strimzi-kafka-operator) - Strimzi 可以基于各种部署配置运行在 Kubernetes 或 OpenShift 上的 Kafka 集群\n* [Debezium](https://github.com/debezium/debezium) - Debezium为捕获改变数据，提供了一个低延迟的流式平台\n\n## 应用定义&镜像构建\n* [Helm](https://github.com/helm/helm) - 一个Kubernetes包管理器，CNCF项目\n* [Brooklyn](https://github.com/apache/brooklyn-server) - Apache 旗下开源框架，用于建模，部署和管理使用声明式YAML蓝图定义的分布式应用程序\n* [Buildpacks](https://github.com/buildpack/pack) - Buildpacks是可插拔的模块化工具，可将源代码转换为OCI映像\n* [Docker Compose](https://github.com/docker/compose) - Compose是一个用于定义和运行多容器Docker应用程序的工具。使用Compose，您可以使用Compose文件来配置应用程序的服务。然后，使用单个命令，您可以从配置中创建并启动所有服务\n* [Draft](https://github.com/azure/draft) - 一款用于开发人员在Kubernetes上创建云原生应用程序的工具\n* [Habitat](https://github.com/habitat-sh/habitat) - 可创建独立于平台的构建工件，并提供内置的部署和管理功能\n* [Kaniko](https://github.com/GoogleContainerTools/kaniko) - kaniko可以在container或者k8s集群中通过Dockerfile构建镜像\n* [KubeVirt](https://github.com/kubevirt/kubevirt) - KubeVirt是Kubernetes的虚拟机管理插件。目的是为Kubernetes提供虚拟化解决方案的共同基础\n* [virtlet](https://github.com/Mirantis/virtlet) - Virtlet是一个Kubernetes运行时服务器，允许您基于QCOW2映像运行VM工作负载\n* [Open Service Broker API](https://github.com/openservicebrokerapi/servicebroker) - Open Service Broker API项目允许独立软件供应商，SaaS提供商和开发人员轻松地为在Cloud Foundry和Kubernetes等云原生平台上运行的工作负载提供支持服务\n* [OpenAPI](https://github.com/OAI/OpenAPI-Specification) - OpenAPI规范是OpenAPI Initiative中的社区驱动的开放规范，一个 Linux 基金会协作项目\n* [Operator Framework](https://github.com/operator-framework/operator-sdk) - 用于构建 Kubernetes 应用程序的 SDK。提供高级 API，有用的抽象和项目脚手架\n* [Packer](https://github.com/hashicorp/packer) - Packer是一个从单一的模板文件来创建多平台一致性镜像的轻量级开源工具\n* [ServiceComb](https://github.com/apache/servicecomb-java-chassis) - ServiceComb Java Chassis 是一款 SDK，用于快速开发Java中的微服务，提供服务注册，服务发现，动态路由和服务管理功能\n* [Ship](https://github.com/replicatedhq/ship) - Ship使Kubernetes集群运营商能够跟踪和自动化生产等级的维护，第三方应用程序部署（适用于开源和商业支持的应用程序）\n* [Skaffold](https://github.com/GoogleContainerTools/skaffold) - Skaffold是一个命令行工具，可以促进Kubernetes应用程序的持续开发\n* [Squash](https://github.com/solo-io/squash) - Squash 可以在Kubernetes中运行时，从终端或IDE调试微服务应用程序\n* [Telepresence](https://github.com/telepresenceio/telepresence) - 针对远程Kubernetes或OpenShift集群的本地开发\n* [Tilt](https://github.com/windmilleng/tilt) - 本地Kubernetes开发无压力\n\n## 搜索引擎\n* [elasticsearch](https://github.com/elastic/elasticsearch) - 支持分布式的Restful的搜索引擎\n\n## 调度&编排\n* [kubernetes](https://github.com/kubernetes/kubernetes) - Kubernetes 是一个开源系统，用于管理多个主机上的容器化应用程序;提供应用程序部署，维护和扩展的基本机制\n* [elastic-job](https://github.com/elasticjob/elastic-job-lite) - Elastic-Job 是一个分布式调度解决方案，由两个相互独立的子项目 Elastic-Job-Lite 和 Elastic-Job-Cloud 组成.\n* [flink](https://github.com/apache/flink) - 隶属于Apache的流处理框架，拥有强大的流处理以及批量处理的能力.\n* [quartz](https://github.com/quartz-scheduler/quartz) - 功能丰富的，几乎可以与任何java程序集成的调度框架\n* [xxl-job](https://github.com/xuxueli/xxl-job) - 分布式任务调度平台XXL-JOB\n* [Mesos](https://github.com/apache/mesos) - Apache Mesos是一个集群管理器，可跨分布式应用程序或框架提供有效的资源隔离和共享。它可以在动态共享节点池上运行Hadoop，Jenkins，Spark，Aurora和其他框架\n* [Crossplane](https://github.com/crossplaneio/crossplane) - Crossplane是一个开源多云平台控制平面。它在现有托管服务的基础上引入了工作负载和资源抽象，从而实现了跨云提供商的高度工作负载可移植性\n* [dolphinscheduler](https://github.com/apache/dolphinscheduler) - 一款分布式且易于扩展的可视工作流计划程序系统，已经成为 Apache 顶级项目\n* [OpenNebula](https://github.com/OpenNebula/one) - OpenNebula 是一个开源平台，提供简单但功能丰富且灵活的解决方案，用于构建和管理用于虚拟化服务、容器化应用程序和无服务器计算的企业云\n* [k3s](https://github.com/k3s-io/k3s) - 轻量级 Kubernetes\n\n## 服务协调&发现\n* [coredns](https://github.com/coredns/coredns) - CoreDNS(Go 语言编写)是一个链接插件的DNS服务器，每个插件都执行DNS功能。\n* [zookeeper](https://github.com/apache/zookeeper) apache旗下的分布式服务协调框架\n* [etcd](https://github.com/etcd-io/etcd) 一个可依赖的分布式key-value存储系统，用于分布式环境下保存关键数据\n* [Consul](https://github.com/hashicorp/consul) - Consul是一种服务发现和配置工具。 Consul 具有分布式，高可用性和极高的可扩展性\n* [Nacos](https://github.com/alibaba/nacos) - 阿里出品的一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台\n* [archguard](https://github.com/archguard/archguard) - ArchGuard 是一个架构治理工具，用于管理和分析组织级别的软件架构。\n\n## 服务代理\n* [envoy](https://github.com/envoyproxy/envoy) - Envoy是一个开源服务代理，专为云应用而设计\n* [HAProxy](https://github.com/haproxy/haproxy) - 可靠，高性能的TCP / HTTP负载均衡器\n* [nginx](https://github.com/nginx/nginx) - nginx [engine x]是一个HTTP和反向代理服务器，一个邮件代理服务器和一个通用的TCP / UDP代理服务器，最初由Igor Sysoev编写。\n* [OpenResty](https://github.com/openresty/openresty) - OpenResty是一个成熟的Web应用程序服务器，它捆绑了标准的nginx核心，许多第三方nginx模块以及大多数外部依赖项。\n* [traefik](https://github.com/containous/traefik) - Traefik（发音为traffic）是一种先进的HTTP反向代理和负载均衡器，可以轻松部署微服务\n\n## API网关\n* [3scale](https://github.com/3scale/apicast) - APIcast是一个建立在NGINX之上的API网关. 它是Red Hat 3scale API管理平台的一部分\n\n## ServiceMesh\n* [linkerd](https://github.com/linkerd/linkerd) - Linkerd旨在透明地向所有服务间通信添加服务发现，负载平衡，故障处理，检测和路由，使应用程序变得安全可靠\n* [Consul](https://github.com/hashicorp/consul) - Consul 是一种分布式，高可用性和数据中心感知解决方案，用于跨动态分布式基础架构连接和配置应用程序\n* [Istio](https://github.com/istio/istio) - Istio是一个开放平台，用于提供统一的方式来集成微服务，管理跨微服务的流量，实施策略和聚合遥测数据\n* [Zuul](https://github.com/Netflix/zuul) - Zuul是一种网关服务，可提供动态路由，监控，弹性，安全性等。\n* [SuperGloo](https://github.com/solo-io/supergloo) - SuperGloo，一个大规模管理和编排服务网格的开源项目\n* [Vamp](https://github.com/magneticio/vamp) - Vamp 的核心功能是平台无关的微服务DSL，简单的 A-B 测试/ canary releasing 所有内容以及深度和可扩展的指标引擎，可监控所有内容并直接反馈到您的服务中。\n\n## 云原生存储\n* [Rook](https://github.com/rook/rook) - Rook是Kubernetes的开源云本地存储协调器，为各种存储解决方案提供平台，框架和支持，以便与云原生环境本地集成\n* [Alluxio](https://github.com/alluxio/alluxio) - Alluxio（以前称为Tachyon）是一个虚拟的分布式存储系统。它弥合了计算框架和存储系统之间的鸿沟，使计算应用程序可以通过公共接口连接到众多存储系统\n* [Ceph](https://github.com/ceph/ceph) - Ceph是一个分布式对象，块和文件存储平台\n* [ChubaoFS](https://github.com/chubaofs/chubaofs) - ChubaoFS(储宝文件系统)是为大规模容器平台设计的分布式文件系统\n* [CSI](https://github.com/container-storage-interface/spec) - Container Storage Interface，容器存储接口规范\n* [Gluster](https://github.com/gluster/glusterfs) - Gluster是一种 software defined 的分布式存储，可以扩展到几个PB。它提供了用于对象，块和文件存储的接口\n* [Longhorn](https://github.com/longhorn/longhorn) - Longhorn 是一个 Kubernetes 的分布式块存储系统\n* [MinIO](https://github.com/minio/minio) - MinIO是与Amazon S3 API兼容的高性能对象存储服务器\n* [MooseFS](https://github.com/moosefs/moosefs) - MooseFS 是一个 PB 级别的开源分布式文件系统。它易于部署和维护，容错，高性能，易于扩展且兼容 POSIX\n* [OpenEBS](https://github.com/openebs/openebs) - 基于与原生架构构建的领先的开源容器附加存储，可以简化运行在 k8s 上的 stateful application\n* [OpenIO](https://github.com/open-io/oio-sds) - OpenIO SDS是面向大数据和AI的高性能对象存储\n* [OpenSDS](https://github.com/opensds/opensds) - Linux基金下的一个协作项目，得到了存储用户和供应商的支持，包括Dell EMC，英特尔，华为，富士通，西部数据，沃达丰，NTT和俄勒冈州立大学\n* [Swift](https://github.com/openstack/swift) - 分布式对象存储系统，旨在从一台机器扩展到数千台服务器\n* [Manta](https://github.com/joyent/manta) - Triton的对象存储和融合分析解决方案，基于HTTP的对象存储\n* [Velero](https://github.com/vmware-tanzu/velero) - Velero（以前称为Heptio Ark），可以备份和迁移Kubernetes应用程序及其持久卷\n* [Zenko](https://github.com/scality/zenko) - enko 为本地存储（使用Docker卷或Scality RING）或在公共云存储服务（如Amazon S3，Microsoft Azure Blob存储或Google Cloud Storage）中存储的数据提供统一的名称空间，访问API和搜索功能\n\n## 容器\n* [containerd](https://github.com/containerd/containerd) - 一个开放且可靠的容器运行时\n* [podman](https://github.com/containers/podman) - 是一个开源的容器运行时项目，可在大多数 Linux 平台上使用\n* [colima](https://github.com/abiosoft/colima) - macOS（和 Linux）平台上，只需最少设置就可使用的容器运行时\n\n## 云原生网络\n* [cni](https://github.com/containernetworking/cni) - Container Network Interface - 用于Linux容器的网络体系\n* [Cilium](https://github.com/cilium/cilium) - Cilium用于在应用程序容器或进程等应用程序工作负载之间提供并透明地保护网络连接和负载平衡\n\n## 自动化&配置\n* [Airship](https://github.com/airshipit/treasuremap) - Airship 是一组组件，它们通过一系列描述性的 yaml 文档，来配置和部署和维护Kubernetes环境。\n* [ansible](https://github.com/ansible/ansible) - IT自动化的平台，使系统跟程序更加容易部署\n* [disconf](https://github.com/knightliao/disconf) - 分布式配置管理平台\n* [mgmt](https://github.com/purpleidea/mgmt) - 号称下一代的配置管理平台\n* [QConf](https://github.com/Qihoo360/QConf) - 奇虎的分布式配置管理平台\n* [apollo](https://github.com/ctripcorp/apollo) - 携程框架部门研发的分布式配置中心，能够集中化管理应用不同环境、不同集群的配置，配置修改后能够实时推送到应用端，并且具备规范的权限、流程治理等特性，适用于微服务配置管理场景\n* [BOSH](https://github.com/cloudfoundry/bosh) - Bosh是一款用于发布，部署，生命周期管理以及监控的开源工具\n* [Cadence Workflow](https://github.com/uber/cadence) - Cadence是一种分布式，可扩展，持久且高度可用的编排引擎，可以以可伸缩和弹性的方式执行异步长时间运行的业务逻辑。\n* [CFEngine](https://github.com/cfengine/core) - CFEngine 3是一种流行的开源配置管理系统。其主要功能是提供大规模计算机系统的自动配置和维护。\n* [Chef Infra](https://github.com/chef/chef) - 系统集成框架，旨在为整个基础架构带来配置管理的优势。\n* [Digital Rebar](https://github.com/digitalrebar/provision) - Digital Rebar Platform是一个简单而强大的Golang可执行文件，它提供了一个完整的API驱动的DHCP / PXE / TFTP配置系统。\n* [Foreman](https://github.com/theforeman/foreman) - Foreman是一个免费的开源项目，使您能够轻松自动执行重复性任务，快速部署应用程序，并主动管理您的服务器生命周期，内部部署或云端\n* [Juju](https://github.com/juju/juju) - 简单，安全和稳定的devops工具。 Juju降低了复杂性，提高了生产率。专为管理当今运行在任何地方的复杂应用程序架构而设计\n* [KubeEdge](https://github.com/kubeedge/kubeedge) - KubeEdge是一个开源系统，将本机容器化的应用程序编排和设备管理扩展到Edge上的主机\n* [Kubicorn](https://github.com/kubicorn/kubicorn) - kubicorn是一个免费的开源项目，它解决了Kubernetes基础设施问题，并为用户提供了丰富的golang库以使用基础设施\n* [LinuxKit](https://github.com/linuxkit/linuxkit) - 用于为容器构建安全，便携式和小巧的操作系统的工具包\n* [MAAS](https://github.com/maas/maas) - 在真实服务器上远程自助安装Windows，CentOS，ESXi和Ubuntu 进一个 bare-metal cloud\n* [ManageIQ](https://github.com/ManageIQ/manageiq) - ManageIQ是一个开源管理平台，可提供企业需要的洞察力，控制力和自动化能力，以应对管理混合IT环境的挑战\n* [OpenStack](https://github.com/openstack/openstack) - OpenStack软件可控制整个数据中心的大型计算，存储和网络资源池，这些资源可通过仪表板或通过OpenStack API进行管理\n* [Pulumi](https://github.com/pulumi/pulumi) - Pulumi的 Infrastructure as Code SDK是在任何云上创建和部署使用容器，无服务器功能，托管服务和基础架构的云软件的最简单方法\n* [Puppet](https://github.com/puppetlabs/puppet) - Puppet是Linux，Unix和Windows系统的自动管理引擎，它基于集中式规范执行管理任务（例如添加用户，安装软件包和更新服务器配置）\n* [Rundeck](https://github.com/rundeck/rundeck) - Rundeck是自带Web控制台，命令行工具和 WebAPI 的开源自动化服务。它使您可以轻松地在一组节点上运行自动化任务\n* [SaltStack](https://github.com/saltstack/salt) - SaltStack为大规模的复杂系统管理软件，几分钟之内即可轻松运行，可扩展性足以管理成千上万台服务器，而速度又足以在秒级内完成与其的通信\n* [StackStorm](https://github.com/stackstorm/st2) - StackStorm（又称“ IFTTT for Ops”）是事件驱动的自动化工具，用于自动修复，安全响应，故障排除，部署等\n* [Terraform](https://github.com/hashicorp/terraform) - Terraform使您能够安全且可预测地创建，更改和改善基础架构。它是一个开源工具，将API编码为声明性配置文件，这些文件可以在团队成员之间共享，就像代码一样代码，进行编辑，审阅和版本控制\n* [Portainer](https://github.com/portainer/portainer) - Portainer 是一个轻量级管理UI，允许您轻松管理不同的Docker环境（Docker主机或Swarm集群）\n* [confd](https://github.com/kelseyhightower/confd) - confd是一个轻量级的配置管理工具，通过读取存储在etcd，consul，redis等的数据来保持本地配置文件最新\n\n## 镜像托管\n* [Harbor](https://github.com/goharbor/harbor) - Harbor是一个开源的云原生注册中心，用于存储，签名和扫描容器映像以查找漏洞\n* [Docker Registry](https://github.com/docker/distribution) - 用于打包，发送，存储和内容交付的Docker工具集。\n* [Dragonfly](https://github.com/dragonflyoss/Dragonfly) - Dragonfly是一个基于开源智能P2P的图像和文件分发系统。其目标是解决云原生场景中的所有分发问题\n* [Kraken](https://github.com/uber/kraken) - Kraken是一个基于P2P的Docker Registry，专注于可扩展性和可用性。它专为混合云环境中的Docker映像管理，复制和分发而设计。借助可插拔的后端支持，Kraken可以轻松地集成到现有的Docker Registry设置中作为分发层。\n* [Portus](https://github.com/SUSE/Portus) - Portus是授权服务器并提供了下一代Docker Registry 的用户界面。\t\n* [Quay](https://github.com/quay/quay) - 一个可以构建，存储和分发您的应用程序和容器的平台\n\n## 安全&合规\n* [Shiro](https://github.com/apache/shiro) - 隶属于apache的功能强大的java安全框架\n* [Knox](https://github.com/pinterest/knox) - Knox用于管理其他服务中使用到的秘钥相关信息\n\n## 秘钥管理\n* [CyberArk Conjur](https://github.com/cyberark/conjur) - Conjur为现代基础设施提供秘密管理和机器身份识别\n\n## 监控\n* [Prometheus](https://github.com/prometheus/prometheus) - CNCF项目，用于监控其他系统或服务. 它以给定的时间间隔从目标收集指标，根据规则进行评估，显示结果，如果达到某些监控条件，还可以触发警报\n* [Centreon](https://github.com/centreon/centreon) - 市面上最灵活，最强大的监控软件之一\n* [Cortex](https://github.com/cortexproject/cortex) - 用于 Prometheus 的水平可扩展，高可用，多租户的长期存储介质\n* [Falcon](https://github.com/open-falcon/falcon-plus) - 小米出品的一款企业级、高可用、可扩展的开源监控解决方案\n* [Grafana](https://github.com/grafana/grafana) - 用于Graphite，InfluxDB和Prometheus等的监视、指标分析和仪表板的工具\n* [Graphite](https://github.com/graphite-project/graphite-web) - Graphite 是一种高度可扩展的实时图形系统，可以在廉价硬件上很好地运行\n* [Icinga](https://github.com/Icinga/icinga2) - Icinga是一个监视系统，用于检查网络资源的可用性，通知用户中断并生成性能数据报告\n* [InfluxData](https://github.com/influxdata/influxdb) - go 编写的可扩展的数据存储，用于指标，事件和实时分析\n* [Kiali](https://github.com/kiali/kiali) - Kiali 是一个具有配置 service mesh 能力的 Istio 的可观察性控制台，它可以通过推断拓扑来帮助您了解服务网格的结构，还可以提供网格的运行状况\n* [Nagios](https://github.com/NagiosEnterprises/nagioscore) - Nagios是一个用 C 编写的主机/服务/网络监视程序，包含 CGI，可以通过Web界面查看当前状态，历史记录等。GNU 协议\n* [Netdata](https://github.com/netdata/netdata) - Netdata 可以针对系统或应用进行分布式、实时的性能跟健康监控\n* [NexClipper](https://github.com/NexClipper/NexClipper) - NexClipper 是一种快速简单的 Kubernetes 监控方案\n* [OpenMetrics](https://github.com/OpenObservability/OpenMetrics) - 致力于将 Prometheus 的展现形式变为一种标准\n* [OpenTSDB](https://github.com/OpenTSDB/opentsdb) - 基于 HBase 的分布式、可伸缩的时间序列数据库\n* [Sensu](https://github.com/sensu/sensu) - 一个简单，可延展和可扩展的框架，用于组件您所需的监控系统，目前已经被 sensu-go 项目取代\n* [sysdig](https://github.com/draios/sysdig) - 一款支持 Linux 系统监控，故障排查的原生支持容器的工具\n* [Thanos](https://github.com/thanos-io/thanos) - Thanos 是一组组件，可以组成具有无限存储容量的高可用性系统，能将其无缝添加到现有 Prometheus 之上。\n\n## 日志\n* [log4j](https://github.com/apache/log4j) - apache旗下的老牌日志工具\n* [Fluentd](https://github.com/fluent/fluentd) - Fluentd从各种数据源收集事件并将其写入文件，RDBMS，NoSQL，IaaS，SaaS，Hadoop等\n* [Loki](https://github.com/grafana/loki) - Loki是一个水平可扩展，高可用性，多租户的日志聚合系统，灵感来自Prometheus\n* [Graylog](https://github.com/Graylog2/graylog2-server) - 按照开放标准构建的开源日志平台，可以无缝收集，增强，存储和分析日志数据\n* [Logstash](https://github.com/elastic/logstash) - Logstash是一个开源的服务器端数据处理管道，它同时从多个源中提取数据，对其进行转换，然后将其发送到您最喜欢的“存储”之中\n\n## 测试\n* [selenium](https://github.com/SeleniumHQ/selenium) - 自动化浏览器测试框架\n* [mockito](https://github.com/mockito/mockito) - Java 体系中用于单元测试的最受欢迎的Mocking工具\n\n## 追踪\n* [Jaeger](https://github.com/jaegertracing/jaeger) - Jaeger 受 Dapper 和 OpenZipkin 的启发，是 Uber Technologies 公开发布的分布式跟踪系统\n* [OpenTracing](https://github.com/opentracing/opentracing-go) - OpenTracing由API规范，已实现规范的框架和库以及项目文档组成\n* [OpenTelemetry](https://github.com/open-telemetry/opentelemetry-specification) - OpenTelemetry是OpenTracing和OpenCensus项目的下一个主要版本，OpenTelemetry由一组集成的API，库以及agent 组成。 这些组件用于生成，收集和描述有关分布式系统的 telemetry 信息\n* [Pinpoint](https://github.com/naver/pinpoint) - Pinpoint是一个APM（应用程序性能管理）工具，适用于用Java / PHP编写的大型分布式系统。灵感源自 google dapper 论文。Pinpoint提供了一种解决方案，通过跟踪分布式应用程序之间的事务，帮助分析系统的整体结构以及它们中的组件如何相互连接。\n* [SkyWalking](https://github.com/apache/skywalking) - 分布式系统下的 APM 工具（Application performance monitor），专为微服务，云原生和基于容器（Docker，K8s，Mesos）架构而设计。\n* [SOFATracer](https://github.com/sofastack/sofa-tracer) - SOFATracer 是一个用于分布式系统调用跟踪的组件，通过统一的 traceId 将调用链路中的各种网络调用情况以日志的方式记录下来，以达到透视化网络调用的目的。这些日志可用于故障的快速发现，服务治理等。\n* [spring-cloud-sleuth](https://github.com/spring-cloud/spring-cloud-sleuth) - Spring Cloud Sleuth是Spring Cloud的分布式跟踪工具。它借鉴了Dapper，Zipkin和HTrace。\n* [Zipkin](https://github.com/openzipkin/zipkin) - Zipkin是一种分布式跟踪系统。它有助于收集解决服务体系结构中的延迟问题所需的计时数据。功能包括收集和查找此类数据\n\n## 混沌工程\n* [Chaos Mesh](https://github.com/pingcap/chaos-mesh) - Kubernetes的混沌工程平台\n* [Chaos Toolkit](https://github.com/chaostoolkit/chaostoolkit) - 为社区所需的各种形式的混沌工程工具提供免费，开放和社区驱动的工具包和API\n* [Chaosblade](https://github.com/chaosblade-io/chaosblade) - 一款简单易用、功能强大的混沌实验注入工具\n* [chaoskube](https://github.com/linki/chaoskube) - chaoskube定期随机性的杀掉K8s集群中的pod\n* [Litmus](https://github.com/litmuschaos/litmus) - Litmus是Kubernetes的e2e测试和混沌工程框架，专注于 stateful workloads\n* [PowerfulSeal](https://github.com/bloomberg/powerfulseal) - PowerfulSeal会为您的Kubernetes群集添加混乱，以便您可以尽早检测系统中的问题。它会杀死目标 pod 并且使虚拟机变得不稳定。遵循[混沌工程原理](http://principlesofchaos.org/)，灵感源自[Chaos Monkey](https://github.com/Netflix/chaosmonkey)\n\n## 插件&工具\n* [guava](https://github.com/google/guava) - Google 出品的非常好用的Java工具包\n* [netty](https://github.com/netty/netty) - 事件驱动的支持异步的网络框架\n* [okhttp](https://github.com/square/okhttp) - 适用于 Android，Kotlin 和 Java的 HTTP 客户端\n* [hystrix](https://github.com/Netflix/Hystrix) - Netflix出品的熔断器，目前已停止更新\n* [Sentinel](https://github.com/alibaba/Sentinel) - (轻量级的流量控制、熔断降级 Java 库\n* [resilience4j](https://github.com/resilience4j/resilience4j) - 轻量级的熔断器，设计上受到Hystrix的启发，但专为Java 8和函数式编程而设计\n* [uid-generator](https://github.com/baidu/uid-generator) - 百度出品的基于snowflake的唯一Id生成器\n* [fastjson](https://github.com/alibaba/fastjson) - 阿里出品的解析/生成JSON的java框架\n* [swagger](https://github.com/swagger-api/swagger-ui) - java API管理工具\n* [protobuf](https://github.com/google/protobuf) - google出品的平台无关，语言无关的序列化工具\n* [cqengine](https://github.com/npgall/cqengine) - 可以在Java的collection中进行SQL-like查询的工具\n* [jetcache](https://github.com/alibaba/jetcache) - 阿里出品的Java缓存框架，\"用起来比Spring Cache更方便\"\n* [RxJava](https://github.com/ReactiveX/RxJava) - RxJava 是 Reactive Extensions 的 Java VM 实现：该库用于通过使用可观察的序列来组成异步和基于事件的程序\n* [Vert.x](https://github.com/eclipse/vert.x) - JVM上用于开发reactive程序的工具包\n* [Akka](https://github.com/akka/akka) - 在JVM上构建高度并发，分布式和弹性消息驱动的应用程序\n* [mapper](https://github.com/abel533/Mapper) - MyBatis 通用 Mapper\n* [tcc-transaction](https://github.com/changmingxie/tcc-transaction) - TCC型事务java实现\n* [druid](https://github.com/alibaba/druid) - 阿里出品的号称\"为监控而生\"的数据库连接池\n* [fast-syntax-highlighting](https://github.com/zdharma/fast-syntax-highlighting) - zsh的语法高亮插件\n* [nosqlclient](https://github.com/nosqlclient/nosqlclient) - mongodb的客户端\n* [mybatis-generator-gui](https://github.com/zouzg/mybatis-generator-gui) mybatis generator的GUI工具\n* [git_commit_template](https://github.com/joelparkerhenderson/git_commit_template) - 一个git message的模板\n* [gitignore.io](https://github.com/joeblau/gitignore.io) - 可以方便的自定义.gitignore文件\n* [shadowsocks](https://github.com/shadowsocks) - 这个无需介绍了，懂的自然都懂\n* [source-code-pro](https://github.com/adobe-fonts/source-code-pro) - Adobe 开源的编程字体\n* [antlr4](https://github.com/antlr/antlr4) - ANTLR是一个功能强大的解析器生成器，用于读取、处理、执行、转换结构化文本或二进制文件\n* [etcdkeeper](https://github.com/evildecay/etcdkeeper) - 一款 etcd 的 web ui 工具，支持 etcd v3\n* [kops](https://github.com/kubernetes/kops) - Kubernetes Operations（kops） - 生产级的K8s安装，升级和管理工具\n* [boot2docker](https://github.com/boot2docker/boot2docker) - Boot2Docker是一个轻量级Linux发行版，专门用于运行Docker容器。它可以完全在RAM中运行，下载约45MB并启动速度很快\n* [FiraCode](https://github.com/tonsky/FiraCode) - 适合编程的等宽开源字体，有retina版本\n* [error-prone](https://github.com/google/error-prone) - Google出品的一款Java静态分析工具，可以在编译时捕获常见错误\n* [Collabobot](https://github.com/AlibabaDR/Collabobot) - Github机器人，自动标签管理，自动问题翻译，自动周报等\n* [MikuTools](https://github.com/Ice-Hazymoon/MikuTools) - 一个轻量的网站工具集合\n* [solo](https://github.com/b3log/solo) - 一款小而美的博客系统，专为程序员设计\n* [JustAuth](https://github.com/justauth/JustAuth) - 史上最全的整合第三方登录的开源库\n* [Bistoury](https://github.com/qunarcorp/bistoury) - Bistoury 是去哪儿网开源的一个对应用透明，无侵入的java应用诊断工具，用于提升开发人员的诊断效率和能力。\n* [wrk](https://github.com/wg/wrk) - 一款 HTTP 基准测试工具\n* [common config](https://github.com/adben/config) - 一些常见工具的优化配置，zsh，idea，git 等\n* [asciinema](https://github.com/asciinema/asciinema) - 一款记录终端操作并将其分享的工具，地址在 https://asciinema.org/\n* [Katacoda](https://github.com/katacoda) - 面向软件开发人员的交互式技术学习平台（https://www.katacoda.com/）\n* [docker-slim](https://github.com/docker-slim/docker-slim) - 一款给 docker image 瘦身的工具\n* [DataX](https://github.com/alibaba/DataX) - 阿里云开源离线同步工具\n* [nmon](http://nmon.sourceforge.net/pmwiki.php) - Linux 下一款精巧的监控小工具\n* [sysbench](https://github.com/akopytov/sysbench) - 一个基于 LuaJIT 的的多线程基准测试工具，可以测试 CPU、IO  以及数据库等\n* [emoji-cheat-sheet](https://github.com/ikatyang/emoji-cheat-sheet) - 记录了所有 emoji 在 github 上的写法\n* [autojump](https://github.com/wting/autojump) - linux 系统下一款可以快速跳跃目录的工具\n* [pyenv](https://github.com/pyenv/pyenv) - 一个简单的 Python 环境管理工具\n* [z](https://github.com/rupa/z) - 一款可让你快速跳转到过去或最近经常访问的目录的命令行工具\n* [async-profiler](https://github.com/jvm-profiling-tools/async-profiler) - 一款功能强大的 profile 工具，可以生成火焰图\n* [SwitchHosts](https://github.com/oldj/SwitchHosts) - SwitchHosts 是一个管理 hosts 文件的应用，可以定时更新 hosts 文件\n* [GitHub520](https://github.com/521xueweihan/GitHub520) - 每日定时更新 github 的 ip 地址\n* [iotop](http://guichaz.free.fr/iotop/) - 查看硬盘上 IO 情况的小工具\n* [protractor](https://github.com/angular/protractor) - Angular 和 AngularJS 应用程序的端到端测试框架\n* [DevToys](https://github.com/ObuchiYuki/DevToysMac) - 支持离线，一款常用工具的“瑞士军刀”，包含文件格式转换、PDF 生成等功能\n* [ASCII Table](https://github.com/vdmeer/asciitable) - 可以在 Java 的控制台中输出表格\n* [Atom](https://github.com/atom/atom) - GitHub 官方文本编辑器\n\n## 相关教程\n* [Knowledge Graph](https://github.com/gocn/knowledge) - Go社区的知识图谱\n* [bash-guide](https://github.com/Idnan/bash-guide) - Bash相关命令教程\n* [p3c](https://github.com/alibaba/p3c) - 阿里巴巴Java代码规范\n* [JCFInternals](https://github.com/CarpenterLee/JCFInternals) - Java collection讲解\n* [elasticsearch-definitive-guide](https://github.com/elastic/elasticsearch-definitive-guide) - 汉化elasticsearch权威指南\n* [zju-icicles](https://github.com/QSCTech/zju-icicles) - 浙江大学课程攻略共享计划\n* [deep-learning](https://github.com/Robinwho/Deep-Learning) - 深度学习/人工智能/机器学习资料汇总\n* [pythontutorial3](https://github.com/sixu05202004/pythontutorial3) - python 3.5.1 tutorial中文版\n* [liaoxuefeng](https://www.liaoxuefeng.com/) - 廖雪峰的 git，python，javascript 教程\n* [git-tutorial](https://backlog.com/git-tutorial/cn/) - 号称是猴子都能看懂的 git 教程\n* [java8-tutorial](https://github.com/winterbe/java8-tutorial) - java 8教程\n* [Linux-Tutorial](https://github.com/judasn/Linux-Tutorial) - java程序员眼中的linux\n* [free-programming-books](https://github.com/justjavac/free-programming-books-zh_CN) - 免费的计算机编程类中文书籍\n* [docker-handbook](https://github.com/rootsongjc/docker-handbook) - 宋净超同学出品的docker handbook\n* [kubernetes-handbook](https://github.com/rootsongjc/kubernetes-handbook) - 宋净超同学出品的kubernetes中文指南\n* [kubernetes-handbook](https://github.com/feiskyer/kubernetes-handbook) - feiskyer出品的Kubernetes指南\n* [cni](https://github.com/CloudNativeInfra/cni) - The book Cloud Native Infrastructure\n* [spring-boot-examples](https://github.com/souyunku/spring-boot-examples) - Spring Boot 学习教程\n* [How-To-Ask-Questions-The-Smart-Way](https://github.com/ryanhanwu/How-To-Ask-Questions-The-Smart-Way) - 提问的智慧\n* [SpringCloudBook](https://github.com/dyc87112/SpringCloudBook) - Spring Cloud微服务实战\n* [java-design-patterns](https://github.com/iluwatar/java-design-patterns) - Java实现的各种设计模式\n* [architecture.wechat-tencent](https://github.com/davideuler/architecture.wechat-tencent) - 互联网公司架构: 微信技术架构， 腾讯技术架构\n* [skill-map](https://github.com/TeamStuQ/skill-map) - 程序员技能图谱\n* [advanced-java](https://github.com/doocs/advanced-java) - 互联网 Java 工程师进阶知识完全扫盲\n* [gopl-zh](https://github.com/golang-china/gopl-zh) - Go语言圣经中文版\n* [prometheus_practice](https://github.com/songjiayang/prometheus_practice) - 包括 Prometheus 安装，基础监控，常用 exporter，性能优化和大量实战经验\n* [和我一步步部署 kubernetes 集群](https://github.com/opsnull/follow-me-install-kubernetes-cluster) - 本系列文档介绍使用二进制部署最新 kubernetes v1.10.4 集群的所有步骤，而不是使用 kubeadm 等自动化方式来部署集群\n* [Go四十二章经](https://github.com/ffhelicopter/Go42) - 作者前言 : 纯粹是因为开发过程中碰到过的一些问题，踩到过的一些坑，感觉在 Go 语言学习使用过程中，有必要深刻理解这门语言的核心思维、清晰掌握语言的细节规范以及反复琢磨标准包代码设计模式，于是才有了这本书\n* [Netty learning](https://github.com/code4craft/netty-learning) - Netty源码解析\n* [git-tips](https://github.com/521xueweihan/git-tips) - Git的奇技淫巧\n* [practical-programming-books](https://github.com/EZLippi/practical-programming-books) - 收录比较实用的计算机相关技术书籍，可以在短期之内入门的简单实用教程、一些技术网站以及一些写的比较好的博文\n* [what-happens-when-k8s](https://github.com/jamiehannaford/what-happens-when-k8s) - 讲解了当 k8s 运行的时候发生了什么\n* [God-Of-BigData](https://github.com/wangzhiwubigdata/God-Of-BigData) - 大数据成神之路\n* [chinese-copywriting-guidelines](https://github.com/sparanoid/chinese-copywriting-guidelines) - 中文文案排版指南\n* [istio-handbook](https://github.com/servicemesher/istio-handbook) - Istio 服务网格进阶实战\n* [分布式系统模式术语表](https://github.com/dreamhead/patterns-of-distributed-systems) - 分布式系统模式中文版一书中的技术术语表\n* [google style guide](https://github.com/google/styleguide) - google 的各种代码风格指南\n* [Docker 从入门到实践](https://yeasy.gitbook.io/docker_practice/) - Docker 从入门到实践\n\n## 文档汉化\n* [kafka-doc-zh](https://github.com/apachecn/kafka-doc-zh/) - Kafka 中文文档\n* [redis](https://github.com/huangz1990/redis) - Redis Command Reference全文的中文翻译版\n* [spring-5-framework-doc](https://github.com/lfvepclr/spring-5-framework-doc) - Spring 5文档翻译\n* [java-nio-zh](https://github.com/avenwu/java-nio-zh) - 汉化的Java NIO教程\n* [istio中文文档](https://github.com/doczhcn/istio) - Istio官方文档中文版\n* [build-web-application-with-golang](https://github.com/astaxie/build-web-application-with-golang) - 包含多语言(包含中文)版本的GO教程\n* [Netty In Action 中文版](https://github.com/ReactivePlatform/netty-in-action-cn) - Netty In Action中文版\n* [Mastering_Go_ZH_CN](https://github.com/hantmac/Mastering_Go_ZH_CN) - 《Mastering GO》中文译本，暂时命名为《玩转 GO》\n* [On Java 8](https://github.com/LingCoder/OnJava8) - 《On Java 8》中文版，又名《Java编程思想》 第5版\n* [effective-java-3rd-chinese](https://github.com/sjsdfg/effective-java-3rd-chinese/) - effective-java-3rd 中文版\n* [提問的智慧](https://github.com/ryanhanwu/How-To-Ask-Questions-The-Smart-Way) - How To Ask Questions The Smart Way 的中文版\n* [Google 开源项目风格指南](https://github.com/zh-google-styleguide/zh-google-styleguide) - Goolge 的开源项目代码风格指南\n\n## 论文\n* [The Raft Consensus Algorithm](https://raft.github.io/) - Raft 共识算法\n* [raft-zh_cn](https://github.com/maemual/raft-zh_cn/blob/master/raft-zh_cn.md) - Raft 一致性算法论文的中文翻译\n\n## 面试相关\n* [Back-End-Developer-Interview-Questions](https://github.com/arialdomartini/Back-End-Developer-Interview-Questions) - 后端开发面试题\n* [The-Art-Of-Programming-By-July](https://github.com/julycoding/The-Art-Of-Programming-By-July) - July的<<编程之法：面试和算法心得>>\n* [hunter](https://github.com/lietoumai/Hunter) - 面试技巧相关\n* [interview-notebook](https://github.com/CyC2018/Interview-Notebook) - 技术面试需要掌握的基础知识\n* [interviews](https://github.com/kdn251/interviews) - 找工作需要了解的基础技术\n* [2018-Java-Interview](https://github.com/xbox1994/2018-Java-Interview) - 2018年几个大厂的面试宝典\n* [interview_internal_reference](https://github.com/0voice/interview_internal_reference) - 2019年最新总结，阿里，腾讯，百度，美团，头条等技术面试题目，以及答案，专家出题人分析汇总\n* [JavaFamily](https://github.com/AobingJava/JavaFamily) - 互联网一线大厂面试+学习指南\n* [tech-interview-handbook](https://github.com/yangshun/tech-interview-handbook) - 帮你在面试里露脸的面试集锦\n\n## 其他资源\n* [awesome-java](https://github.com/akullpp/awesome-java) - 整理了相当多java生态圈的相关资源\n* [awesome-chaos-engineering](https://github.com/dastergon/awesome-chaos-engineering) - 收集了优秀的混沌工程相关的信息\n* [awesome-scalability](https://github.com/binhnguyennus/awesome-scalability) - 整理了相当多的高扩展，高可用，高性能等的设计模式\n* [awesome-blockchain-cn](https://github.com/chaozh/awesome-blockchain-cn) - 收集所有区块链(BlockChain)技术开发相关资料，包括Fabric和Ethereum开发资料\n* [awesome-readme](https://github.com/matiassingers/awesome-readme) - 收集了github 上很多写的很棒的 readme\n* [awesome-kubernetes](https://github.com/ramitsurana/awesome-kubernetes) - 优秀的 k8s 资料集\n* [awesome-cloud-native](https://github.com/rootsongjc/awesome-cloud-native) - cloud native 的工具，软件，教程的精选列表\n* [awesome-go-cn](https://github.com/jobbole/awesome-go-cn) - Go 资源大全中文版， 内容包括：Web框架、模板引擎、表单、身份认证、数据库、ORM框架、图片处理、文本处理、自然语言处理、机器学习、日志、代码分析、教程和（电子）书等\n* [awesome-architecture](https://github.com/toutiaoio/awesome-architecture) - 架构师技术图谱，助你早日成为架构师\n* [cloud-native-slides-share](https://github.com/rootsongjc/cloud-native-slides-share) - 收集了大量的cloud native相关的大会资料，开源书籍以及类似信息\n* [IntelliJ-IDEA-Tutorial](https://github.com/judasn/IntelliJ-IDEA-Tutorial) - IDEA教程\n* [tenant-point](https://github.com/soulteary/tenant-point) - 租房要点，适用于北上广深杭\n* [English-level-up-tips-for-Chinese](https://github.com/byoungd/English-level-up-tips-for-Chinese) - 高效学习英语\n* [lianjia-beike-spider](https://github.com/jumper2014/lianjia-beike-spider) - 主要城市的房价爬虫\n* [chinese-copywriting-guidelines](https://github.com/sparanoid/chinese-copywriting-guidelines) - 中文文案排版指南\n* [xg2xg](https://github.com/jhuangtw-dev/xg2xg) - 前 google 员工整理的 google 技术栈\n* [architecture.of.internet-product](https://github.com/davideuler/architecture.of.internet-product) - 互联网公司技术架构，微信/淘宝/微博/腾讯/阿里/美团点评/百度/Google/Facebook/Amazon/eBay的架构\n* [rpc-benchmark](https://github.com/hank-whu/rpc-benchmark) - java rpc benchmark，灵感源自 https://www.techempower.com/benchmarks/\n* [hacker-laws-zh](https://github.com/nusr/hacker-laws-zh) - 对开发人员有用的定律、理论、原则和模式\n* [golang-open-source-projects](https://github.com/hackstoic/golang-open-source-projects) - 为互联网IT人打造的中文版awesome-go\n* [advanced-java](https://github.com/doocs/advanced-java) - 互联网 Java 工程师进阶知识完全扫盲：涵盖高并发、分布式、高可用、微服务、海量数据处理等领域知识，后端同学必看，前端同学也可学习\n* [LeetCode](https://github.com/azl397985856/leetcode) - 一位 github 用户记录自己的 leetcode 解题之路\n* [LeetCodeAnimation](https://github.com/MisterBooo/LeetCodeAnimation) - 用动画的形式呈现解LeetCode题目的思路\n* [Google Cloud Platform Icon](https://cloud.google.com/icons) - 架构图的解决方案图标\n* [developer-roadmap](https://github.com/kamranahmedse/developer-roadmap) - 开发人员技术栈成长之路\n* [virtual-environments](https://github.com/actions/virtual-environments) - Github Action 使用的环境的具体信息\n\n## 优秀blog\n* [TiDB博客](https://pingcap.com/blog-cn/) - TiDB官网的博客\n* [阿里中间件](http://jm.taobao.org/) - 阿里中间件团队博客\n* [Tim Yang](https://timyang.net/) - 后端技术 - Tim Yang\n* [许令波](https://github.com/xulingbo/xulingbo.github.io/issues/) - 许令波的 Issue\n* [martinfowler](https://martinfowler.com/) - martin fowler的博客\n* [美团点评技术团队](https://tech.meituan.com/) - 美团点评技术团队的博客\n* [CoolShell](https://coolshell.cn/) - 左耳朵耗子的酷壳\n* [并发编程网](http://ifeve.com/concurrency-site/) - 并发编程网\n* [今日头条技术博客](https://techblog.toutiao.com/) - 今日头条技术博客\n* [developerworks](https://www.ibm.com/developerworks/cn/) - IBM developerworks\n* [伪架构师](https://blog.fleeto.us/) - 崔秀龙的博客\n* [芋道源码](http://www.iocoder.cn/) - 作者通过阅读大量源码拆解，分析各种常见框架\n* [Draveness's Blog](https://draveness.me/) - 面向信仰编程\n* [Tom Hombergs](https://github.com/thombergs/code-examples/tree/master/spring-boot/spring-boot-testing) - spring boot testing\n* [Matt's Blog](https://matt33.com/) - 无意中看到的一位高手的博客\n* [fangzhipeng](https://www.fangzhipeng.com) - 方志朋的博客\n* [Piotr's Blog](https://piotrminkowski.wordpress.com) - piotr 的博客\n* [jeremy-xu](https://jeremy-xu.oschina.io/) - jeremy的技术点滴\n* [编程小梦](https://blog.bcmeng.com/) - 编程小梦的博客\n* [Microservice Architecture](https://microservices.io/) - Chris Richardson 创立的撰写微服务文章的网站\n* [数据库内核月报](http://mysql.taobao.org/monthly/) - 阿里 SQL 的数据库内核月报\n* [小米信息部技术团队](https://xiaomi-info.github.io/) - 小米信息部技术团队的技术博客\n* [伴鱼技术团队](https://tech.ipalfish.com/blog/) - 伴鱼技术团队的技术博客\n* [夜空](https://www.jianshu.com/u/64f062dc305f) - 夜空的简书\n* [bugstack虫洞栈](https://bugstack.cn/) - 一个看着靠谱的小哥的技术沉淀\n* [Jiekun's Blog](https://jiekun.dev/posts/) - 一位爱学习的后辈的技术博客\n* [易水寒](https://www.liuyj.topa/) - 一名从事后端 Java 开发工作的 90 后程序员的技术博客\n* [康瑞部落](http://www.kangry.net/blog/) - 瑞远大师的博客\n\n## 游戏\n* [RetroArch](https://github.com/libretro/RetroArch) - 跨平台游戏模拟器\n* [Citra](https://github.com/citra-emu/citra) - 3DS 模拟器\n* [Dolphin](https://github.com/dolphin-emu/dolphin) - Wii 模拟器\n* [Cemu](http://cemu.info/) - Wii U 模拟器\n* [Ryujinx](https://github.com/Ryujinx/Ryujinx) - 任天堂 Switch 模拟器\n* [PPSSPP](https://github.com/hrydgard/ppsspp) - PSP 模拟器\n* [ePSXe](http://www.epsxe.com/) - PS模拟器\n* [PCSX2](https://pcsx2.net/) - PS2模拟器\n* [RPCS3](https://github.com/RPCS3/rpcs3) - PS3模拟器\n* [RetroPie](https://github.com/RetroPie) - 一个模拟器合集，可以将树莓派改造成一个模拟器\n* [lakka](http://www.lakka.tv/get/) - Lakka，一款树莓派可用的模拟器集合，界面很像 PS4\n* [ResidentEvi HD](https://github.com/MoArtis/ResidentEvilSeamlessHdProject/issues) - 老版生化危机的 HD 项目",
    "created_at": "2025-03-11T06:58:59Z",
    "updated_at": "2025-03-15T15:20:55Z",
    "labels": [],
    "url": "https://github.com/kaozb/ai-arctl/issues/12"
  },
  {
    "id": 22,
    "title": "35页综述：Agentic RAG七大架构首次曝光！ - 53AI-AI生产力的卓越领导者（大模型知识库|大模型训练|智能体开发）",
    "content": "35页综述：Agentic RAG七大架构首次曝光！ - 53AI-AI生产力的卓越领导者（大模型知识库|大模型训练|智能体开发）\n===============  \n\n[![Image 1](https://static.53ai.com/assets/static/images/logo.png)](https://www.53ai.com/)\n\n ![Image 2](https://static.53ai.com/uploads/20240311/eb21a9e0409ab946254c64427055a5fa.png)支持私有云部署\n\n[首页](https://www.53ai.com/)\n\n[产品服务](https://www.53ai.com/product.html)\n\n*   开箱即用的企业大模型应用平台\n    \n    ![Image 3](https://static.53ai.com/uploads/20240529/f87e241ff2dd3924718463507d38fcd1.png)\n    \n    工作+AI  \n    大模型提升全员工作效率\n    \n     [![Image 4](https://static.53ai.com/uploads/20240529/7f7fb3a563c7530b68e88add9f84a335.png) ![Image 5](https://static.53ai.com/uploads/20240529/39185f663b28883aa8de355676d00838.png) 工作对话](https://www.53ai.com/product/gongzuoduihua) [![Image 6](https://static.53ai.com/uploads/20240529/fef10f390be59cbf4758c8bdc29b543b.png) ![Image 7](https://static.53ai.com/uploads/20240529/a4de80d25bb700416c04905f92e5d89b.png) 内容创作](https://www.53ai.com/product/neirongchuangzuo) [![Image 8](https://static.53ai.com/uploads/20240529/87c26e340e1ab72d144f01222b54416a.png) ![Image 9](https://static.53ai.com/uploads/20240529/088ab85a974ebb3c60b5907ef75d3852.png) 方案撰写](https://www.53ai.com/product/zhinengwendang) [![Image 10](https://static.53ai.com/uploads/20240529/3b2ecb11c2ed3414aa1dd9f060c9b07e.png) ![Image 11](https://static.53ai.com/uploads/20240529/818975be79b3c7bf409d26750da48dd2.png) 魔法菜单](https://www.53ai.com/product/mofacaidan)\n    \n    ![Image 12](https://static.53ai.com/uploads/20240529/e3d1b654d90fe4a02dfda2b7bda13b74.png)\n    \n    业务+AI  \n    大模型掌握企业知识与流程\n    \n     [![Image 13](https://static.53ai.com/uploads/20240529/1815cb1b02a7c713455d9ea21c04a54d.png) ![Image 14](https://static.53ai.com/uploads/20240529/e23b099525c800ed821a4f49287d5339.png) 智能问答](https://www.53ai.com/product/jiqiren) [![Image 15](https://static.53ai.com/uploads/20240529/de8fcfa0c133a540d928bb0105c87874.png) ![Image 16](https://static.53ai.com/uploads/20240529/55787c1b82bb850ad6b118645bec7ced.png) 拓展能力](https://www.53ai.com/product/jinengtuozhan) [![Image 17](https://static.53ai.com/uploads/20240529/0652389e299c43463020c0659bedc02b.png) ![Image 18](https://static.53ai.com/uploads/20240529/cc1c95ffbf6069fba0f6977b36e16093.png) 私有模型](https://www.53ai.com/product/siyoumoxing)\n    \n    ![Image 19](https://static.53ai.com/uploads/20240529/3294c40ae237a976140829e8c3e481c6.png)\n    \n    AIx业务  \n    大模型驱动产品智能化改造\n    \n     [![Image 20](https://static.53ai.com/uploads/20240529/119e72b8cc4579450b59bd6bbdb0f504.png) ![Image 21](https://static.53ai.com/uploads/20240529/d440209b9c1afda99d91101920ce06a0.png) 应用智改](https://www.53ai.com/product/zijianyingyong) [![Image 22](https://static.53ai.com/uploads/20240531/8e80a680ffd13c17b19ac753bd344d58.png) ![Image 23](https://static.53ai.com/uploads/20240531/8a55810e147bec67f510cb64241d2118.png) LLMFlow](https://www.53ai.com/product/LLMFlow) [![Image 24](https://static.53ai.com/uploads/20240531/b3d4c54aadc1a3fa88de3080f1429c53.png) ![Image 25](https://static.53ai.com/uploads/20240531/454df06679465b9ed7e517a33c515648.png) ChatBI](https://www.53ai.com/product/ChatBI) [![Image 26](https://static.53ai.com/uploads/20240529/48ff0070564e7e5204ce01302f8639ed.png) ![Image 27](https://static.53ai.com/uploads/20240529/f56b3b28ed3bdf19179f29de6d181e88.png) 统管平台](https://www.53ai.com/product/xitongguanli)\n    \n\n*   大模型咨询\n    \n    [![Image 28](https://static.53ai.com/uploads/20240529/d84e48f5bedc6e502af93d083ba4f487.jpg) Consulting AI咨询与内训 了解更多 \\>](https://www.53ai.com/consulting.html)\n    \n*   大模型开发\n    \n    [![Image 29](https://static.53ai.com/uploads/20250210/30a846a48c2b2f72efe6633d3d32efb4.jpg) DeepSeek 本地部署与开发 了解更多 \\>](https://www.53ai.com/fine-tuning.html)\n    \n\n[解决方案](https://www.53ai.com/solution.html)\n\n*   场景解决方案\n    \n    [![Image 30: 【智能问答】解决方案](https://static.53ai.com/assets/static/images/solution_icon_1.png) 【智能问答】解决方案 让大模型掌握企业的知识和流程](https://www.53ai.com/solution.html#solution-148)[![Image 31: 【应用智改】解决方案](https://static.53ai.com/assets/static/images/solution_icon_2.png) 【应用智改】解决方案 让大模型融入企业的产品和业务](https://www.53ai.com/solution.html#solution-149)[![Image 32: 【智能工单】解决方案](https://static.53ai.com/assets/static/images/solution_icon_3.png) 【智能工单】解决方案 让大模型创建和受理业务工单](https://www.53ai.com/solution.html#solution-150)\n    \n\n[AI知识库](https://www.53ai.com/news.html)\n\n[前沿技术](https://www.53ai.com/news/qianyanjishu) [Agent框架](https://www.53ai.com/news/agentplatform) [行业应用](https://www.53ai.com/news/hangyeyingyong) [企业经营](https://www.53ai.com/news/qiyejingying)\n\n[结构化提示词](https://www.53ai.com/prompt.html)\n\n[LangGPT之路](https://www.53ai.com/prompt/LangGPTzhilu) [提示词合集](https://www.53ai.com/prompt/Sorayanjiufenxi) [应用案例](https://www.53ai.com/prompt/tongwangAGIzhilu) [社区达人](https://www.53ai.com/prompt/shequndaren)\n\n[关于我们](https://www.53ai.com/about.html)\n\n[公司介绍](https://www.53ai.com/about/introduction) [渠道合作](https://www.53ai.com/about/cooperation)\n\n[登录](https://chat.53ai.com/) [预约演示](https://www.53ai.com/trial.html)\n\n![Image 33](https://static.53ai.com/assets/static/images/menu_icon.svg)\n\n![Image 34](https://static.53ai.com/assets/static/images/menu_close.png)\n\n*   [首页](https://www.53ai.com/)\n*   [产品服务](javascript:)\n*   [解决方案](javascript:)\n*   [AI知识库](javascript:)\n*   [结构化提示词](javascript:)\n*   [关于我们](javascript:)\n\n开箱即用的企业大模型应用平台\n\n![Image 35](https://static.53ai.com/uploads/20240529/f87e241ff2dd3924718463507d38fcd1.png)\n\n工作+AI\n\n[![Image 36](https://static.53ai.com/uploads/20240529/39185f663b28883aa8de355676d00838.png)工作对话](https://www.53ai.com/product/gongzuoduihua)[![Image 37](https://static.53ai.com/uploads/20240529/a4de80d25bb700416c04905f92e5d89b.png)内容创作](https://www.53ai.com/product/neirongchuangzuo)[![Image 38](https://static.53ai.com/uploads/20240529/088ab85a974ebb3c60b5907ef75d3852.png)方案撰写](https://www.53ai.com/product/zhinengwendang)[![Image 39](https://static.53ai.com/uploads/20240529/818975be79b3c7bf409d26750da48dd2.png)魔法菜单](https://www.53ai.com/product/mofacaidan)\n\n![Image 40](https://static.53ai.com/uploads/20240529/e3d1b654d90fe4a02dfda2b7bda13b74.png)\n\n业务+AI\n\n[![Image 41](https://static.53ai.com/uploads/20240529/e23b099525c800ed821a4f49287d5339.png)智能问答](https://www.53ai.com/product/jiqiren)[![Image 42](https://static.53ai.com/uploads/20240529/55787c1b82bb850ad6b118645bec7ced.png)拓展能力](https://www.53ai.com/product/jinengtuozhan)[![Image 43](https://static.53ai.com/uploads/20240529/cc1c95ffbf6069fba0f6977b36e16093.png)私有模型](https://www.53ai.com/product/siyoumoxing)\n\n![Image 44](https://static.53ai.com/uploads/20240529/3294c40ae237a976140829e8c3e481c6.png)\n\nAIx业务\n\n[![Image 45](https://static.53ai.com/uploads/20240529/d440209b9c1afda99d91101920ce06a0.png)应用智改](https://www.53ai.com/product/zijianyingyong)[![Image 46](https://static.53ai.com/uploads/20240531/8a55810e147bec67f510cb64241d2118.png)LLMFlow](https://www.53ai.com/product/LLMFlow)[![Image 47](https://static.53ai.com/uploads/20240531/454df06679465b9ed7e517a33c515648.png)ChatBI](https://www.53ai.com/product/ChatBI)[![Image 48](https://static.53ai.com/uploads/20240529/f56b3b28ed3bdf19179f29de6d181e88.png)统管平台](https://www.53ai.com/product/xitongguanli)\n\n[大模型咨询](https://www.53ai.com/consulting.html)\n\n[大模型开发](https://www.53ai.com/fine-tuning.html)\n\n场景解决方案\n\n[![Image 49](https://static.53ai.com/assets/static/images/solution_icon_1.png) 【智能问答】解决方案](https://www.53ai.com/solution.html#solution-148)\n\n[![Image 50](https://static.53ai.com/assets/static/images/solution_icon_2.png) 【应用智改】解决方案](https://www.53ai.com/solution.html#solution-149)\n\n[![Image 51](https://static.53ai.com/assets/static/images/solution_icon_3.png) 【智能工单】解决方案](https://www.53ai.com/solution.html#solution-150)\n\n[前沿技术](https://www.53ai.com/news/qianyanjishu)[Agent框架](https://www.53ai.com/news/agentplatform)[行业应用](https://www.53ai.com/news/hangyeyingyong)[企业经营](https://www.53ai.com/news/qiyejingying)\n\n[LangGPT之路](https://www.53ai.com/prompt/LangGPTzhilu)[提示词合集](https://www.53ai.com/prompt/Sorayanjiufenxi)[应用案例](https://www.53ai.com/prompt/tongwangAGIzhilu)[社区达人](https://www.53ai.com/prompt/shequndaren)\n\n[公司介绍](https://www.53ai.com/about/introduction)[渠道合作](https://www.53ai.com/about/cooperation)\n\n ![Image 52: AI知识库](https://static.53ai.com/uploads/20250210/aec076a60258b0cc07078c8ea7dff92c.webp)\n\n53AI知识库\n\n学习大模型的前沿技术与行业应用场景\n\n[立即咨询](javascript:;) [预约演示](javascript:;)\n\n[首页](https://www.53ai.com/) [AI知识库](https://www.53ai.com/news.html) [前沿技术](https://www.53ai.com/news/qianyanjishu) [RAG技术](https://www.53ai.com/news/RAG)\n\n![Image 53](https://static.53ai.com/assets/static/images/edit-icon.png)我要投稿\n\n35页综述：Agentic RAG七大架构首次曝光！\n==========================\n\n发布日期：2025-02-01 10:55:59 浏览次数： 2005 来源：探索AGI\n\n推荐语\n\n探索人工智能新边界，Agentic RAG技术深度解析。  \n  \n核心内容：  \n1\\. Agentic RAG的必要性与传统LLMs的局限  \n2\\. RAG技术的发展历程与Agentic RAG的创新  \n3\\. Agentic RAG的工作原理与四大工作模式\n\n![Image 54](https://static.53ai.com/assets/static/images/avatar.jpg)\n\n杨芳贤\n\n53A创始人/腾讯云(TVP)最具价值专家\n\n1\\. 为什么需要Agentic RAG？\n---------------------\n\n传统的LLMs虽然强大，但受限于静态训练数据，往往无法适应动态、实时的查询需求。虽然 RAG 通过引入实时数据检索提供了一定改善，但其静态工作流程仍然存在明显短板：\n\n*   缺乏上下文理解\n    \n*   无法进行多步推理\n    \n*   难以处理复杂任务\n    \n\n所以我们需要Agentic RAG~\n\n2\\. RAG技术的演进之路\n--------------\n\n在深入Agentic RAG之前，我们先来看看RAG的基础架构：\n\n![Image 55](https://api.ibos.cn/v4/weapparticle/accesswximg?aid=100705&url=aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9kMDhsdjBhblVuZ1BVODRsWm5kall4RnRiOU01VDRCOENmRTFtdE92eG8wSTZmYnlZb2ljbVRpY01KWVhxVEN6S2V3VWJES0t3TjUwdlNYekp6TWoyMU9RLzY0MD93eF9mbXQ9cG5nJmFtcA==;from=appmsg)\n\n如上图所示，传统RAG包含三个核心组件：\n\n*   检索模块：负责查询外部数据源\n    \n*   增强模块：处理检索到的数据\n    \n*   生成模块：结合LLM生成回答\n    \n\n但这种简单的架构难以应对复杂的现实场景。比如，当你问\"帮我分析一下最近三年的销售数据并给出改进建议\"时，传统RAG可能就会捉襟见肘。\n\n3\\. Agentic RAG的核心原理\n--------------------\n\n那么，Agentic RAG是如何突破这些限制的？智能体（Agent）架构。\n\n![Image 56](https://api.ibos.cn/v4/weapparticle/accesswximg?aid=100705&url=aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9kMDhsdjBhblVuZ1BVODRsWm5kall4RnRiOU01VDRCOFlONThwdUNPV0tTeXU5ZjBoZFhLS3ZvdzJwOWJQb1dZZnZmWk5mSDFkWVhsdGttNXBsRUczdy82NDA/d3hfZm10PXBuZyZhbXA=;from=appmsg)\n\n每个AI Agent都包含四个关键组件：\n\n*   LLM：作为核心推理引擎\n    \n*   记忆系统：维护对话上下文\n    \n*   规划能力：进行任务分解和推理\n    \n*   工具使用：调用外部资源和API\n    \n\nAgentic RAG引入了四种的工作模式：\n\n### 3.1 自反思模式\n\n![Image 57](https://api.ibos.cn/v4/weapparticle/accesswximg?aid=100705&url=aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9kMDhsdjBhblVuZ1BVODRsWm5kall4RnRiOU01VDRCODA5bU1MWWg2QUZ5T0paeWtCMWRLQWo1Rk9KeG5mRTBhbzFnbEJsaWFjQUNnbUg3bllaVHM2YVEvNjQwP3d4X2ZtdD1wbmcmYW1w;from=appmsg)\n\n通过持续的自我评估和改进，Agent能够不断优化其输出质量。就像一个经验丰富的工程师，每完成一个任务都会进行复盘和改进。\n\n### 3.2 规划模式\n\n![Image 58](https://api.ibos.cn/v4/weapparticle/accesswximg?aid=100705&url=aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9kMDhsdjBhblVuZ1BVODRsWm5kall4RnRiOU01VDRCODNSNFlXTXRWMFdpYXZpY2ljeTFpY1U0Zk56NjZIVXF6TmliRHZMamliSUJRR0VKTWt3VmRobGlhdUtWNlEvNjQwP3d4X2ZtdD1wbmcmYW1w;from=appmsg)\n\n面对复杂任务时，Agent会先制定详细的执行计划，将大任务分解为可管理的小步骤。这就像项目经理在开始一个新项目时，会先制定详细的项目计划。\n\n### 3.3 工具使用模式\n\n![Image 59](https://api.ibos.cn/v4/weapparticle/accesswximg?aid=100705&url=aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9kMDhsdjBhblVuZ1BVODRsWm5kall4RnRiOU01VDRCOEtoZnI2b3hXMmxtU3RyS2FLMEs3UjJ4cFZFdnF2UzNSejNGTk9BSXN2SmliTkNCMWlhZVdONEpnLzY0MD93eF9mbXQ9cG5nJmFtcA==;from=appmsg)\n\nAgent能够灵活调用各种外部工具和API，极大扩展了其能力边界。比如在分析销售数据时，可以同时调用数据库查询、统计分析和可视化工具。\n\n### 3.4 多智能体协作模式\n\n![Image 60](https://api.ibos.cn/v4/weapparticle/accesswximg?aid=100705&url=aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9kMDhsdjBhblVuZ1BVODRsWm5kall4RnRiOU01VDRCOGtLaWFZbU1oOFNMcjB4T3ppYXJMUGplSlltYVVkeGJFS0NvSU9VMFNPaWFzUTVUN21PckxQY0g1dy82NDA/d3hfZm10PXBuZyZhbXA=;from=appmsg)\n\n多个Agent可以协同工作，每个Agent负责特定的任务，共同完成复杂目标。这就像一个高效的团队，每个成员都有自己的专长，通过协作完成项目。\n\n4\\. Agentic RAG的七大架构详解\n----------------------\n\n随着技术的发展，Agentic RAG已经衍生出多种强大的架构。每种架构都有其独特的优势和适用场景。让我们一起来看看：\n\n### 4.1 单智能体架构：简单而高效\n\n![Image 61](https://api.ibos.cn/v4/weapparticle/accesswximg?aid=100705&url=aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9kMDhsdjBhblVuZ1BVODRsWm5kall4RnRiOU01VDRCOGhlZzhzS2tzbHVPbkJjT0ZBRkJIUzI2eWljREhkNlZzdFdBYjRaa3RwcHRpYkFYanFUMTlZbEdnLzY0MD93eF9mbXQ9cG5nJmFtcA==;from=appmsg)\n\n单智能体架构是最基础的形式，但是别小看它。想象一个全能的私人助理，它能：\n\n*   智能分析用户问题\n    \n*   选择最合适的信息源\n    \n*   整合多个数据库的内容\n    \n*   生成连贯的回答\n    \n\n比如在客服场景中，它可以同时查询订单系统、物流信息和用户档案，一次性解答用户的问题。\n\n### 4.2 多智能体架构：分工协作的艺术\n\n![Image 62](https://api.ibos.cn/v4/weapparticle/accesswximg?aid=100705&url=aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9kMDhsdjBhblVuZ1BVODRsWm5kall4RnRiOU01VDRCOEI5OGNOZHp4aWNQOVh3WG5VU253bWI4MWZVNkpkbGMxNGgzS3lVcGdDSm4zdFU1bENUOERHRkEvNjQwP3d4X2ZtdD1wbmcmYW1w;from=appmsg)\n\n这就像一个专业的服务团队，每个成员都有自己的专长：\n\n*   Agent 1：负责结构化数据查询\n    \n*   Agent 2：处理语义搜索\n    \n*   Agent 3：获取实时信息\n    \n*   Agent 4：负责个性化推荐\n    \n\n在金融分析场景中，一个Agent负责获取市场数据，另一个分析历史趋势，第三个预测未来走势，最后由主Agent整合输出投资建议。\n\n### 4.3 层级式架构：有序管理的典范\n\n![Image 63](https://api.ibos.cn/v4/weapparticle/accesswximg?aid=100705&url=aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9kMDhsdjBhblVuZ1BVODRsWm5kall4RnRiOU01VDRCOEM3MXV3bDVseXR6MlhSZXh1bmlhaWNaNXlGUU43NjdWSGZpY0FpY0Q2N3ZvTkJTVzU0SENTVGsyamcvNjQwP3d4X2ZtdD1wbmcmYW1w;from=appmsg)\n\n层级式架构就像一个高效的公司组织结构：\n\n*   顶层Agent：负责战略决策\n    \n*   中层Agent：执行具体任务\n    \n*   基层Agent：处理数据检索\n    \n\n这种架构特别适合处理复杂的研究任务。比如在医疗诊断中，顶层Agent制定诊断策略，中层Agent分别负责症状分析、病史查询和检验报告解读，基层Agent则负责具体数据获取。\n\n### 4.4 自纠错架构：不断进化的系统\n\n![Image 64](https://api.ibos.cn/v4/weapparticle/accesswximg?aid=100705&url=aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9kMDhsdjBhblVuZ1BVODRsWm5kall4RnRiOU01VDRCOGlhSG0wUmliUjZxdjlvanNTclJSMzFrOHRkS2tVTWtzNDRleUVwMXRTNmEzMVRCU3hmUGlhTVJody82NDA/d3hfZm10PXBuZyZhbXA=;from=appmsg)\n\n自纠错架构引入了智能的质量控制机制：\n\n*   相关性评估：确保检索内容的准确性\n    \n*   查询优化：动态调整搜索策略\n    \n*   外部知识补充：及时补充缺失信息\n    \n*   响应合成：生成高质量答案\n    \n\n就像一个经验丰富的编辑，不断审核和改进输出的内容质量。\n\n### 4.5 自适应架构：灵活应对的智者\n\n![Image 65](https://api.ibos.cn/v4/weapparticle/accesswximg?aid=100705&url=aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9kMDhsdjBhblVuZ1BVODRsWm5kall4RnRiOU01VDRCOGFRRXMwMUlNNmxJUW9QaDFleU5PeXZvNHlGdlk4c3hGVjBBMHE3TGE4ZERxSVhoVU1MekZwdy82NDA/d3hfZm10PXBuZyZhbXA=;from=appmsg)\n\n自适应架构最大的特点是能根据问题的复杂度动态调整处理策略：\n\n*   简单查询：直接使用LLM回答\n    \n*   中等复杂度：单步检索\n    \n*   高复杂度：多步推理和检索\n    \n\n这就像一个智慧的导师，能根据学生的问题难度，给出恰到好处的指导。\n\n### 4.6 图增强架构：知识图谱的力量\n\n![Image 66](https://api.ibos.cn/v4/weapparticle/accesswximg?aid=100705&url=aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9kMDhsdjBhblVuZ1BVODRsWm5kall4RnRiOU01VDRCOFJISk5NVktETXJ1a2thbUZLN1prZ1BiS25hODZia2FYbDFiTlVtdnQ3a3FNMERpYlc5bWVKQ3cvNjQwP3d4X2ZtdD1wbmcmYW1w;from=appmsg)\n\n![Image 67](https://api.ibos.cn/v4/weapparticle/accesswximg?aid=100705&url=aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9kMDhsdjBhblVuZ1BVODRsWm5kall4RnRiOU01VDRCODFHNWRzSHZRRUJEVFVKZUZzaWFjeThBRk5DdnBjZXdmaWJvaWJQZTRmZFJpYmZsQkFaeEtsVmJCRGcvNjQwP3d4X2ZtdD1wbmcmYW1w;from=appmsg)\n\n图增强架构通过结合知识图谱，极大提升了系统的推理能力：\n\n*   关系推理：理解实体间的复杂关联\n    \n*   多跳推理：支持跨领域知识关联\n    \n*   结构化表示：优化知识组织方式\n    \n\n在医疗领域，它可以轻松处理\"某种症状与哪些疾病相关，这些疾病又有什么共同的风险因素\"这样的复杂问题。\n\n### 4.7 文档工作流架构：企业级的选择\n\n![Image 68](https://api.ibos.cn/v4/weapparticle/accesswximg?aid=100705&url=aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9kMDhsdjBhblVuZ1BVODRsWm5kall4RnRiOU01VDRCOFhNUDJ1V2xNcXptd2p0UkVHYXNvUzJoWWhMdEk5OW5QWFRGSWljQWV6VGNDbkdWZ1dnTjQ2SFEvNjQwP3d4X2ZtdD1wbmcmYW1w;from=appmsg)\n\n这是一个面向企业级应用的完整解决方案：\n\n*   文档解析：智能提取关键信息\n    \n*   状态管理：跟踪处理进度\n    \n*   知识检索：访问企业知识库\n    \n*   流程编排：协调多个组件\n    \n*   输出生成：产出结构化报告\n    \n\n比如在合同审查中，它能自动提取关键条款、比对历史合同、检查合规性，最后生成审查报告。\n\n5\\. 最后是文中罗列的一些应用场景\n------------------\n\n（后续几乎是原文翻译，实际写的就是这么简单~）\n\n### 5.1 智能客服：新一代服务体验\n\n以Twitch的广告销售系统为例，通过Agentic RAG：\n\n*   实时获取广告主数据\n    \n*   分析历史活动效果\n    \n*   研究受众群体特征\n    \n*   生成定制化建议\n    \n\n这不仅提升了运营效率，更带来了显著的转化率提升。\n\n### 5.2 医疗健康：精准诊疗的助手\n\n在医疗领域，Agentic RAG能够：\n\n*   整合电子病历数据\n    \n*   检索最新医学文献\n    \n*   分析检验报告结果\n    \n*   提供诊疗建议支持\n    \n\n比如在生成病例总结时，系统能自动整合患者历史记录、当前症状和相关研究文献，为医生提供全面的参考信息。\n\n### 5.3 金融分析：智能决策的帮手\n\n在金融领域的应用包括：\n\n*   实时市场分析\n    \n*   风险评估预警\n    \n*   投资组合优化\n    \n*   合规审查支持\n    \n\n例如在保险理赔中，系统可以自动处理理赔申请、验证保单信息、评估风险因素，并给出理赔建议。\n\n### 5.4 法律服务：高效的法务助理\n\n在法律领域，Agentic RAG可以：\n\n*   智能合同审查\n    \n*   法律文献检索\n    \n*   案例相关性分析\n    \n*   合规风险评估\n    \n\n通过自动化的合同审查流程，大大提升了法务工作效率，同时降低了人为错误。\n\n### 5.5 教育培训：个性化学习伙伴\n\n在教育领域的应用包括：\n\n*   自适应学习路径\n    \n*   个性化内容推荐\n    \n*   实时答疑解惑\n    \n*   学习进度跟踪\n    \n\n系统能根据学生的学习水平和进度，动态调整教学内容和难度。\n\n分享：\n\n![Image 69](https://static.53ai.com/assets/static/images/share_icon_1.png)\n\n用微信扫描二维码\n\n![Image 70](https://static.53ai.com/assets/static/images/share_icon_2.png)\n\n用微信扫描二维码\n\n![Image 71](https://static.53ai.com/assets/static/images/share_icon_3.png)\n\n用微信扫描二维码\n\n![Image 72](https://static.53ai.com/assets/static/images/share_icon_4.png)\n\n用微信扫描二维码\n\n53AI，企业落地大模型首选服务商\n\n**产品**：场景落地咨询+大模型应用平台+行业解决方案\n\n**承诺**：免费场景POC验证，效果验证后签署服务协议。**零风险落地应用大模型**，已交付160+中大型企业\n\n[上一篇：你的RAG系统真的达标了吗？生产环境RAG成功的7大关键指标](https://www.53ai.com/news/RAG/2025020453280.html) [下一篇：Model2Vec加速RAG：模型小15倍，速度快500倍：](https://www.53ai.com/news/RAG/2025012847685.html)\n\n[返回列表](https://www.53ai.com/news/RAG)\n\n相关资讯\n\n[2025-03-15 RAG效果差竟因文本切片！深入理解LangChain4J NLP方案](https://www.53ai.com/news/RAG/2025031518457.html)[2025-03-15 NLP+图技术：如何低成本打造高效GraphRAG应用？](https://www.53ai.com/news/RAG/2025031508716.html)[2025-03-15 使用 Ollama 本地模型与 Spring AI Alibaba 的强强结合，打造下一代 RAG 应用](https://www.53ai.com/news/RAG/2025031587095.html)[2025-03-14 一文学会基于LangChain开发大模型RAG知识问答应用](https://www.53ai.com/news/RAG/2025031425483.html)[2025-03-14 GraphRAG落地难，微软工业级RAG+Agent实施方案](https://www.53ai.com/news/RAG/2025031426081.html)[2025-03-14 Embedding向量模型在RAG本地知识库中如何使用](https://www.53ai.com/news/RAG/2025031491527.html)[2025-03-14 DeepSearch/DeepResearch中最优文本段选择和URL重排](https://www.53ai.com/news/RAG/2025031401342.html)[2025-03-13 大模型私有知识库如何提高准确率？切块是关键](https://www.53ai.com/news/RAG/2025031378932.html)\n\n![Image 73: 智能化改造方案](https://static.53ai.com/uploads/20240531/5002026623535870b7a07ff223f9f34a.jpg) ![Image 74: 智能化改造方案](https://static.53ai.com/uploads/20240531/5002026623535870b7a07ff223f9f34a.jpg) [了解更多](https://www.53ai.com/)\n\n![Image 75: 大模型落地应用平台](https://static.53ai.com/uploads/20240529/72a2c0f952f63ef0a546b91beb4bbb32.jpg) ![Image 76: 大模型落地应用平台](https://static.53ai.com/uploads/20240530/5002026623535870b7a07ff223f9f34a.jpg) [了解更多](https://www.53ai.com/)\n\n160+中大型企业正在使用53AI\n\n[立即咨询](javascript:;) [预约演示](javascript:;)\n\n[把握AI发展的机遇，共同探索、共同进步 2025-01-22](https://www.53ai.com/news/dongtai/2025012294502.html)[如何打造基于GenAI的员工服务机器人 2025-01-22](https://www.53ai.com/news/dongtai/2025012234192.html)\n\n热点资讯\n\n[全网最全国内Agent平台深度测评：扣子、Dify、FastGPT，谁是你的Agent开发首选？ 2024-10-27](https://www.53ai.com/news/RAG/2024102704765.html)[一文彻底搞懂大模型 - RAG（检索、增强、生成） 2024-09-04](https://www.53ai.com/news/RAG/2024090469028.html)[GraphRAG+Ollama 本地部署，保姆教程，踩坑无数，闭坑大法 2024-07-18](https://www.53ai.com/news/RAG/2024071808762.html)[RAGFlow：基于OCR和文档解析的下一代 RAG 引擎 2024-05-05](https://www.53ai.com/news/RAG/1740.html)[RAG框架，都在这了! 2024-06-20](https://www.53ai.com/news/RAG/2024062056319.html)[RAG 高效应用指南：Embedding 模型的选择和微调 2024-06-13](https://www.53ai.com/news/RAG/2024061372409.html)[深入解析 Graph RAG：提升语言模型问答能力的创新策略 2024-07-09](https://www.53ai.com/news/RAG/2024070935217.html)[微软开源的GraphRAG解读 2024-07-09](https://www.53ai.com/news/RAG/2024070997368.html)[基于Llama 3 构建RAG语音助手：将本地 RAG 与 Qdrant、Whisper 和 LangChain 集成 2024-05-19](https://www.53ai.com/news/RAG/2302.html)[Prompt工程师必备：复旦重磅 | 最佳RAG实践长什么样的？ 2024-07-07](https://www.53ai.com/news/RAG/2024070786014.html)\n\n大家都在问\n\n[NLP+图技术：如何低成本打造高效GraphRAG应用？ 2025-03-15](https://www.53ai.com/news/RAG/2025031508716.html)[为什么RAG一定需要Rerank？ 2025-03-13](https://www.53ai.com/news/RAG/2025031364325.html)[如何提升RAG知识库文档的召回准确率？ 2025-03-13](https://www.53ai.com/news/RAG/2025031330416.html)[什么是Embedding向量模型？我们应该如何选择？ 2025-03-11](https://www.53ai.com/news/RAG/2025031152837.html)[Graph RAG 迎来记忆革命：“海马体”机制如何提升准确率？ 2025-03-05](https://www.53ai.com/news/RAG/2025030521096.html)[谷歌放大招！RAG 技术已死？ 2025-03-03](https://www.53ai.com/news/RAG/2025030303859.html)[知识库对决：知乎、钉钉、腾讯、谷歌，谁更懂你的资料？ 2025-03-02](https://www.53ai.com/news/RAG/2025030206289.html)[直接拿大模型当搜索页(SERP)会怎样？ 2025-02-28](https://www.53ai.com/news/RAG/2025022825864.html)\n\n热门标签\n\n[内容创作](https://www.53ai.com/news/neirongchuangzuo) [大模型技术](https://www.53ai.com/news/LargeLanguageModel) [个人提效](https://www.53ai.com/news/gerentixiao) [langchain](https://www.53ai.com/news/langchain) [llamaindex](https://www.53ai.com/news/llamaindex) [多模态技术](https://www.53ai.com/news/MultimodalLargeModel) [RAG技术](https://www.53ai.com/news/RAG) [智能客服](https://www.53ai.com/news/zhinengkefu) [知识图谱](https://www.53ai.com/news/knowledgegraph) [模型微调](https://www.53ai.com/news/finetuning) [RAGFlow](https://www.53ai.com/news/RAGFlow) [coze](https://www.53ai.com/news/coze) [Dify](https://www.53ai.com/news/dify) [Fastgpt](https://www.53ai.com/news/fastgpt) [Bisheng](https://www.53ai.com/news/Bisheng) [Qanything](https://www.53ai.com/news/Qanything) [AI+汽车](https://www.53ai.com/news/AIqiche) [AI+金融](https://www.53ai.com/news/AIjinrong) [AI+工业](https://www.53ai.com/news/AIgongye) [AI+培训](https://www.53ai.com/news/AIpeixun) [AI+SaaS](https://www.53ai.com/news/AISaaS) [提示词框架](https://www.53ai.com/news/tishicikuangjia) [提示词技巧](https://www.53ai.com/news/tishicijiqiao) [AI+电商](https://www.53ai.com/news/AIdianshang) [AI面试](https://www.53ai.com/news/AImianshi) [数字员工](https://www.53ai.com/news/shuziyuangong) [ChatBI](https://www.53ai.com/news/zhinengbaobiao) [知识管理](https://www.53ai.com/news/zhishiguanli) [开源大模型](https://www.53ai.com/news/OpenSourceLLM) [智能营销](https://www.53ai.com/news/zhinengyingxiao) [智能硬件](https://www.53ai.com/news/zhinengyingjian) [智能化改造](https://www.53ai.com/news/zhinenghuagaizao) [AI+医疗](https://www.53ai.com/news/AIyiliao) [MaxKB](https://www.53ai.com/news/MaxKB)\n\n  \n\n[应聘简历请发送至： ceo@53ai.com](mailto:ceo@53ai.com)\n\n \n\n[产品服务](https://www.53ai.com/product.html)\n\n[工作+AI](https://www.53ai.com/product/quanyuanAI)\n\n[工作对话](https://www.53ai.com/product/gongzuoduihua)\n\n[内容创作](https://www.53ai.com/product/neirongchuangzuo)\n\n[方案撰写](https://www.53ai.com/product/zhinengwendang)\n\n[魔法菜单](https://www.53ai.com/product/mofacaidan)\n\n[业务+AI](https://www.53ai.com/product/yewuAI)\n\n[智能问答](https://www.53ai.com/product/jiqiren)\n\n[拓展能力](https://www.53ai.com/product/jinengtuozhan)\n\n[私有模型](https://www.53ai.com/product/siyoumoxing)\n\n[AIx业务](https://www.53ai.com/product/AIXyewu)\n\n[应用智改](https://www.53ai.com/product/zijianyingyong)\n\n[LLMFlow](https://www.53ai.com/product/LLMFlow)\n\n[ChatBI](https://www.53ai.com/product/ChatBI)\n\n[统管平台](https://www.53ai.com/product/xitongguanli)\n\n[大模型咨询](https://www.53ai.com/consulting.html)\n\n[大模型开发](https://www.53ai.com/fine-tuning.html)\n\n[解决方案](https://www.53ai.com/solution.html)\n\n【智能问答】解决方案\n\n【应用智改】解决方案\n\n【智能工单】解决方案\n\n[AI知识库](https://www.53ai.com/news.html)\n\n[前沿技术](https://www.53ai.com/news/qianyanjishu)\n\n[Agent框架](https://www.53ai.com/news/agentplatform)\n\n[行业应用](https://www.53ai.com/news/hangyeyingyong)\n\n[企业经营](https://www.53ai.com/news/qiyejingying)\n\n[结构化提示词](https://www.53ai.com/prompt.html)\n\n[LangGPT之路](https://www.53ai.com/prompt/LangGPTzhilu)\n\n[提示词合集](https://www.53ai.com/prompt/Sorayanjiufenxi)\n\n[应用案例](https://www.53ai.com/prompt/tongwangAGIzhilu)\n\n[社区达人](https://www.53ai.com/prompt/shequndaren)\n\n[关于我们](https://www.53ai.com/about.html)\n\n[公司介绍](https://www.53ai.com/about/introduction)\n\n[渠道合作](https://www.53ai.com/about/cooperation)\n\n友情链接：\n\n[通往AGI之路](https://www.waytoagi.com/) [云璨信息](https://www.yuncan.com/) [企微SCRM](https://www.wescrm.com/) [小名片](https://www.mingpian.top/) [优网科技](https://www.uweb.net.cn/)\n\nCopyRight © 2012-2024 深圳市博思协创网络科技有限公司 版权所有\n\n[![Image 77](https://static.53ai.com/assets/static/images/bei.png)粤ICP备17114055号](https://beian.miit.gov.cn/#/Integrated/index)\n\n广州：广州市华景路37号(华景软件园)暨南大学科技大厦6楼（整层） 杨小姐   186 6662 7370\n\n深圳：深圳市福田区泰然四路29号天安创新科技广场一期A座1204    陈先生  185 8882 0121\n\n上海：上海市浦东新区金新路58号1602室    戴先生   186 1639 7587\n\n微信扫码  \n和创始人交个朋友\n\n联系我们\n\n售前咨询\n\n[186 6662 7370](tel:18666627370)\n\n预约演示\n\n[185 8882 0121](tel:18588820121)\n\n![Image 78](https://static.53ai.com/assets/static/images/loading.svg)\n\n微信扫码\n\n添加专属顾问\n\n回到顶部\n\n![Image 79](https://static.53ai.com/assets/static/images/loading.svg)加载中...\n\n扫码咨询\n\n![Image 80](https://www.53ai.com/news/RAG/2025020132490.html)\n\n![Image 81](https://www.53ai.com/news/RAG/2025020132490.html)\n",
    "created_at": "2025-03-15T04:56:24Z",
    "updated_at": "2025-03-15T04:56:51Z",
    "labels": [],
    "url": "https://github.com/kaozb/ai-arctl/issues/22"
  },
  {
    "id": 21,
    "title": "一文说清楚让LangChain大佬“开战”的MCP是什么？",
    "content": "一文说清楚让LangChain大佬“开战”的MCP是什么？\n===============\n                                                                          \n\n             \n\n  \n\n![Image 1: cover_image](https://mmbiz.qpic.cn/mmbiz_jpg/ko3ibXTD3NEJliaPOURsPbqpSM39emGFXibI2cee9OosWNiaGIicD61iab8SgD1icrJS65yTpqRuX3t5wYw3bOeRbZ0ibQ/0?wx_fmt=jpeg)\n\n一文说清楚让LangChain大佬“开战”的MCP是什么？\n=============================\n\nOriginal AI取经路 [AI取经路](javascript:void(0);)\n\n![Image 2: profile_qrcode](https://mp.weixin.qq.com/mp/qrcode?scene=10000005&size=102&__biz=MzI4MjE1Nzc2MQ==&mid=2649038667&idx=1&sn=d1467904da2f8acc62b7bb4838737ed2&send_time=)\n\nAI取经路\n\n踏上取经路，比抵达灵山更重要！ AI技术、 AI知识 、 AI应用 、 人工智能 、 大语言模型\n\n97篇原创内容\n\n_2025年03月13日 10:43_\n\n**\\-推荐关注-**\n\n**\\-正文-**\n\n\n========================\n\nMCP（Model Context Protocol）是Anthropic于2024年开源的标准协议，旨在统一AI模型与数据源的交互方式，提升数据访问的便捷性和可靠性，提供标准化的工具调用、资源管理和提示词功能。目前，MCP仍处于探索阶段，其行业影响力有待进一步验证。\n\n*   1\\. MCP是什么\n    \n*   2\\. MCP的应用场景举例\n    \n\n*   2.1 代码管理与开发\n    \n*   2.2 数据管理与交互\n    \n*   2.3 远程资源交互\n    \n*   2.4 构建智能助手应用\n    \n\n*   3\\. MCP 的架构是什么\n    \n*   4\\. MCP Servers 可以给我们提供什么能力？\n    \n*   5\\. MCP：昙花一现还是未来标准？── LangChain 首席执行官 VS LangGraph 负责人\n    \n\n*   Harrison Chase（支持 MCP）的观点：\n    \n*   Nuno Campos（质疑 MCP）的观点：\n    \n*   网友对双方的投票结果\n    \n\n\\-- 领取学习资料大礼包，见文末\n\n3月8号，LangChain 首席执行官和 LangGraph 负责人对于MCP的价值表达了不同的意见。（见第5章）\n\n而在当下大火的AI编程工具cursor和cline中，也能看到MCP的身影。\n\n![Image 3: image-20250313104947953](https://mmbiz.qpic.cn/mmbiz_png/ko3ibXTD3NEJliaPOURsPbqpSM39emGFXib80uUACSBrjWu9etiazVoibBZXOLNI6DDdf2n5f2x4icXsKwxeaUpibnSlg/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)\n\n  \n\nMCP关键字的热度不断上升，那么MCP到底是什么？能引起大家的持续讨论？\n\n相关阅读：\n\n[从0到1开发AI Agent（智能体）（四）| LangChain 的快速入门](https://mp.weixin.qq.com/s?__biz=MzI4MjE1Nzc2MQ==&mid=2649034780&idx=1&sn=10c84b7606a226394a93987483b58ba7&scene=21#wechat_redirect)\n\n[LangChain实战 | LangGraph 让你的 AI 项目从 “好” 变 “卓越”](https://mp.weixin.qq.com/s?__biz=MzI4MjE1Nzc2MQ==&mid=2649036562&idx=1&sn=ae0476450838b9a9d8e3d1bc923ee1d2&scene=21#wechat_redirect)\n\n1\\. MCP是什么\n----------\n\n2024 年 11 月 25 日，Anthropic 宣布开源 Model Context Protocol（MCP）( https://www.anthropic.com/news/model-context-protocol)。\n\n> ❝Anthropic是一家专注于人工智能安全和可控性的AI公司，由前OpenAI成员于2021年创立。其代表产品是Claude系列AI助手\n\nMCP为连接**AI应用**与数据源提供了一个通用的开放标准，用单一协议取代了碎片化的集成。通过这个机制， 为**AI应用**提供所需数据的接入方式变得更简单、更可靠。他标准化了应用程序向LLMs提供上下文的方法。\n\n可以把 MCP 想象成**AI应用**程序的 USB-C 接口。正如 USB-C 提供了一种标准化的方式，将设备连接到各种外设和配件。\n\nMCP 也提供了一种标准化的方式，将 AI 模型连接到不同的数据源和工具。\n\n通过这种连接，能力小的**AI应用**会变成更强的应用\n\n![Image 4: image-20250313132742878](https://mmbiz.qpic.cn/mmbiz_png/ko3ibXTD3NEJliaPOURsPbqpSM39emGFXibhOImgOjqcYo38ibjmXMwv2QehN1fvlFCdOqnYkSUqniaT0EVe4t4Tofw/640?wx_fmt=png&from=appmsg)\n\n  \n\nAnthropic 为开发者提供了：\n\n1. Model Context Protocol 规范和 SDK\n\nhttps://github.com/modelcontextprotocol\n\n2. MCP Servers 的开源库,仓库提供了许多官方集成的和社区分享的MCP Servers：\n\nhttps://github.com/modelcontextprotocol/servers\n\n  \n\n2\\. MCP的应用场景举例\n--------------\n\n### 2.1 代码管理与开发\n\n在代码开发方面，开发人员可以利用大语言模型自动化编程，IDEs 通过 MCP 协议可以直接接入很多工具，如接入连接版本库的 MCP Server，就可以让 AI 自己写代码、创建仓库、Push 代码、创建 Issue、创建分支、创建 PR 等操作，全程无需离开聊天界面，开发人员仅需提出需求即可 。\n\n当然也可以让IDE接入其他MCP Server\n\n![Image 5: Image](https://mmbiz.qpic.cn/mmbiz_png/ko3ibXTD3NEJliaPOURsPbqpSM39emGFXibcNeFsa93GichvRk1flWbMDwTo6rpoLxOPY87t792IOOLbiaBVhdOVprw/640?wx_fmt=png&from=appmsg)\n\n### 2.2 数据管理与交互\n\nMCP 协议支持对本地资源的管理，如电脑里的文件、数据库（像 SQLite 数据库）等。\n\n开发人员可以使用 MCP 协议让**AI应用**安全连接本地服务，进行文件的创建、读取、编辑等操作，还能对数据库中的数据进行交互操作，例如查询、更新等 。\n\n### 2.3 远程资源交互\n\n对于远程资源，如 `GoogleDrive` 等平台的数据，**AI应用**借助 MCP 协议可以直接进行控制和访问。这使得企业和开发者在构建 AI 应用时，能够轻松整合不同来源的数据，如从商业工具、软件、内容库、应用程序开发环境等各种来源提取资料，协助模型产生与指令更相关的回复 。\n\n### 2.4 构建智能助手应用\n\nMCP 协议可以让 **AI应用**更加智能和强大。**AI应用**不再只是简单的问答系统，而是变成了一个能够执行复杂任务、处理文件和与外部系统通信的强大工具。\n\n例如，在构建一个企业内部的智能助手时，可以利用 MCP 协议连接企业内部的各种数据资源（如数据库、文件服务器等）以及外部相关的业务工具（如项目管理工具等），为企业员工提供更全面、更高效的服务。\n\n![Image 6: image-20250313145443872](https://mmbiz.qpic.cn/mmbiz_png/ko3ibXTD3NEJliaPOURsPbqpSM39emGFXib7fvE2p9WBlLqAhmM9FdEYtkFoo3x6NRPJVVOaUiaZlMbUXqas76zUUg/640?wx_fmt=png&from=appmsg)\n\nAI工具接入搜索引擎，实时查询信息\n\n3\\. MCP 的架构是什么\n--------------\n\n在整个MCP的应用场景中，整体架构如下：\n\n![Image 7: image-20250313150255764](https://mmbiz.qpic.cn/mmbiz_png/ko3ibXTD3NEJliaPOURsPbqpSM39emGFXibUOichcKUKjxprHvpFZMSMsYk6ic8pX2dV8ic1KK2Rkk0yMeg2LibmS7yzg/640?wx_fmt=png&from=appmsg)\n\n  \n\n*   **MCP Hosts**: 希望通过 MCP 访问数据的程序，如 Claude Desktop、Cline等开发工具或AI应用\n    \n*   **MCP Clients**: 与服务器保持 1:1 连接的协议客户端\n    \n*   **MCP Servers**: 轻量级程序，每个程序通过标准化的Model Context Protocol (MCP)暴露特定的能力\n    \n*   **本地数据源（Local Data Sources）**: 您计算机中，MCP 服务器可以安全访问的文件、数据库和服务\n    \n*   **远程服务（Remote Services）**: 可以通过互联网（例如，通过 API）访问的外部系统，MCP 服务器可以连接到这些系统\n    \n\n请在微信客户端打开\n\n  \n\n4\\. MCP Servers 可以给我们提供什么能力？\n----------------------------\n\nAI应用通过标准化的接口连接MCP Server后，AI应用能获取什么能力呢？\n\n![Image 8: image-20250313155456430](https://mmbiz.qpic.cn/mmbiz_png/ko3ibXTD3NEJliaPOURsPbqpSM39emGFXibANGYNBljFnmLpZibYAP19LSXibAmFVOdrYIOfZPogf6CtQanLaBCNjCA/640?wx_fmt=png&from=appmsg)\n\n  \n\n**1\\. Prompts 提示词**\n\nModel Context Protocol (MCP) 让 **servers** 向客户端暴露 **prompts** 模板。\n\n客户端可以发现可用的**prompts**，并提供参数自定义它们。\n\n通常，**Prompts**会通过用户在用户界面中发起的命令触发，这使得用户能够自然地发现和调用可用的提示。\n\n例如，通过斜杠命令：\n\n![Image 9: Example of prompt exposed as slash command](https://mmbiz.qpic.cn/mmbiz_png/ko3ibXTD3NEJliaPOURsPbqpSM39emGFXibUNfqFx3s69hs1vCpzwE3vHLziblJHJsYHeWsNGr7OEruN5FlRfblnoA/640?wx_fmt=png&from=appmsg)\n\n  \n\n**2\\. Resources 资源**\n\nModel Context Protocol (MCP) 可以使 **servers** 向客户端暴露Resources ，例如文件、数据库schemas。每个资源都通过 URI 唯一标识，如：`file:///home/user/documents/report.pdf`。\n\n应用程序根据其需求决定如何将Resources整合到上下文。\n\n例如，应用程序可以：\n\n*   通过 UI 元素显式选择资源，以树形或列表视图显示\n    \n*   允许用户搜索和过滤可用资源\n    \n*   通过AI 应用选择文件，从而实现包含在上下文中\n    \n\n![Image 10: Example of resource context picker](https://mmbiz.qpic.cn/mmbiz_png/ko3ibXTD3NEJliaPOURsPbqpSM39emGFXiblFyb41dkBK0h1rRzRnYevdbrMzcLPiaYoemlDtzmCT7nYAXIqKiaDBdQ/640?wx_fmt=png&from=appmsg)\n\n  \n\n**3\\. Tools 工具**\n\nModel Context Protocol (MCP) 允许 **servers** 公开可被语言模型调用的工具。工具使模型能够与外部系统交互，例如查询数据库、调用 API 或执行计算。每个工具都有一个唯一的名称，并包括描述其架构的元数据。\n\n对于MCP 中工具使用，由模型控制，这意味着语言模型可以根据其上下文理解和用户的提示自动发现和调用工具。\n\n相关阅读:\n\n[LangChain实战 | Tool Calling ：让AI真正动起来的关键技术](https://mp.weixin.qq.com/s?__biz=MzI4MjE1Nzc2MQ==&mid=2649035594&idx=1&sn=06b4ef579c9b3101074411adb000e9f4&scene=21#wechat_redirect)\n\n**对于以上所有能力的使用方式仅供参考，该协议本身并不强制特定的用户交互方式。**\n\n5\\. MCP：昙花一现还是未来标准？── LangChain 首席执行官 VS LangGraph 负责人\n------------------------------------------------------\n\n2025 年 3 月 8 日,LangChain发布了一篇辩论，\n\n在这场关于模型上下文协议（MCP）的辩论中，Harrison Chase（LangChain 首席执行官）和 Nuno Campos（LangGraph 负责人）分别从不同角度阐述了他们对 MCP 的观点。以下是双方的主要观点总结：\n\n### Harrison Chase（支持 MCP）的观点：\n\n1.  **MCP 的实用性和价值**：\n    \n\n*   **为非控制Agent提供工具**：MCP 在用户无法控制底层Agent（如 Claude Desktop、Cursor 和 Windsurf）时，能够为这些Agent提供额外的工具支持，添加默认不支持的工具。\n    \n*   **降低技术门槛**：MCP 使非开发人员能够为Agent添加工具，而无需深入编辑Agent逻辑。这有助于让业务专家（非技术背景人员）也能参与Agent构建。\n    \n*   **适应未来趋势**：随着基础模型的不断改进，MCP 的工具调用Agent也会变得更好。MCP 的工具定义和提示功能可以帮助Agent更好地理解和使用工具。\n    \n    相关阅读：[一文说清楚什么是基础模型(Base LLM)、指令微调模型(Instruction-Tuned LLM)](https://mp.weixin.qq.com/s?__biz=MzI4MjE1Nzc2MQ==&mid=2649037721&idx=1&sn=9f4209975d2be3fdc1a580fbd3c86730&scene=21#wechat_redirect)\n    \n\n3.  **MCP 的长期价值**：\n    \n    当前 MCP 的实现形式可能不够完善，但未来有望改进，例如通过一键安装 MCP 应用程序，使其在 Web 应用中更易用。\n    \n\n### Nuno Campos（质疑 MCP）的观点：\n\n1.  **MCP 的局限性和问题**：\n    \n\n*   **工具与Agent的适配性**：仅仅通过 MCP 注入工具并不能解决实际问题，因为Agent的架构和系统消息需要与工具高度适配。在实际生产环境中，Agent需要为工具定制化，否则效果不佳。\n    \n*   **可靠性问题**：当前模型在调用工具时的成功率较低（约一半时间失败），即使在为特定工具集定制的Agent中也是如此。这种可靠性不足使得 MCP 的实用性大打折扣。\n    \n*   **复杂性**：MCP 的协议过于复杂，例如MCP 的双向通信机制并不是一个足够好的理由，增加了实现的复杂性。当前的实现形式（如需要在本地终端运行服务器）并不实用。\n    \n\n3.  **对 MCP 能力的质疑**：\n    \n\n*   **实际应用不足**：尽管 MCP 在 网络上引起关注，但实际应用案例很少。Nuno 认为，MCP 的生态系统并没有比插件（Plugins）更大，且插件也未能成功。\n    \n*   **用户期望的挑战**：即使模型性能提升，用户的期望也会随之提高。MCP 需要证明其能够满足这些不断上升的期望。\n    \n\n  \n\n相关阅读：[一文说清楚什么是AI Agent(智能体)](https://mp.weixin.qq.com/s?__biz=MzI4MjE1Nzc2MQ==&mid=2649034220&idx=1&sn=96f26af6f4895428187df31826089a74&scene=21#wechat_redirect)\n\n### 网友对双方的投票结果\n\n![Image 11: image-20250313103209975](https://mmbiz.qpic.cn/mmbiz_png/ko3ibXTD3NEJliaPOURsPbqpSM39emGFXibwXnOcoDdmVym2tia3ymXuM6L1TWwdUiaIZjYBmVwxgRj8FoIdibia5GF4Q/640?wx_fmt=png&from=appmsg)\n\n  \n\n辩论原文：https://blog.langchain.dev/mcp-fad-or-fixture/\n\n  \n\n  \n\n  \n\n  \n\n往日推荐：\n\n  \n\n1.  [LangChain实战 | 路由机制让AI助手更聪明，专业问题交给专业模块！](https://mp.weixin.qq.com/s?__biz=MzI4MjE1Nzc2MQ==&mid=2649038248&idx=1&sn=fb46934ddd6c12b261a4dcd23fb503ab&scene=21#wechat_redirect)\n    \n2.  [LangChain实战 | MultiQueryRetriever 让 RAG 更懂你的问题](https://mp.weixin.qq.com/s?__biz=MzI4MjE1Nzc2MQ==&mid=2649038076&idx=1&sn=c876b11f688e1efa065c80fe53b9807d&scene=21#wechat_redirect)\n    \n3.  [从0开始：用 Streamlit + LangChain 搭建个简易ChatGPT](https://mp.weixin.qq.com/s?__biz=MzI4MjE1Nzc2MQ==&mid=2649037770&idx=1&sn=610887ea31da18f9a5636815f51a92b9&scene=21#wechat_redirect)\n    \n4.  [LangChain实战 | ParentDocumentRetriever 优化长文档的向量搜索质量](https://mp.weixin.qq.com/s?__biz=MzI4MjE1Nzc2MQ==&mid=2649037710&idx=1&sn=9cce683f68571eabdd3238add098a1b9&scene=21#wechat_redirect)\n    \n",
    "created_at": "2025-03-15T03:46:16Z",
    "updated_at": "2025-03-15T04:46:59Z",
    "labels": [
      "集合"
    ],
    "url": "https://github.com/kaozb/ai-arctl/issues/21"
  },
  {
    "id": 16,
    "title": "如何构建通用LLM Agent",
    "content": "如何构建通用LLM Agent\n===============\n                                                                         \n\n             \n\n  \n\n![Image 1: cover_image](https://mmbiz.qpic.cn/mmbiz_jpg/2lV2gxZP551rvLsudBXeo8K9RHPm0Id3LkX10ribJSCXuA75l3NOIEvDI38KPsjkhnZ2XkN3pYDsZol7fNqDRnQ/0?wx_fmt=jpeg)\n\n如何构建通用LLM Agent\n===============\n\nOriginal 鸿煊 [鸿煊的学习笔记](javascript:void(0);)\n\n![Image 2: profile_qrcode](https://mp.weixin.qq.com/mp/qrcode?scene=10000005&size=102&__biz=Mzg4MDAzNjMyMg==&mid=2247486851&idx=1&sn=a22c51cdcb73e285f969d5f76017496d&send_time=)\n\n鸿煊的学习笔记\n\n包括但不限于机器学习、深度学习、数据挖掘、自然语言处理、大数据、算法等人工智能相关领域的知识。\n\n133篇原创内容\n\n_2025年01月01日 13:55_\n\n1\\. LLM Agent是什么2\\. 构建通用型大语言模型智能体的步骤2.1 选择合适的大语言模型2.2 定义智能体的控制逻辑（即通信结构）2.3 定义智能体的核心指令2.4 定义和优化核心工具2.5 决定内存处理策略2.6 解析智能体的原始输出2.7 编排Agent的下一步骤2.8 多智能体系统在什么情况下适用3 入门建议\n\n![Image 3: Image](https://mmbiz.qpic.cn/mmbiz_png/2lV2gxZP551rvLsudBXeo8K9RHPm0Id3vQdJUyb3MFHrzaAyZLy5ugDLFUjS8VJzTZtMEsooafebRkA22DyIrQ/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)\n\n1\\. LLM Agent是什么\n================\n\n![Image 4: Image](https://mmbiz.qpic.cn/mmbiz_png/2lV2gxZP551rvLsudBXeo8K9RHPm0Id38pFlAIZibAPejpRtvDjh69ziaKNprhfP9YKegTI9azq7sextv6icLJ16w/640?wx_fmt=png&from=appmsg)\n================================================================================================================================\n\n大语言模型智能体是一种程序，其执行逻辑由其底层模型控制。\n\n![Image 5: Image](https://mmbiz.qpic.cn/mmbiz_png/2lV2gxZP551rvLsudBXeo8K9RHPm0Id3MGN1Pt8WeCPJStlSLqJxtVGnb4DBoia00lhfjlzyhsLf6KvibI0VKKfA/640?wx_fmt=png&from=appmsg)\n\n大语言模型智能体与少样本提示或固定工作流程等方法的区别在于，它能够定义和调整执行用户查询所需的步骤。通过使用一组工具（如代码执行或网络搜索），智能体可以决定使用哪个工具、如何使用它，并根据输出对结果进行迭代。这种适应性使系统能够以最小的配置处理各种用例。\n\n![Image 6: Image](https://mmbiz.qpic.cn/mmbiz_png/2lV2gxZP551rvLsudBXeo8K9RHPm0Id3KINVVkJjkFNpz4HZR2xekicNn0s6EJZic0h76W1ZvInH8jSxcepJS2lg/640?wx_fmt=png&from=appmsg)\n\n智能体架构存在于一个范围内，从固定工作流程的可靠性到自主智能体的灵活性。例如，像检索增强生成（RAG）这样的固定流程可以通过自我反思循环进行增强，使程序在初始响应不足时能够进行迭代。或者，一个反应式（ReAct）智能体可以配备固定流程作为工具，提供一种灵活而结构化的方法。架构的选择最终取决于用例以及在可靠性和灵活性之间的期望权衡。\n\n2\\. 构建通用型大语言模型智能体的步骤\n====================\n\n2.1 选择合适的大语言模型\n--------------\n\n选择合适的模型对于实现期望的性能至关重要。需要考虑多个因素，如许可证、成本和语言支持。构建大语言模型智能体时，最重要的考虑因素是模型在关键任务（如编码、工具调用和推理）上的性能。评估基准包括：\n\n*   大规模多任务语言理解（MMLU）（推理）\n    \n*   伯克利函数调用排行榜（工具选择与工具调用）\n    \n*   HumanEval 和 BigCodeBench（编码）\n    \n\n*   模型的上下文窗口也是一个关键因素。智能体工作流程可能会消耗大量token，有时甚至超过 10 万个，较大的上下文窗口非常有帮助。\n    \n\n*   可供考虑的模型：\n    \n\n*   前沿模型（GPT4 - o、Claude 3.5）；\n    \n*   开源模型（Llama3.2、Qwen2.5）。\n    \n\n一般来说，较大的模型往往性能更好，但能够在本地运行的较小模型仍然是一个不错的选择。使用较小的模型时，你将局限于更简单的用例，并且可能只能将智能体连接到一两个基本工具。\n\n2.2 定义智能体的控制逻辑（即通信结构）\n---------------------\n\n![Image 7: Image](https://mmbiz.qpic.cn/mmbiz_png/2lV2gxZP551rvLsudBXeo8K9RHPm0Id3fU0ds5aPoNPXnAUl79mpicFg4EnUWyAqD6WKVPnvIDduRZLxvV8j23Q/640?wx_fmt=png&from=appmsg)\n\nLLM和智能体之间的主要区别在于系统提示。在LLM的背景下，系统提示是在模型处理用户查询之前提供给它的一组指令和上下文信息。大语言模型的智能体行为可以在系统提示中进行编码。以下是一些常见的智能体模式，可以根据需要进行定制：\n\n*   **工具使用**：智能体决定何时将查询路由到适当的工具或依赖自身知识。\n    \n*   **反思**：智能体在回答用户之前审查并纠正自己的答案。大多数大语言模型系统也可以添加反思步骤。\n    \n*   **推理 - 行动（ReAct）**：智能体迭代地推理如何解决查询，执行一个动作，观察结果，并决定是否采取另一个动作或提供响应。\n    \n*   **计划 - 执行**：智能体预先计划，将任务分解为子步骤（如果需要），然后执行每个步骤。\n    \n\n最后两种模式（ReAct 和计划 - 执行）通常是构建通用型单智能体的最佳起点。\n\n![Image 8: Image](https://mmbiz.qpic.cn/mmbiz_png/2lV2gxZP551rvLsudBXeo8K9RHPm0Id3u2lwKX2F74vd66IibC0HZ7R4k03eOwF6d7EKHlzWIIwcXbLAaD7wNMA/640?wx_fmt=png&from=appmsg)\n\n为了有效地实现这些行为，你需要进行一些提示词工程。你可能还想使用结构化生成技术。这基本上意味着塑造大语言模型的输出以匹配特定的格式或模式，以便智能体的响应与你所期望的通信风格保持一致。\n\n示例：以下是来自 Bee Agent 框架的反应式（ReAct）风格智能体的提示(https://github.com/i-am-bee/bee-agent-framework/blob/main/src/agents/bee/prompts.ts)。\n\n```\n# Communication structure\n```\n\n2.3 定义智能体的核心指令\n--------------\n\n我们往往认为大语言模型开箱即用就带有许多功能。其中一些功能很棒，但其他功能可能不完全符合你的需求。为了获得你期望的性能，在系统提示中明确列出你想要和不想要的所有功能非常重要。这可能包括以下指令：\n\n*   **智能体名称和角色**：智能体的名称以及它的用途。\n    \n*   **语气和简洁性**：它应该听起来多么正式或随意，以及应该多么简短。\n    \n*   **何时使用工具**：决定何时依赖外部工具而不是模型自身的知识。\n    \n*   **处理错误**：当工具或过程出现问题时，智能体应该怎么做。\n    \n\n示例：以下是 Bee Agent 框架中指令部分的一个片段。\n\n```\n# Instructions\n```\n\n2.4 定义和优化核心工具\n-------------\n\n工具赋予智能体超能力。通过一组定义明确的有限工具，你可以实现广泛的功能。关键工具包括代码执行、网络搜索、文件读取和数据分析。对于每个工具，你需要定义以下内容并将其作为系统提示的一部分：\n\n*   **工具名称**：功能的唯一、描述性名称。\n    \n*   **工具描述**：清晰解释工具的作用以及何时使用它。这有助于智能体确定何时选择正确的工具。\n    \n*   **工具输入模式**：一个模式，概述必需和可选参数、它们的类型以及任何约束。智能体根据用户查询使用此模式填写所需的输入。\n    \n*   **指向运行工具的位置 / 方式**。\n    \n\n示例：以下是来自 Langchain (https://github.com/langchain-ai/langchain/blob/master/libs/community/langchain\\_community/tools/arxiv/tool.py)社区的 Arxiv 工具实现的摘录。此实现需要一个 ArxivAPIWrapper 实现(https://github.com/langchain-ai/langchain/blob/master/libs/community/langchain\\_community/utilities/arxiv.py)。\n\n```\n\"\"\"Tool for the Arxiv API.\"\"\"\n```\n\n在某些情况下，仍需要优化工具以获得期望的性能。这可能涉及通过一些提示工程调整工具名称或描述，设置高级配置来处理常见错误，或者过滤工具的输出。\n\n2.5 决定内存处理策略\n------------\n\n大语言模型受其上下文窗口的限制，即它们一次可以 “记住” 的令牌数量。在多轮对话中的过去交互、冗长的工具输出或智能体所基于的额外上下文等情况下，内存可能会很快填满。这就是为什么拥有可靠的内存处理策略至关重要。\n\n在智能体中，内存是指系统存储、记忆和利用过去交互信息的能力。这使智能体能够随着时间的推移保持上下文，根据先前的交流改进其响应，并提供更个性化的体验。\n\n常见内存处理策略：\n\n*   滑动内存：在内存中保留最后 k 轮对话，并丢弃更早的对话。\n    \n*   token内存：保留最后 n 个token，丢弃其余的。\n    \n*   总结式内存：使用大语言模型在每一轮对话时总结对话内容，并丢弃单个消息\n    \n\n此外，你还可以让大语言模型检测关键时刻并存储在长期记忆中。这使得智能体能够 “记住” 关于用户的重要事实，从而使体验更加个性化。\n\n* * *\n\n到目前为止我们所涵盖的五个步骤为设置智能体奠定了基础。但是，如果在这个阶段我们通过大语言模型运行用户查询会发生什么呢？\n\n![Image 9: Image](https://mmbiz.qpic.cn/mmbiz_png/2lV2gxZP551rvLsudBXeo8K9RHPm0Id3DMTiaCguJXmc0cw4tH7xZdGxsBhrx2UcM8SNG6sia0KTGH22j52SuNAw/640?wx_fmt=png&from=appmsg)\n\n以下是可能出现的情况的一个示例：\n\n```\nUser Message: Extract key insighs from this dataset\n```\n\n在这一点上，智能体会产生原始文本输出。那么我们如何让它实际执行下一步呢？这就是解析和编排发挥作用的地方。\n\n2.6 解析智能体的原始输出\n--------------\n\n解析器是一种将原始数据转换为应用程序可以理解和处理的格式（如具有属性的对象）的函数。\n\n对于我们正在构建的智能体，解析器需要识别我们在 2.2 中定义的通信结构，并返回结构化输出，如 JSON。这使应用程序更容易处理和执行智能体的下一步骤。\n\n注意：一些模型提供商（如 OpenAI）默认可以返回可解析的输出。对于其他模型，尤其是开源模型，这需要进行配置。\n\n2.7 编排Agent的下一步骤\n----------------\n\n最后一步是设置编排逻辑。这决定了大语言模型输出结果后会发生什么。根据输出，你将：\n\n*   执行工具调用，或者\n    \n*   返回答案，即对用户查询的最终响应或要求更多信息的后续请求。\n    \n\n![Image 10: Image](https://mmbiz.qpic.cn/mmbiz_png/2lV2gxZP551rvLsudBXeo8K9RHPm0Id3SEeo55MuqD5UXCic8qYjOj1E1ej3maHU3k3hvoza1ljQqtr9g2LRaTQ/640?wx_fmt=png&from=appmsg)\n\n如果触发了工具调用，工具的输出将被发送回大语言模型（作为其工作记忆的一部分）。然后，大语言模型将决定如何处理这个新信息：要么执行另一个工具调用，要么向用户返回答案。\n\n以下是这种编排逻辑在代码中可能呈现的示例：\n\n```\ndef orchestrator(llm_agent, llm_output, tools, user_query):\n```\n\n现在你拥有了一个能够处理各种各样场景的系统，从竞争分析和高级研究到自动化复杂工作流程。\n\n2.8 多智能体系统在什么情况下适用\n------------------\n\n虽然这一代大语言模型非常强大，但它们有一个关键限制：它们难以处理信息过载。过多的上下文或工具可能会使模型不堪重负，导致性能问题。通用型单智能体最终会遇到这个瓶颈，尤其是因为Agent通常消耗大量token。\n\n对于某些应用场景而言，采用多智能体的设置可能更合理。通过将职责分配给多个智能体，你能够避免单个大语言模型智能体的上下文负担过重，并提高整体效率。\n\n话虽如此，通用的单智能体设置对于制作原型来说是一个很好的开始。它可以帮助你快速测试你的使用案例，并确定在哪些地方开始出现问题。通过这个过程，你可以：\n\n*   了解任务的哪些部分确实能从智能体方法中获益。\n    \n*   确定在更大的工作流程中可作为独立流程拆分出来的组件。\n    \n\n从单个智能体入手能让你获得宝贵的见解，以便在扩展到更复杂的系统时改进你的方法。\n\n3\\. 入门建议\n========\n\n使用框架是快速测试和迭代智能体配置的好方法。\n\n*   如果你计划使用像 Llama 3 这样的开源模型，可以尝试 Bee Agent Framework （https://github.com/i-am-bee/bee-agent-framework）的入门模板（https://github.com/i-am-bee/bee-agent-framework-starter）。\n    \n*   如果你计划使用像 OpenAI 这样的前沿模型，可以尝试 LangGraph 的教程（https://langchain-ai.github.io/langgraph/how-tos/react-agent-from-scratch/#define-nodes-and-edges）。\n    \n",
    "created_at": "2025-03-12T02:32:32Z",
    "updated_at": "2025-03-15T03:21:39Z",
    "labels": [],
    "url": "https://github.com/kaozb/ai-arctl/issues/16"
  },
  {
    "id": 17,
    "title": "DeepSeek-R1背后的思维链（CoT）技术",
    "content": "DeepSeek-R1背后的思维链（CoT）技术\n===============\n                                                                         \n\n             \n\n  \n\n![Image 1: cover_image](https://mmbiz.qpic.cn/mmbiz_jpg/2lV2gxZP552WQjfOJfc9ys1lImXvAYApM28ckyhNvYDEF7NCadmTjibKCescVmOq3sclBs0ejibxaj44F3NuvbPw/0?wx_fmt=jpeg)\n\nDeepSeek-R1背后的思维链（CoT）技术\n========================\n\nOriginal 乘风破浪jxj [鸿煊的学习笔记](javascript:void(0);)\n\n![Image 2: profile_qrcode](https://mp.weixin.qq.com/mp/qrcode?scene=10000005&size=102&__biz=Mzg4MDAzNjMyMg==&mid=2247487179&idx=1&sn=d43b8cc231b9c10fa3aaa1691815d74f&send_time=)\n\n鸿煊的学习笔记\n\n包括但不限于机器学习、深度学习、数据挖掘、自然语言处理、大数据、算法等人工智能相关领域的知识。\n\n133篇原创内容\n\n_2025年02月15日 14:23_\n\n推荐阅读\n\n*   [Open-R1：首个DeepSeek-R1开源复现](https://mp.weixin.qq.com/s?__biz=Mzg4MDAzNjMyMg==&mid=2247487050&idx=1&sn=b63a890d5a562121939fb3169665d547&scene=21#wechat_redirect)\n    \n*   [探索 DeepSeek V3：强大的开源语言模型](https://mp.weixin.qq.com/s?__biz=Mzg4MDAzNjMyMg==&mid=2247486822&idx=1&sn=a1c606c6c25945fd33979b9f2e5b5fcc&scene=21#wechat_redirect)\n    \n*   [DeepSeek-R1 万字解读](https://mp.weixin.qq.com/s?__biz=Mzg4MDAzNjMyMg==&mid=2247487063&idx=1&sn=01f067eab4af28f88d5fe919b33b4522&scene=21#wechat_redirect)\n    \n*   [DeepSeek 蒸馏技术：AI 模型的 “轻装上阵” 秘籍](https://mp.weixin.qq.com/s?__biz=Mzg4MDAzNjMyMg==&mid=2247487113&idx=1&sn=949566099a01306e54079a09523a5e95&scene=21#wechat_redirect)\n    \n*   [一文读懂 DeepSeek-R1 的 “最强外挂” GRPO 算法](https://mp.weixin.qq.com/s?__biz=Mzg4MDAzNjMyMg==&mid=2247487120&idx=1&sn=0ad3d5fae841fa349335c43a9bc2d06b&scene=21#wechat_redirect)\n    \n\n  \n\n1\\. 思维链（CoT）究竟是什么？2\\. DeepSeek-R1 如何运用思维链（CoT）？3\\. Chain-of-Thought Prompting 是什么？4\\. 如何让大语言模型（LLM）生成思维链？\n\nAI 圈超火的 DeepSeek-R1 模型！它在逻辑推理、数学计算、复杂问答这些难题面前，就像开了挂一样厉害。而它的 “秘密武器”之一就是思维链（CoT）技术，今天咱们就一起来揭开它的神秘面纱！\n\n1\\. 思维链（CoT）究竟是什么？\n==================\n\n思维链（Chain of Thought，简称 CoT），简单来说，就是让大模型模仿人类思考的过程。大家想想，咱们平时遇到复杂问题时，是不是会一步步分析，最后得出答案？思维链就是让模型也这么干，把复杂问题拆分成一个个简单步骤，再逐步推导，这样就能得出最终答案！\n\n![Image 3: Image](https://mmbiz.qpic.cn/mmbiz_png/2lV2gxZP552WQjfOJfc9ys1lImXvAYApcjAib9kYgL2Nx4ptDDvOiaibRKKn6Ol9RfrMlcD1UXe3ibItHKDVFfZdEA/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)\n\n这个超厉害的概念，是在《Chain-of-Thought Prompting Elicits Reasoning in Large Language Models》这篇论文里提出的。它有很多厉害的地方：\n\n*   **智能分配计算力**：碰到那种需要多步推理的难题，思维链能把问题拆成中间步骤，让模型把更多的计算能力用在刀刃上，专门攻克这些难题。\n    \n*   **可解释性超强**：以前模型给出答案，咱们都不知道它咋想的。现在有了思维链，就像给模型的思考过程开了一扇窗，能清楚看到它是怎么得出答案的。要是推理过程出了错，也能顺着这个思路去检查、调试。\n    \n*   **应用超广泛**：不管是数学应用题、常识推理，还是符号操作，思维链都能大显身手。而且从理论上讲，只要是人类能用语言解决的问题，它都有可能搞定！\n    \n*   **激发超简单**：在足够大的现成语言模型里，只要在少样本提示的示例里加一些思维链序列的例子，就能轻松激发模型的思维链推理能力。\n    \n\n![Image 4: Image](https://mmbiz.qpic.cn/mmbiz_png/2lV2gxZP552WQjfOJfc9ys1lImXvAYApyrymb0uMWRocnalmdCP3qjV0R1BzC70L7vqib1Z4p0YtGco9VFKj3mg/640?wx_fmt=png&from=appmsg)\n\n2\\. DeepSeek-R1 如何运用思维链（CoT）？\n=============================\n\nDeepSeek-R1 模型在使用思维链技术的时候，有一套自己的 “训练秘籍”。\n\n首先，它得让模型具备输出思维链的能力。\n\n然后，再通过人类反馈强化学习（RLHF）和基于规则的推理奖励（Rule Base Reward for Reasoning）对模型进行强化训练。\n\n经过这样的训练，DeepSeek-R1 模型在推理的时候，就能自然而然地生成思维链，还能按照咱们人类期望的方式来思考和回答问题！\n\n![Image 5: Image](https://mmbiz.qpic.cn/mmbiz_png/2lV2gxZP552WQjfOJfc9ys1lImXvAYApRI0K9nAiclaPHmA5GCofKvVdwc5fl3K80hMhsIibibnicuZaM4JZScgYlQ/640?wx_fmt=png&from=appmsg)\n\n3\\. Chain-of-Thought Prompting 是什么？\n===================================\n\n这是引导大语言模型生成思维链的关键方法。简单来讲，就是在给模型的提示里，加入中间推理步骤的示例，这样就能引导模型生成类似的思维链啦。具体有这几个步骤：\n\n1.  **分步提示设计**：在编写大模型应用时，咱们可以用特定格式的提示（Prompt）来要求模型展示思考过程。比如说，用 “Let's think step by step” 这样的关键词，就能触发模型一步步推理。而且它还支持零样本（Zero-shot）和少样本（Few-shot）两种模式，就算没有太多示例，也能让模型开动脑筋！\n    \n2.  **中间状态生成**：模型会把中间推理步骤生成文本，每一个步骤都能作为后面推理的基础，就像搭积木一样，一步一步搭出完整的推理过程。它是通过自回归的方式，逐步生成这些内容的。\n    \n3.  **结果提取**：等模型把推理过程都写出来了，咱们就能从生成的文本里找到最终答案啦。一般像 “Therefore, the answer is” 这样的关键词后面，跟着的就是答案。\n    \n\n![Image 6: Image](https://mmbiz.qpic.cn/mmbiz_png/2lV2gxZP552WQjfOJfc9ys1lImXvAYApFXUCnY7r0MiaYmEOXY332dzxgzFBA6MArao5OZrScLSsVgmZ1D4RCiag/640?wx_fmt=png&from=appmsg)\n\n4\\. 如何让大语言模型（LLM）生成思维链？\n=======================\n\n方法就是刚刚提到的 Chain-of-Thought Prompting。\n\n在少样本提示里，给每个示例都加上和答案相关的思维链。这些示例得清楚展示出，怎么从问题出发，经过一系列中间步骤，最后得出结论。这样一来，大语言模型在遇到新问题时，就会照着这些示例的思路，分解问题、生成思维链了。\n\n![Image 7: Image](https://mmbiz.qpic.cn/mmbiz_png/2lV2gxZP552WQjfOJfc9ys1lImXvAYApj8Q1yeoNjE118s6BDFFcpeLWuib28KXHOPj8KDkG9qTrQKcVnaD3icPg/640?wx_fmt=png&from=appmsg)\n",
    "created_at": "2025-03-12T02:40:10Z",
    "updated_at": "2025-03-15T03:21:12Z",
    "labels": [],
    "url": "https://github.com/kaozb/ai-arctl/issues/17"
  },
  {
    "id": 6,
    "title": "RAG检索增强之Reranker重排序模型详解！",
    "content": "RAG检索增强之Reranker重排序模型详解！\n===============\n                                                                         \n\n             \n\n  \n\n![Image 1: cover_image](https://mmbiz.qpic.cn/sz_mmbiz_jpg/Zvl9ickIYtdKswZvzlnLibrGogBlccFEIut2cyvOSq4Moed30aoo6TJrlrnmGINxQOKen66uj4YMcSEa1gBOEMEg/0?wx_fmt=jpeg)\n\nRAG检索增强之Reranker重排序模型详解！\n========================\n\nOriginal 郭小喵玩AI [小喵学AI](javascript:void(0);)\n\n![Image 2: profile_qrcode](https://mp.weixin.qq.com/mp/qrcode?scene=10000005&size=102&__biz=Mzg2MzkwNDM0OQ==&mid=2247488883&idx=1&sn=03c98bccee4458a46ea68fb32d3aa88d&send_time=)\n\n小喵学AI\n\n专注于分享C++/Python编程、计算机视觉、自然语言处理、大模型等深度学习与人工智能领域干货、应用。\n\n154篇原创内容\n\n_2025年03月07日 02:38_\n\n什么是Reranker模型？\n--------------\n\nReRanker模型是对RAG检索返回的结果进行重新排序的模型。也就是下图所示中2nd Retrieval的模型。具体来说，ReRanker模型在RAG Pipeline中扮演着第二阶段的角色，即在初始检索步骤之后，对检索出的文档块chunks进行重新排序，以确保相关的文档块优先被传递给LLM进行处理。\n\n![Image 3: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/Zvl9ickIYtdKswZvzlnLibrGogBlccFEIuddRMomhxp4Kk6GehE0l8dge04mrBl7OAjariaZqMicnTVK2GlqNp2hMA/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)\n\n  \n\n为什么需要Reranker模型？\n----------------\n\n在回答这个问题之前，我们先深入了解一下背后的问题。\n\nRAG通过在大量文本文档中进行语义搜索来工作，这些文档数量可能达到数十亿。为了实现大规模搜索的快速响应，我们一般采用向量搜索技术，即将文本转化为向量后，放入一个向量空间内，通过余弦相似度等度量标准来比较它们与查询向量之间的相似度。\n\n向量搜索的前提是需要向量。这些向量基本上是将文本背后的意义压缩成固定维度的向量（如768或1536维），这一过程不可避免地会导致信息丢失。因此，常常会发现，即便是排名靠前的文档，也可能会遗漏一些关键信息。\n\n如果较低位置的文档包含了有助于LLM更好地形成回答的相关信息，这些信息就很容易被忽略。这该怎么办？一个简单的方法就是增加返回的文档数量，即增加top\\_k值，并将它们全部传递给LLM。\n\n我们此处关注的指标是召回率，即“我们检索到了多少相关文档”。值得注意的是，召回率衡量的是系统能够找到的相关文档的比例，而不考虑检索到的文档总数。因此，理论上通过返回所有文档可以实现完美的召回率。\n\n然而，这在实际操作中是不可行的，一是因为大语言模型（LLM）对输入文本量有一定的限制，我们称之为**「上下文窗口」**。即使像Anthropic 的 Claude这样的模型拥有高达100K Token的巨大上下文窗口，也不能无限制地增加输入文本量。二是当上下文窗口被过多的Token填满时，大语言模型的回忆能力和执行指令的效果都会受到影响。研究表明，过度填充上下文窗口会降低模型在该窗口中检索信息的能力，从而影响生成回答的质量。\n\n![Image 4: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/Zvl9ickIYtdKswZvzlnLibrGogBlccFEIu7uUybgZo4PUGKInPxibjcNA3O1m5XlSMHQ7tVzl3GDJFOicaDLEn3hoQ/640?wx_fmt=png&from=appmsg)\n\n  \n\n为了解决召回率和LLM上下文窗口之间的矛盾，Reranker模型提供了一种有效的解决方案。具体步骤如下：\n\n1.  最大化检索召回率\n    \n    ❝在初始检索阶段，通过增加向量数据库返回的文档数量（即增加 top\\_k 值），可以提高检索的召回率。这意味着尽可能多地检索相关文档，确保不会遗漏任何可能有助于 LLM 形成高质量回答的信息。\n    \n    ❞\n    \n2.  重新排序并筛选最相关的文档\n    \n    ❝在第二阶段，使用 Reranker 模型对检索到的大量文档进行\\> 重新排序。Reranker 模型能够更精确地评估查询与文档的相\\> 关性，筛选出最相关的文档，并减少最终传递给 LLM 的文档\\> 数量。这一步骤的关键在于：\n    \n    ❞\n    \n\n*   重新排序：根据查询和文档的相关性分数对文档进行重新排序。\n    \n*   筛选：只保留最相关的文档，确保这些文档在 LLM 的上下文窗口内。\n    \n\n4.  确保 LLM 处理高质量信息\n    \n    ❝通过上述两步，Reranker 模型不仅提高了检索的召回率，还确保了传递给 LLM 的文档是最相关的。这使得 LLM 能够基于高质量的信息生成更准确、更有价值的回答，同时避免了上下文窗口过载的问题。\n    \n    ❞\n    \n\nReranker模型的原理\n-------------\n\n重排序模型（也被称为Cross-Encoder）是一种模型，能够针对一个查询和文档对，输出它们的相似度分数。我们利用这个分数对文档按照与查询的相关性进行重新排序。\n\n![Image 5: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/Zvl9ickIYtdKswZvzlnLibrGogBlccFEIu9PUYG1ewbvTeM3TUP7WyoIhdV3NMZicqibtpUv0vZpuvxVOibquDEibCicA/640?wx_fmt=png&from=appmsg)\n\n  \n\n其本质是一个包含两阶段的检索系统：\n\n*   第一阶段：快速检索（Vector DB或Bi-Encoder检索）：使用双编码器（Bi-Encoder）或稀疏嵌入模型从大数据集中快速提取一组相关文档。这一阶段的核心目标是高效地缩小搜索范围，确保能够在短时间内处理大规模数据集。双编码器将查询和文档分别编码为向量，并通过余弦相似度等度量标准计算它们的相似性。\n    \n*   第二阶段：精确重排序（Reranker / Cross-Encoder）：使用重排序模型（Reranker）对第一阶段提取的文档进行重新排序。Reranker模型能够更精确地评估查询与文档的相关性，输出它们的相似度分数，并根据相似度分数对文档进行重新排序，返回最相关的前K个文档。这一阶段的目标是提高检索结果的相关性，确保最相关的文档优先传递给大语言模型（LLM）。\n    \n\n为什么采用两阶段策略？\n-----------\n\n是因为从大数据集中检索少量文档的速度远快于对大量文档进行重排序。简而言之，重排序器处理较慢，而检索器速度快。\n\n尽管重排序器的处理速度较慢，但我们仍然选择使用它们，关键在于其精确度远超过嵌入模型。\n\n双编码器（Bi-Encoder）精度较低的根本原因在于：\n\n1.  双编码器将文档和查询分别编码为固定维度的向量（如768或1536维），这一过程不可避免地会导致信息丢失。文本的丰富语义被压缩成一个低维向量，无法完全保留原始文本的所有潜在含义。\n    \n2.  双编码器在用户提出查询之前就已经创建了嵌入，因此它对查询的具体内容一无所知。这意味着它只能生成一个泛化的、平均化的含义，而无法针对具体查询进行优化。这种静态的嵌入方式限制了其在处理复杂查询时的表现。\n    \n\n而重排序器（Reranker / Cross-Encoder）能够在大型Transformer中直接处理原始文本信息，避免了信息压缩带来的损失。它可以直接分析查询和文档的原始文本，确保所有相关信息都能被充分考虑。\n\n然而，尽管重排序器具有更高的精度，但它也有代价，就是需要更多的时间来生成相似度分数。\n\n![Image 6: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/Zvl9ickIYtdKswZvzlnLibrGogBlccFEIumYcK9XAXQibVUMsMwphcU5Qz21R02ax89qznjFic12MTuYrf7tjj6aPg/640?wx_fmt=png&from=appmsg)\n\n  \n\n因此在实际应用中，通常会结合两者优势，采用两阶段检索策略：\n\n*   第一阶段：使用双编码器快速检索出一批候选文档。\n    \n*   第二阶段：使用重排序器对这批候选文档进行重新排序，确保最终返回的文档是最相关的。\n    \n\n这种组合方式既能保证检索的速度，又能提高结果的准确性。例如，在处理4000万条记录的情况下，如果仅使用重排序器，可能会需要超过50小时来返回一个查询结果；而使用双编码器和向量搜索，则可以在不到100毫秒内完成初步筛选。随后，再用重排序器对筛选出的少量文档进行精排，既提高了效率又保证了质量。\n",
    "created_at": "2025-03-10T07:28:44Z",
    "updated_at": "2025-03-15T03:20:33Z",
    "labels": [],
    "url": "https://github.com/kaozb/ai-arctl/issues/6"
  },
  {
    "id": 8,
    "title": "一文读懂大模型RAG：检索、增强与生成的技术详解",
    "content": "一文读懂大模型RAG：检索、增强与生成的技术详解\n===============\n                                                                         \n\n             \n\n  \n\n![Image 1: cover_image](https://mmbiz.qpic.cn/sz_mmbiz_jpg/Zvl9ickIYtdLD5GmG63jJ6bib4eib5VaNRJlKwDmLcGLUIdHunMwzTpFlC6rzNMDdCpNl17pHnLxVcEhTI2eEibYYA/0?wx_fmt=jpeg)\n\n一文读懂大模型RAG：检索、增强与生成的技术详解\n========================\n\nOriginal 郭小喵玩AI [小喵学AI](javascript:void(0);)\n\n![Image 2: profile_qrcode](https://mp.weixin.qq.com/mp/qrcode?scene=10000005&size=102&__biz=Mzg2MzkwNDM0OQ==&mid=2247488831&idx=1&sn=35f65afa16b06ca3c8898766210823be&send_time=)\n\n小喵学AI\n\n专注于分享C++/Python编程、计算机视觉、自然语言处理、大模型等深度学习与人工智能领域干货、应用。\n\n154篇原创内容\n\n_2025年03月03日 08:32_\n\n大模型（Large Language Model，LLM）的浪潮已经席卷了几乎各行业，但当涉及到专业场景或行业细分领域时，通用大模型往往面临专业知识不足的问题。相对于成本昂贵的“Post-Training”或“Supervised Fine-Tuning”（监督微调，SFT），基于RAG的技术方案成为了一种更优选择。\n\n本文笔者将从RAG所解决的问题及模拟场景入手，详细总结相关技术细节，与大家分享~\n\n初识：RAG所解决的问题及模拟场景\n-----------------\n\n### 大模型“幻觉”问题\n\n在探讨RAG技术的必要性之前，我们首先需要理解大模型中有名的“幻觉”问题。\n\n所谓“幻觉”，是指大模型在试图生成内容或回答问题时，输出的结果并不完全正确，甚至会有错误，即通常所说的“一本正经地胡说八道”。因此，**「这种“幻觉”可以提现在对事实的错误陈述与编造、错误的复杂推理或在复杂语境下处理能力不足等。」**\n\n而产生这种“幻觉”的主要原因是：\n\n1.  **「训练知识存在偏差」**：在训练大模型时输入的海量知识可能包含错误、过时，甚至带有偏见的信息。这些信息在被大模型学习后，就可能在未来的输出中被重现。\n    \n2.  **「过度泛化地推理」**：大模型尝试通过大量的语料来学习人类语言的普遍规律与模式，这可能导致“过度泛化”的现象，即把普通的模式推理用到某些特定场景，就会产生不准确的输出。\n    \n3.  **「理解存在局限性」**：大模型并没有真正“理解”训练知识的深层含义，也不具备人类普遍的常识与经验，因此可能会在一些需要深入理解与复杂推理的任务中出错。\n    \n4.  **「缺乏特定领域的知识」**：通用大模型虽然掌握了大量人类通用知识且具备超强的记忆与推理能力，但可能不是某个垂直领域的专家（比如医学或者法律专家）。当面临一些复杂度较高的领域性问题或私有知识相关的问题时（比如介绍企业的某个新产品），它就可能会编造信息并将其输出。\n    \n\n除了“幻觉”问题，大模型还可能存在知识落后、输出难以解释、输出不确定等问题。\n\n这也决定了大模型在大规模商业生产应用中面临着挑战：很多时候，我们不仅需要大模型具备理解力和创造力，还需要极高的准确性。例如，在金融风险评估、医疗诊断、法律咨询等领域，任何错误的输出都可能导致严重的后果。因此，解决“幻觉”问题是提升大模型实际应用价值的关键。\n\n### RAG如何解决“幻觉”问题？\n\nRAG（Retrieval-Augmented Generation，检索增强生成）技术正是为了尽可能解决大模型在实际应用中面临的一些问题，特别是“幻觉”问题而诞生的。其基本思想可以简单表述如下：\n\n将传统的生成式大模型与实时信息检索技术相结合，为大模型补充来自外部的相关数据与上下文，以帮助大模型生成更丰富、更准确、更可靠的内容。这允许大模型在生成内容时可以依赖实时与个性化的数据与知识，而不只是依赖训练知识。\n\n换句话说，RAG给大模型增加了一个可以快速查找的知识外挂，使得它在面对特定问题时能够参考最新的、权威的信息源，从而减少错误输出和“幻觉”的发生。\n\n![Image 3: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/Zvl9ickIYtdLD5GmG63jJ6bib4eib5VaNRJdqgzldSQ2ls88vLY1sicgbTeHmazv7JPF8pWBwc5VjadvMIaLNGgQXA/640?wx_fmt=png&from=appmsg)\n\n  \n\n为了更进一步帮助我们理解RAG的概念，举个例子。\n\n如果把大模型比喻成一个经过大量医学知识与治疗技能训练的优秀学生，大模型响应的过程比喻成一场医学考试，那么这个学生在考试时仍然可能会对某些最新的治疗方法并不熟悉，他可能会根据自己的记忆和推理能力编造答案（即“幻觉”），导致错误。 而RAG会从最新的医学文献中检索相关信息，并提供给学生作为参考。这样，学生就可以基于最新的专业知识来回答问题，避免了“幻觉”，提高了答题的准确性和可靠性。\n\n### 模拟简单的RAG场景\n\n假如你需要开发一个在线的自助产品咨询工具，允许客户使用自然语言进行交互式的产品问答，比如“请介绍一下您公司这款产品与××产品的不同之处”。为了让客户有更好的体验，你决定使用大模型来构造这样的咨询功能并将其嵌入公司的官方网站。如果你直接使用通用大模型，那么结果很可能如下所示。\n\n**「用户提问：」**\n\n> ❝请介绍小麦公司的最新手机产品小麦Pro与iPhone有什么区别？\n> \n> \\[引用\\]❞\n\n不出意外，大模型显然不具备贵公司的最新手机产品知识，因此无法回答客户的问题（有时候可能会尝试编造答案）。现在，如果你使用RAG的思想，那么可以先从企业私有的知识库中**「检索出下面一段相关的补充知识」**：\n\n> ❝小麦Pro手机参数简览：\n> \n> *   系统：安卓最新版本\n>     \n> *   处理器：高性能八核处理器\n>     \n> *   显示屏：6.7英寸AMOLED全面屏，2K分辨率\n>     \n> *   后置摄像头：主摄像头6400万像素，四摄系统\n>     \n> *   前置摄像头：3200万像素，AI美颜、HDR功能\n>     \n> *   内存与存储：最高可选12GB运行内存，最高512GB存储空间\n>     \n> *   电池：5000mAh大容量电池，支持快速充电\n>     \n> *   网络：支持5G网络，Wi-Fi6，蓝牙5.2\n>     \n> *   其他特性：IP68防水防尘，面部识别和指纹识别解锁 小麦Pro以其强大的性能、清晰的显示效果、出色的摄像能力以及长久续航等特点，为用户提供优质的手机体验。\n>     \n> \n> ❞\n\n你再把检索出的补充知识组装到提示词中，将其输入大模型，并要求大模型基于提供的知识来回答你的问题。大模型很聪明地“吸收”了补充的外部知识，并结合自己已经掌握的知识，成功推理并给出了答案：\n\n**「RAG增强后的回答：」**\n\n> ❝小麦Pro手机与iPhone12之间的主要区别可以从以下几个方面来比较：\n> \n> 操作系统：\n> \n> *   小麦Pro采用安卓最新版本作为操作系统，而iPhone12运行的是苹果自家的iOS操作系统。这意味着两者的用户界面、应用生态系统、功能和定制性可能会有所不同。 处理器性能：\n>     \n> *   小麦Pro配备了一款高性能的八核处理器，而iPhone12搭载了苹果自家设计的A14仿生芯片。尽管具体的性能表现可能需要进行实际测试来比较，但两者都应该能够提供流畅的用户体验。 显示屏：\n>     \n> *   小麦Pro采用了6.7英寸的AMOLED全面屏，分辨率达到了2K级别，而iPhone12则配备了6.1英寸的屏幕。 其他特性：\n>     \n> *   小麦Pro拥有更大的电池容量（5000mAh），支持更快的充电速度，并且具备更高的防水防尘等级（IP68）。\n>     \n> \n> ❞\n\nRAG基础概念\n-------\n\n### 什么是RAG?\n\n**「RAG（Retrieval-Augmented Generation，检索增强生成）」**是一种结合了检索和生成技术的自然语言处理(NLP)模型。该模型由Facebook AI提出，旨在提升生成式模型在处理开放域问答、对话生成等任务中的性能。\n\nRAG模型通过引入外部知识库，利用检索模块（Retriever）从大量文档中提取相关信息，并将这些信息传递给生成模块（Generator），从而生成更加准确和有用的回答或文本。\n\n其核心思想是通过检索和生成的有机结合，弥补生成模型（如GPT-3、BERT等）在处理知识密集型任务时的不足。在传统的LLM（大语言模型）应用中，模型仅依赖训练时学到的知识来回答问题，这导致了知识更新困难、回答可能过时或不准确等问题。而RAG系统通过在生成回答前主动检索相关信息，将实时、准确的知识作为上下文提供给模型，从而显著提升了回答的质量和可靠性。\n\nRAG本质上是一种借助“外挂”的提示工程，但绝不仅限于此。它不仅仅是简单地将外部知识拼接到提示词中，而是通过一系列优化手段，确保大模型能够更好地理解和利用这些外部知识，从而提高输出答案的质量。\n\nRAG架构\n-----\n\nRAG模型的技术架构可以分为两个主要模块：检索模块（Retriever）和生成模块（Generator）。\n\n![Image 4: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/Zvl9ickIYtdLD5GmG63jJ6bib4eib5VaNRJ0frKVJap6yxPGKXnKHqe8s5cfPfkynKgeWiaPa8OTpywDbC6fjAz6CA/640?wx_fmt=png&from=appmsg)\n\n  \n\n**「检索模块」**\n\n负责从大规模的知识库或文档集合中，使用预训练的双塔模型（dual-encoder）进行高效的向量化检索，快速找到与查询最相关的若干个文档或段落。\n\n**「生成模块」**\n\n根据检索到的文档和输入查询生成最终的回答或文本。并使用强大的生成模型（如T5、BART等）对输入进行处理，确保生成的内容连贯、准确且信息丰富。\n\n### RAG工作流程\n\n通过结合检索增强技术，将用户查询与外部知识库中的信息融合，利用大语言模型生成准确、可靠的回答。以下是RAG的完整工作流程：\n\n1.  知识准备\n    \n\n*   收集知识文档：从企业内部文档、公开数据集、专业数据库等来源收集相关知识文档。\n    \n*   预处理：对文档进行清洗、去重、分段等操作，确保数据质量。\n    \n*   索引化：将处理后的文档分割为适合检索的单元（如段落或句子），并建立索引以便快速查找。\n    \n\n3.  嵌入与索引\n    \n\n*   使用嵌入模型：利用预训练的嵌入模型（如BERT、Sentence-BERT等）将文本转换为高维向量表示。\n    \n*   存储向量：将生成的向量存储在向量数据库（如FAISS、Elasticsearch、Pinecone等）中，构建高效的索引结构。\n    \n\n5.  查询检索\n    \n\n*   用户查询向量化：将用户的自然语言查询通过嵌入模型转换为向量表示。\n    \n*   相似度计算：在向量数据库中计算查询向量与存储向量之间的相似度（通常使用余弦相似度或欧氏距离）。\n    \n*   检索结果排序：根据相似度得分，选择若干个最相关的文档或段落作为检索结果。\n    \n\n7.  提示增强\n    \n\n*   组装提示词：将检索到的相关文档内容与原始用户查询组合成一个新的输入序列。\n    \n*   优化提示模板：根据任务需求设计提示模板，确保生成模块能够充分利用检索到的信息。例如：\n    \n    > ❝用户查询：请介绍小麦Pro手机与iPhone的区别。 检索结果：小麦Pro采用安卓系统，配备高性能八核处理器，6.7英寸AMOLED屏幕，5000mAh电池。 增强提示：基于以下信息回答问题：“小麦Pro采用安卓系统，配备高性能八核处理器，6.7英寸AMOLED屏幕，5000mAh电池。”\n    > \n    > ❞\n    \n\n9.  生成回答\n    \n\n*   输入增强提示：将增强提示模板输入生成模块（如T5、BART、GPT等）。\n    \n*   生成文本：生成模块根据提示模板生成最终的回答，综合考虑检索到的知识和自身的训练知识。\n    \n*   后处理：对生成的回答进行格式调整、语法检查等后处理，确保输出的质量和一致性。\n \n",
    "created_at": "2025-03-10T07:30:17Z",
    "updated_at": "2025-03-14T14:29:37Z",
    "labels": [],
    "url": "https://github.com/kaozb/ai-arctl/issues/8"
  },
  {
    "id": 7,
    "title": "深入理解RAG中的嵌入模型Embedding Model",
    "content": "深入理解RAG中的嵌入模型Embedding Model\n===============\n                                                                         \n\n             \n\n  \n\n![Image 1: cover_image](https://mmbiz.qpic.cn/sz_mmbiz_jpg/Zvl9ickIYtdKzvLL2BAYicBx5lTpOrBp80zN59qbLh8vA60BF9n1p3t4HMYqwxicpl5TCBiauL6cbu4yknN1Ette3Q/0?wx_fmt=jpeg)\n\n深入理解RAG中的嵌入模型Embedding Model\n============================\n\n[小喵学AI](javascript:void(0);)\n\n![Image 2: profile_qrcode](https://mp.weixin.qq.com/mp/qrcode?scene=10000005&size=102&__biz=Mzg2MzkwNDM0OQ==&mid=2247488843&idx=1&sn=b78fc76a1599a77d2af232996a72fb2f&send_time=)\n\n小喵学AI\n\n专注于分享C++/Python编程、计算机视觉、自然语言处理、大模型等深度学习与人工智能领域干货、应用。\n\n154篇原创内容\n\n_2025年03月05日 03:50_\n\n在当前流行的RAG引擎（例如RAGFlow、Qanything、Dify、FastGPT等）中，嵌入模型（Embedding Model）是必不可少的关键组件。在RAG引擎中究竟扮演着怎样的角色呢？本文笔者进行了总结，与大家分享~\n\n什么是Embedding？\n-------------\n\n在学习嵌入模型之前，我们需要先了解什么是Embedding。简单来说，Embedding是一种将离散的非结构化数据（如文本中的单词、句子或文档）转换为连续向量的技术。\n\n在自然语言处理（NLP）领域，Embedding通常用于将文本映射为固定长度的实数向量，以便计算机能够更好地处理和理解这些数据。每个单词或句子都可以用一个包含其语义信息的向量来表示。\n\nEmbedding常用于将文本数据映射为固定长度的实数向量，从而使计算机能够更好地处理和理解这些数据。每个单词或句子都可以用一个包含其语义信息的实数向量来表示。\n\n![Image 3: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/Zvl9ickIYtdIDzjD7HMjZY4s3V0aDJvz2YNNgpXic2tQIw46F6hXeVMHXr3T3ePoW0w9sD45DTFx0ricNhx5UfdVw/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)\n\n  \n\n以“人骑自动车”为例，在计算机中，单词是以文字形式存在的，但计算机无法直接理解这些内容。Embedding的作用就是将每个单词转化为向量，例如：\n\n*   “人”可以表示为 \\[0.2, 0.3, 0.4\\]\n    \n*   “骑”可以表示为 \\[0.5, 0.6, 0.7\\]\n    \n*   “自行车”可以表示为 \\[0.8, 0.9, 1.0\\]\n    \n\n通过这些向量，计算机可以执行各种计算，比如分析“人”和“自行车”之间的关系，或者判断“骑”这个动作与两者之间的关联性。\n\n此外，Embedding还可以帮助计算机更好地处理和理解自然语言中的复杂关系。例如：\n\n*   相似的词（如“人”和“骑手”）在向量空间中会比较接近。\n    \n*   不相似的词（如“人”和“汽车”）则会比较远。\n    \n\n**「那么为什么需要向量呢？」**\n\n因为计算机只能处理数字，无法直接理解文字。通过将文本转换为向量，相当于为数据分配了一个数学空间中的“地址”，使计算机能够更高效地理解和分析数据。\n\n什么是Embedding Model？\n-------------------\n\n在自然语言处理（NLP）中，嵌入模型（Embedding Model） 是一种将词语、句子或文档转换成数字向量的技术。它通过将高维、离散的输入数据（如文本、图像、声音等）映射到低维、连续的向量空间中，使得计算机能够更好地理解和处理这些数据。\n\n![Image 4: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/Zvl9ickIYtdIDzjD7HMjZY4s3V0aDJvz2s4Ug7OrTooWh3ILbps3cMG1z84zqMW3KibrbGkT6OnPqM5iaGjRZ0d6Q/640?wx_fmt=png&from=appmsg)\n\n  \n\nEmbedding Model就像是给每个词或句子分配一个独特的“指纹”，这个“指纹”能够在数学空间中表示这个词或句子的含义。具体来说，这种模型将每个词语或句子转换成一个固定长度的数字向量。通过这种方式，计算机可以对文本进行各种数学计算，例如：\n\n*   比较词语的相似性：通过计算两个词语向量之间的距离（如余弦相似度），可以判断它们在语义上的相似程度。\n    \n*   分析句子的意义：通过对句子中的所有词语向量进行聚合（如平均值或加权和），可以得到整个句子的向量表示，并进一步分析其语义信息。\n    \n\n这种技术在许多NLP任务中具有重要意义，以下是几个典型的应用示例：\n\n*   语义搜索：通过计算查询向量与文档库中各文档向量的相似度，找到与查询最相关的文档或段落。例如，用户输入“如何制作披萨？”，系统会返回最相关的烹饪指南。\n    \n*   情感分析：判断一段文本的情感倾向（如正面、负面或中性）。例如，对于一篇产品评论“这款手机性能出色，但电池续航一般”，系统可以分析出该评论整体上是正面的，但也存在一些负面因素。\n    \n*   机器翻译：将一种语言的文本转换为另一种语言。例如，用户输入“我喜欢猫”，系统将其转换为对应的英文翻译“I like cats”。\n    \n*   问答系统：根据用户的问题，从知识库中检索相关信息并生成回答。例如，用户提问“太阳有多大？”，系统通过嵌入模型找到相关天文学文档，并生成详细的回答。\n    \n*   文本分类：将文本归类到预定义的类别中。例如，新闻文章可以被自动分类为政治、体育、科技等不同类别，基于其内容的向量表示。\n    \n*   命名实体识别（NER）：识别文本中的特定实体（如人名、地名、组织名等）。例如，在一段文字“李华在北京大学学习”中，系统可以识别出“李华”是人名，“北京大学”是组织名。\n    \n\nEmbedding Model的作用\n------------------\n\n在RAG引擎中，嵌入模型（Embedding Model） 扮演着至关重要的角色。它用于将文本转换为向量表示，以便进行高效的信息检索和文本生成。以下是Embedding Model在RAG引擎中的具体作用和示例：\n\n1.  文本向量化\n    \n\n*   作用：将用户的问题和大规模文档库中的文本转换为向量表示。\n    \n*   举例：在RAG引擎中，用户输入一个问题，如“如何制作意大利面？”，Embedding Model会将这个问题转换为一个高维向量。\n    \n\n3.  信息检索\n    \n\n*   作用：使用用户的查询向量在文档库的向量表示中检索最相似的文档。\n    \n*   举例：RAG引擎会计算用户问题向量与文档库中每个文档向量的相似度，然后返回最相关的文档，这些文档可能包含制作意大利面的步骤。\n    \n\n5.  上下文融合\n    \n\n*   作用：将检索到的文档与用户的问题结合，形成一个新的上下文，用于生成回答。\n    \n*   举例：检索到的关于意大利面的文档会被Embedding Model转换为向量，并与问题向量一起作为上下文输入到生成模型中。\n    \n\n7.  生成回答\n    \n\n*   作用：利用融合了检索文档的上下文，生成模型生成一个连贯、准确的回答。\n    \n*   举例：RAG引擎结合用户的问题和检索到的文档，生成一个详细的意大利面制作指南作为回答。\n    \n\n9.  优化检索质量\n    \n\n*   作用：通过微调Embedding Model，提高检索的相关性和准确性。\n    \n*   举例：如果RAG引擎在特定领域（如医学或法律）中使用，可以通过领域特定的数据对Embedding模型进行微调，以提高检索的质量。\n    \n\n11.  多语言支持\n    \n\n*   作用：在多语言环境中，Embedding Model可以处理和理解不同语言的文本。\n    \n*   举例：如果用户用中文提问，而文档库包含英语内容，Embedding Model需要能够处理两种语言的文本，并将它们转换为统一的向量空间，以便进行有效的检索。\n    \n\n13.  处理长文本\n    \n\n*   作用：将长文本分割成多个片段，并为每个片段生成Embedding，以便在RAG引擎中进行检索。\n    \n*   举例：对于长篇文章或报告，Embedding Model可以将其分割成多个部分，每个部分都生成一个向量，这样可以在不损失太多语义信息的情况下提高检索效率。\n    \n\n通过以上几点，Embedding Model在RAG引擎中提供了一个桥梁，连接了用户查询和大量文本数据，使得信息检索和文本生成成为可能。如下图所示，Embedding Model正处于整个RAG系统的中心位置。\n\n![Image 5: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/Zvl9ickIYtdIDzjD7HMjZY4s3V0aDJvz2naYWhbiaAHaUyTJeUHdabcjgqHWPFEcAb0dS4haOicxDZPNnZnibl6LNQ/640?wx_fmt=png&from=appmsg)\n\n  \n\nRAG引擎中的工作流\n----------\n\n以下是一个RAG引擎中工作流的示意图，此流程基本与各大RAG引擎相匹配。虽然各个不同的RAG引擎内部算法可能有所区别，但整体工作流程大同小异。\n\n![Image 6: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/Zvl9ickIYtdIDzjD7HMjZY4s3V0aDJvz2S5dE75SwYJY8vZ26f5FP9n0j12cPmUfPeSFJaYncEZH2VwvJr3gu6w/640?wx_fmt=png&from=appmsg)\n\n  \n\n**「流程说明」**\n\n1.  查询嵌入化：将用户输入的查询传递给嵌入模型，并在语义上将查询内容表示为嵌入的查询向量。\n    \n2.  向量数据库查询：将嵌入式查询向量传递给向量数据库。\n    \n3.  检索相关上下文：检索前k个相关上下文——通过计算查询嵌入和知识库中所有嵌入块之间的距离（如余弦相似度）来衡量检索结果。\n    \n4.  上下文融合：将查询文本和检索到的上下文文本传递给对话大模型（LLM）。\n    \n5.  生成回答：LLM 将使用提供的内容生成回答内容。\n    \n\n预览时标签不可点\n",
    "created_at": "2025-03-10T07:29:34Z",
    "updated_at": "2025-03-14T14:21:10Z",
    "labels": [],
    "url": "https://github.com/kaozb/ai-arctl/issues/7"
  },
  {
    "id": 15,
    "title": "7种RAG 架构及其核心组件概览",
    "content": "7种RAG 架构及其核心组件概览\n===============\n                                                                         \n\n             \n\n  \n\n![Image 1: cover_image](https://mmbiz.qpic.cn/mmbiz_jpg/2lV2gxZP550icSicEvMuMr6RXJ4THec8UW4uvCD720gRS6VQNjwFib6L7n5d79dpgibWgibibEWdSCDenXo99lBVnoQw/0?wx_fmt=jpeg)\n\n7种RAG 架构及其核心组件概览\n================\n\nOriginal 鸿煊 [鸿煊的学习笔记](javascript:void(0);)\n\n![Image 2: profile_qrcode](https://mp.weixin.qq.com/mp/qrcode?scene=10000005&size=102&__biz=Mzg4MDAzNjMyMg==&mid=2247486772&idx=1&sn=564ecc2f9ba1f33cd7e9915f583c83c1&send_time=)\n\n鸿煊的学习笔记\n\n包括但不限于机器学习、深度学习、数据挖掘、自然语言处理、大数据、算法等人工智能相关领域的知识。\n\n133篇原创内容\n\n_2024年12月20日 13:50_\n\nRetrieval-Augmented Generation（RAG）架构正发挥着日益重要的作用。它通过在 AI 生成过程中引入外部知识检索，极大地提升了 AI 回答的准确性和全面性，从基础的文档查询逐步发展为多模态、多智能体协同的智能架构。本文将概览 RAG 架构从基础到高级的 7 种模式及其核心组件。\n\n![Image 3: Image](https://mmbiz.qpic.cn/sz_mmbiz_jpg/1niaDLWmibsweY5W8gOTHWEGZW0ib3NH3Hr0b4h0rJiccI7Haqys0zviafgoTEFQp2iaib4ERxwoT1Of2KKdhD6kAVaTg/640?wxfrom=5&usePicPrefetch=1&wx_fmt=jpeg&tp=webp&wx_lazy=1&wx_co=1)\n\n### 一、RAG 的 7 种模式\n\n### （一）Naive RAG：基础架构的构建\n\nNaive RAG 是 RAG 架构的最基础形式。其工作流程主要包含三个关键步骤：文档检索、处理和生成响应。在文档检索阶段，系统会根据用户的查询在文档库中查找相关内容；接着对检索到的文档进行处理，为后续生成响应做准备；最后，生成模型利用这些处理后的信息生成最终的回答。这种简单直接的架构为 RAG 技术奠定了基石，让我们初步领略到如何将外部知识引入 AI 生成过程。\n\n### （二）Retrieve-and-rerank：优化检索结果\n\n在 Naive RAG 的基础上，Retrieve-and-rerank 模式增加了重排序步骤。当完成初始的文档检索后，重排序模型会根据一定的标准对检索结果进行重新排序。这样做的目的是优化检索结果的相关性，使得最终提供给生成模型的上下文信息更加精准。通过这种方式，系统能够更好地筛选出与用户查询最为相关的文档片段，从而进一步提高生成响应的质量。\n\n### （三）Multimodal RAG：突破文本限制\n\nMultimodal RAG 的独特之处在于它能够处理多种类型的数据，而不仅仅局限于文本。在当今数字化时代，信息的形式多种多样，如图像、音频等。Multimodal RAG 可以将这些不同模态的数据进行整合处理，例如在处理包含图像的文档时，它能够同时理解图像中的信息以及与之相关的文本描述。这一模式拓宽了 RAG 架构的应用范围，使其能够适应更加复杂和多样化的信息环境。\n\n### （四）Graph RAG：挖掘知识连接\n\nGraph RAG 利用图数据库来增强知识连接。在这种模式下，文档之间的关系不再是孤立的，而是通过图结构进行表示。图数据库可以更好地捕捉文档之间的语义关联和逻辑关系，例如一篇关于科技的文章可能与其他相关的技术文档、研究报告等通过引用、相似主题等关系连接起来。这样，当进行查询时，系统能够基于这种知识图谱更深入地理解文档间的关系，提供更有深度和广度的上下文信息，从而提升回答的准确性和全面性。\n\n### （五）Hybrid RAG：融合多种技术优势\n\nHybrid RAG 正如其名，结合了多种技术的优势。它既包含了图结构所带来的知识关系理解能力，又融合了传统检索方法的高效性。这种融合使得 Hybrid RAG 在处理复杂查询时能够灵活运用不同技术的长处。例如，在某些情况下，传统检索方法可以快速定位到相关文档，而图结构则有助于进一步挖掘文档之间深层次的联系，从而为生成模型提供更丰富、更准确的信息，以生成高质量的响应。\n\n### （六）Agentic RAG Router：智能路由查询\n\nAgentic RAG Router 引入了 AI Agent 来路由和处理查询。AI Agent 在这里扮演着智能决策的角色，它能够根据用户查询的特点、当前系统的状态以及可用资源等因素，选择最适合的处理路径。例如，当面对不同类型的查询时，它可以决定是直接从向量数据库中检索信息，还是需要调用其他外部工具或服务。这种智能路由机制提高了系统的效率和灵活性，使得 RAG 架构能够更好地应对多样化的用户需求。\n\n### （七）Agentic RAG Multi - Agent：多智能体协同工作\n\nAgentic RAG Multi - Agent 模式则更进一步，它使用多个专门的 AI Agent 协同工作。这些智能体可以分别负责不同的任务，并且能够调用不同的工具，如向量搜索、网页搜索、Slack、Gmail 等。例如，一个智能体负责在向量数据库中进行高效的信息检索，另一个智能体则可以通过网页搜索获取最新的外部信息，还有的智能体可以与 Slack 或 Gmail 等通信工具交互，获取相关的团队协作或邮件信息。通过多智能体的协同合作，RAG 架构能够整合来自多个渠道和资源的信息，为用户提供更加全面和准确的回答。\n\n二、RAG 架构的核心组件\n-------------\n\n### （一）嵌入模型\n\n嵌入模型在 RAG 架构中起着关键作用，它负责将文本转换为向量表示。这种向量表示能够将文本的语义信息以一种数学形式呈现，使得计算机能够更好地理解和处理文本之间的相似性和相关性。例如，在文档检索阶段，通过将查询和文档都转换为向量，系统可以快速计算它们之间的相似度，从而找到与查询最相关的文档。\n\n### （二）生成模型\n\n生成模型是负责最终内容生成的核心组件。它基于检索到的上下文信息，运用自身的算法和训练知识，生成回答用户查询的文本内容。生成模型的性能和质量直接影响着 RAG 架构输出的准确性和流畅性。不同的生成模型可能具有不同的特点和优势，如某些模型在生成自然语言描述方面表现出色，而另一些模型则在处理特定领域知识时更加准确。\n\n### （三）重排序模型\n\n重排序模型专注于优化检索结果的相关性。在文档检索完成后，重排序模型会根据预先设定的规则和算法，对检索到的文档进行重新评估和排序。这些规则可能涉及文档与查询的关键词匹配程度、语义相关性、文档的质量和权威性等多个因素。通过重排序，系统能够确保提供给生成模型的上下文信息是最相关和最有价值的。\n\n### （四）向量数据库\n\n向量数据库是存储和检索向量化内容的重要设施。它为 RAG 架构提供了高效的数据存储和检索能力，能够快速定位与查询向量相似的文档向量。向量数据库的设计和性能对于整个 RAG 系统的效率至关重要，它需要能够处理大规模的向量数据，并支持快速的相似性搜索操作。\n\n### （五）提示模板\n\n提示模板在 RAG 架构中起到规范化查询处理的作用。它为用户查询提供了一种标准化的格式，使得系统能够更好地理解用户的意图。同时，提示模板也可以包含一些预定义的指令或引导信息，帮助生成模型更好地生成响应。例如，模板可以规定查询的结构、需要包含的关键信息等，从而提高整个系统的准确性和一致性。\n\n### （六）AI Agent\n\nAI Agent 是 RAG 架构中的智能决策和任务协调者。在不同的模式中，AI Agent 发挥着不同的作用，如在 Agentic RAG Router 中进行查询路由决策，在 Agentic RAG Multi - Agent 中协调多个智能体的工作。它能够根据系统的目标、环境和用户需求，动态地调整系统的行为，实现高效的任务执行和资源利用。\n\n",
    "created_at": "2025-03-12T02:29:24Z",
    "updated_at": "2025-03-14T14:06:28Z",
    "labels": [],
    "url": "https://github.com/kaozb/ai-arctl/issues/15"
  },
  {
    "id": 4,
    "title": "请回答 2025丨印象最深的 AI 技术突破是什么？",
    "content": "请回答 2025丨印象最深的 AI 技术突破是什么？\n===============\n                                                                         \n\n             \n\n  \n\n![Image 1: cover_image](https://mmbiz.qpic.cn/sz_mmbiz_jpg/0v4p9yzE7NLPG6PhZufvUrRNPWHZ4MttNvZiaPLbiaYf4mFYdAOTwwf8f3gtODLkQ1h2ziaUTypjZqtvqK6IRrzEg/0?wx_fmt=jpeg)\n\n请回答 2025丨印象最深的 AI 技术突破是什么？\n==========================\n\n特工小坏 [特工宇宙](javascript:void(0);)\n\n![Image 2: profile_qrcode](https://mp.weixin.qq.com/mp/qrcode?scene=10000005&size=102&__biz=Mzk0NTYzNDQ5NQ==&mid=2247507934&idx=1&sn=38631a0f13ceaf8606b84a0e7325423e&send_time=)\n\n特工宇宙\n\nAgent Universe，专注于智能体的AI科技媒体。\n\n197篇原创内容\n\n_2025年02月05日 14:44_\n\n![Image 3: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/0v4p9yzE7NLPG6PhZufvUrRNPWHZ4MtticHBr9Dl8eJxQeQ687ico0jQj11DNtt7XWyuJHaU8u4eT7ypqpLf0hXQ/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)\n\n![Image 4: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/0v4p9yzE7NLPG6PhZufvUrRNPWHZ4MttAz5WF4eaYw3mFxvHD7RkzOIgor8ykh9XaDYorKorYawP3A7WSqyxCw/640?wx_fmt=png&from=appmsg)\n\n![Image 5: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/0v4p9yzE7NLPG6PhZufvUrRNPWHZ4MtticsaXgZa8rfOfHDlCNiajxldb3ic4CBvRSc8OEQyLaPgaEbT9Vicv2TbHw/640?wx_fmt=png&from=appmsg)\n\n![Image 6: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/0v4p9yzE7NLPG6PhZufvUrRNPWHZ4MttuHmH9Jxz9yCM9vqY1NEN5G2sb4cSLJ2m1hbbGa4nlfWJxWCibmGgffw/640?wx_fmt=png&from=appmsg)\n\n  \n\n![Image 7: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/0v4p9yzE7NLPG6PhZufvUrRNPWHZ4Mttna0crMyc4jVx77c2pld6TE65ZkT950fSL71ibBD2rhb8AH82bROq1pQ/640?wx_fmt=png&from=appmsg)\n\n![Image 8: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/0v4p9yzE7NLPG6PhZufvUrRNPWHZ4MttibgPyAubuRk3wI91zzjibnibWKibssJOtlLgSFRo8LhhzYFxhLbKRJUuVg/640?wx_fmt=png&from=appmsg)\n\n![Image 9: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/0v4p9yzE7NLPG6PhZufvUrRNPWHZ4MtteoXTfhxiaUrFvjWjZ7se7w4taibIibaiaO8UiaSj1XlFR7V8TbAAF3wzL6Q/640?wx_fmt=png&from=appmsg)\n\n![Image 10: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/0v4p9yzE7NLPG6PhZufvUrRNPWHZ4MttSON2CFBoGFArIIGNpru6CXPWsoaCje19SK7uPHkCU5Hib3EC4aAUnMw/640?wx_fmt=png&from=appmsg)\n\n![Image 11: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/0v4p9yzE7NLPG6PhZufvUrRNPWHZ4MttIZsltiauNV5zVE26JWwA7ON6y9Uk2nxU23V8Djk8icn3cqBLgf9tTRcg/640?wx_fmt=png&from=appmsg)\n\n![Image 12: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/0v4p9yzE7NLPG6PhZufvUrRNPWHZ4MttDib6tWMn9RpxvycnRh5KSjbDibyNQpf2ZbVSqLU2e2df27S4ZUrqvg8w/640?wx_fmt=png&from=appmsg)\n\n![Image 13: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/0v4p9yzE7NLPG6PhZufvUrRNPWHZ4Mtt7SZfhyCccs3EsrLYctvnYfr20arsxfFIXO2UFD3qHgbia9Dz3N5t6Tg/640?wx_fmt=png&from=appmsg)\n\n![Image 14: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/0v4p9yzE7NLPG6PhZufvUrRNPWHZ4MttbY76h5kgeajvYh6x596uicIXjxpIWmNebdsHIr9icnC1SyJOtMISK9mw/640?wx_fmt=png&from=appmsg)\n\n![Image 15: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/0v4p9yzE7NLPG6PhZufvUrRNPWHZ4Mtt22Vicv4GnicZ2wSNauTRibTicWxUv7OoWjxjI8wfkCGX02RJTTnXOrob9w/640?wx_fmt=png&from=appmsg)\n\n",
    "created_at": "2025-03-10T06:11:50Z",
    "updated_at": "2025-03-14T14:05:29Z",
    "labels": [],
    "url": "https://github.com/kaozb/ai-arctl/issues/4"
  },
  {
    "id": 14,
    "title": "一文读懂 RAG 中的 embedding model",
    "content": "一文读懂 RAG 中的 embedding model\n===============\n                                                                         \n\n             \n\n  \n\n![Image 1: cover_image](https://mmbiz.qpic.cn/mmbiz_jpg/2lV2gxZP550WkVlCiaiaeSfyezM17xVpm76bGQX95epjEBONN8h6c7sNMh0NtNnbLv9I3U66f0gHzjMZt86EZ4NA/0?wx_fmt=jpeg)\n\n一文读懂 RAG 中的 embedding model\n===========================\n\nOriginal 乘风破浪jxj [鸿煊的学习笔记](javascript:void(0);)\n\n![Image 2: profile_qrcode](https://mp.weixin.qq.com/mp/qrcode?scene=10000005&size=102&__biz=Mzg4MDAzNjMyMg==&mid=2247487438&idx=1&sn=c22b261cb7923eec1d12d902ad578403&send_time=)\n\n鸿煊的学习笔记\n\n包括但不限于机器学习、深度学习、数据挖掘、自然语言处理、大数据、算法等人工智能相关领域的知识。\n\n133篇原创内容\n\n_2025年03月10日 16:01_\n\n1\\. Embedding 究竟是什么？2\\. Embedding Model 揭秘3\\. 嵌入模型在 RAG 引擎中的关键作用\n\n在当今人工智能的浪潮中，RAG（检索增强生成）技术大放异彩，像是 RAGFlow、Qanything、Dify、FastGPT 等 RAG 引擎，逐渐走进大家的视野。在这些强大的 RAG 引擎背后，有一个关键组件起着不可或缺的作用，它就是嵌入模型（Embedding Model）。今天，就让我们一起深入了解一下这个神秘的嵌入模型吧！\n\n1\\. Embedding 究竟是什么？\n====================\n\n在了解嵌入模型之前，得先搞清楚 Embedding 的概念。简单来说，Embedding 是一种 “神奇魔法”，能把离散的非结构化数据，比如文本里的单词、句子或者整篇文档，转化成连续向量。\n\n在自然语言处理（NLP）领域，它的作用尤为突出。计算机 “看不懂” 文本内容，而 Embedding 就负责把文本变成固定长度的实数向量，让计算机能够理解和处理。\n\n![Image 3: Image](https://mmbiz.qpic.cn/mmbiz_png/2lV2gxZP550WkVlCiaiaeSfyezM17xVpm7ReVBf19dzib0ibRnBW3gd8w2vnY1MaZ8Asykm9Lsqm43lP1vN8vhTaCQ/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)\n\n比如说 “人骑自行车” 这句话，计算机面对 “人”“骑”“自行车” 这些文字时一脸茫然，但经过 Embedding 的 “加工”，“人” 可以表示为 \\[0.2, 0.3, 0.4\\] ，“骑” 表示为 \\[0.5, 0.6, 0.7\\] ，“自行车” 表示为 \\[0.8, 0.9, 1.0\\] 。有了这些向量，计算机就能大显身手了，它可以分析 “人” 和 “自行车” 之间的关系，判断 “骑” 这个动作和它们的关联性。\n\n而且，Embedding 还能帮助计算机处理自然语言里复杂的关系。像 “人” 和 “骑手” 这种相似的词，在向量空间里就离得很近；而 “人” 和 “汽车” 不相似，在向量空间里就离得很远。这是为什么呢？因为计算机只认识数字，把文本转化成向量，就相当于给数据在数学空间里找了个 “地址”，计算机处理起来就更高效啦。\n\n2\\. Embedding Model 揭秘\n======================\n\n在自然语言处理中，嵌入模型（Embedding Model）是将词语、句子或文档转换成数字向量的技术。它就像一个 “指纹生成器”，给每个词或句子分配一个独特的 “指纹”，这个 “指纹” 就是在数学空间里表示它们含义的固定长度数字向量。\n\n![Image 4: Image](https://mmbiz.qpic.cn/mmbiz_png/2lV2gxZP550WkVlCiaiaeSfyezM17xVpm73T2DOFOKMpd9ErmESzmibwHSWvvewH99icKoKGajq1MvUCk2pt56ia17w/640?wx_fmt=png&from=appmsg)\n\n借助这个模型，计算机能对文本进行各种数学计算。比如计算两个词语向量之间的距离（像余弦相似度），就能知道它们在语义上有多相似；把句子里所有词语向量聚合起来（求平均值或者加权和），就能得到整个句子的向量表示，进而分析句子的语义信息。\n\n嵌入模型在很多 NLP 任务中都有重要应用：\n\n*   **语义搜索**：输入 “如何制作披萨？”，系统通过计算查询向量和文档库中各文档向量的相似度，就能找到最相关的烹饪指南。\n    \n*   **情感分析**：面对 “这款手机性能出色，但电池续航一般” 这样的产品评论，系统能分析出整体是正面评价，但也有负面因素。\n    \n*   **机器翻译**：输入 “我喜欢猫”，系统能把它翻译成英文 “I like cats”。\n    \n*   **问答系统**：提问 “太阳有多大？”，系统借助嵌入模型找到相关天文学文档，给出详细回答。\n    \n*   **文本分类**：根据内容向量表示，把新闻文章自动分类成政治、体育、科技等类别。\n    \n*   **命名实体识别（NER）**：在 “李华在北京大学学习” 这句话里，能识别出 “李华” 是人名，“北京大学” 是组织名。\n    \n\n3\\. 嵌入模型在 RAG 引擎中的关键作用\n======================\n\n在 RAG 引擎里，嵌入模型可是 “顶梁柱”，主要有以下这些作用：\n\n*   **文本向量化**：把用户的问题和大规模文档库中的文本都转化为向量。比如用户问 “如何制作意大利面？”，嵌入模型就把这个问题变成高维向量。\n    \n*   **信息检索**：用用户的查询向量在文档库的向量表示里找最相似的文档。RAG 引擎计算问题向量和文档库中每个文档向量的相似度，返回和制作意大利面步骤相关的文档。\n    \n*   **上下文融合**：把检索到的文档和用户问题结合，形成新的上下文，用于生成回答。关于意大利面的文档被嵌入模型转成向量后，和问题向量一起作为上下文，输入到生成模型里。\n    \n*   **生成回答**：生成模型利用融合后的上下文，生成连贯、准确的回答。RAG 引擎结合问题和检索到的文档，生成详细的意大利面制作指南。\n    \n*   **优化检索质量**：通过微调嵌入模型，提升检索的相关性和准确性。在医学或法律这些特定领域使用 RAG 引擎时，可以用领域特定数据微调嵌入模型，让检索结果更靠谱。\n    \n*   **多语言支持**：在多语言环境下，嵌入模型能处理不同语言的文本。用户用中文提问，文档库是英文内容，嵌入模型要把两种语言的文本都转化到统一的向量空间，方便检索。\n    \n*   **处理长文本**：把长文本分割成多个片段，给每个片段生成 Embedding，提高检索效率。长篇文章或报告可以被分成多个部分，每个部分都生成向量，还不会损失太多语义信息。\n    \n\n从 RAG 引擎的工作流（查询嵌入化、向量数据库查询、检索相关上下文、上下文融合、生成回答）中也能看出，嵌入模型处于核心位置，它就像一座桥梁，连接着用户查询和大量文本数据，让信息检索和文本生成得以实现。\n\n![Image 5: Image](https://mmbiz.qpic.cn/mmbiz_png/2lV2gxZP550WkVlCiaiaeSfyezM17xVpm7UwKdGqUanI6am3XcEObHTsPEy75Z4xZfiaVUlADdiah4Ff2o35HntAqg/640?wx_fmt=png&from=appmsg)\n\n",
    "created_at": "2025-03-12T02:06:16Z",
    "updated_at": "2025-03-14T14:02:09Z",
    "labels": [],
    "url": "https://github.com/kaozb/ai-arctl/issues/14"
  },
  {
    "id": 10,
    "title": "深入浅出大模型：预训练、监督微调、强化学习、RLHF",
    "content": "深入浅出大模型：预训练、监督微调、强化学习、RLHF\n===============\n                                                                         \n\n             \n\n  \n\n![Image 1: cover_image](https://mmbiz.qpic.cn/sz_mmbiz_jpg/SaeK9tW7Buibv7KkmmNAvYicy1jv4CZ4q1YziaSC8PNibI3Kuj3NvsHKmNWRgicJ8kzM8mO7yCjMVJpKerAYwBELRwA/0?wx_fmt=jpeg)\n\n深入浅出大模型：预训练、监督微调、强化学习、RLHF\n==========================\n\n\n### 本文分为两大部分：\n\n*   ### 第1部分： 涵盖LLM的基础知识，包括从预训练到后训练、神经网络、幻觉现象（Hallucinations）以及推理过程。\n    \n*   ### 第2部分：人工智能/人类反馈强化学习（RLHF）、o1模型研究、DeepSeek R1、AlphaGo。\n    \n\n让我们开始吧！首先，我们来看LLM是如何构建的。\n\n**第1部分**\n\n**从整体上看，训练LLM主要包括两个关键阶段：**预训练（Pre-training）**和**后训练（Post-training）**。**\n\n### \n\n### **1\\. 预训练（Pre-training）**\n\n**在LLM能够生成文本之前，它首先必须学习语言的工作方式，而这一过程就是预训练——一个极其计算密集的任务。**\n\n#### \n\n#### ****步骤1：数据收集与预处理****\n\n**训练LLM的第一步是收集尽可能多的高质量文本数据。目标是创建一个庞大且多样化的数据集，涵盖广泛的人类知识。**\n\n**一个常见的数据来源是**Common Crawl**，这是一个免费的、开放的网页爬取数据存储库，包含过去18年间约2500亿个网页的数据。然而，原始网页数据往往比较嘈杂——其中包含垃圾信息、重复内容和低质量文本，因此**数据预处理至关重要**。**\n\n**https://commoncrawl.org/**\n\n**如果你对经过预处理的数据集感兴趣，**FineWeb**提供了一个整理后的Common Crawl版本，并已在Hugging Face上公开可用。**\n\n**https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1**\n\n![Image 3: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/SaeK9tW7Buibv7KkmmNAvYicy1jv4CZ4q1NyjIKBGtrFKrCbhjpwpJOfnXYvibghngJAveicovMHibjenLMTyp6BFOQ/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)\n\n一旦文本语料库经过清理，就可以进行分词（Tokenization）处理。\n\n### **步骤2：分词（Tokenization）**\n\n在神经网络处理文本之前，文本必须先转换为**数值形式**。这一过程就是**分词**，它将单词、子词或字符映射为唯一的数值**token**。\n\n可以把**token**想象成构建语言模型的**基本单元**——所有语言模型的核心组件。在GPT-4中，可能的token数量为**100277**个。\n\n一个常见的分词工具是**Tiktokenizer**，它允许你进行分词实验，并查看文本是如何被拆解为token的。\n\nhttps://tiktokenizer.vercel.app/\n\n你可以尝试输入一句话，看看每个单词或子词是如何被分配一系列数值ID的。\n\n![Image 4: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/SaeK9tW7Buibv7KkmmNAvYicy1jv4CZ4q1TsjxsLIlq5nfib4svWN6uiaNkgRvCibcugqJaicjaSQoeyQyZZWtHxCS1Q/640?wx_fmt=png&from=appmsg)\n\n### **步骤3：神经网络训练（Neural Network Training）**\n\n一旦文本被分词处理，神经网络就会学习**根据上下文预测下一个token**。模型会接收一串输入token（例如“我正在烹饪”），然后通过一个**庞大的数学表达式**——即模型的架构——进行处理，以预测下一个token。\n\n![Image 5: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/SaeK9tW7Buibv7KkmmNAvYicy1jv4CZ4q1xDvDia8pB9HFGezOn7uFUQqBy56yEMGVFUArW9nrH62uZNlH5ickLuYg/640?wx_fmt=png&from=appmsg)\n\n一个**神经网络**主要由两个关键部分组成：\n\n*   参数（参数权重，Weights）：通过训练学习得到的数值。\n    \n*   架构（数学表达式，Architecture）：定义输入token如何被处理以生成输出的结构。\n    \n\n### **最初，模型的预测是随机的**，但随着训练的进行，它逐渐学会为可能的下一个token分配概率。\n\n###   \n\n### 当正确的token（例如“食”）被识别后，模型会通过**反向传播（Backpropagation）**来调整**数十亿个参数（权重）**。这是一个优化过程，通过提高正确预测的概率、降低错误预测的概率来强化模型的学习。\n\n这个过程会在**海量数据集**上重复数十亿次。\n\n**基础模型（Base Model）：预训练的产物**\n---------------------------\n\n在这一阶段，基础模型已经学会了：\n\n*   **单词、短语和句子之间的关联**\n*   **训练数据中的统计模式**\n\n然而，**基础模型并未针对真实世界任务进行优化**。你可以将其类比为一个**高级自动补全系统**——它能够基于概率预测下一个token，但缺乏良好的**指令跟随能力**。\n\n基础模型有时会**逐字复述训练数据**，并且可以通过**上下文学习（In-Context Learning）**进行特定应用，即在提示（Prompt）中提供示例来引导模型的响应。但为了让模型真正**有用且可靠**，它还需要进一步训练。\n\n**2\\. 后训练（Post-Training）：让模型更实用**\n---------------------------------\n\n基础模型是**未经打磨的**。为了让它更加**实用、可靠、安全**，需要进行**后训练（Post-Training）**，即在**更小、更专业的数据集**上进行微调。\n\n由于**神经网络无法像传统软件那样被显式编程**，我们只能通过**训练它**来“编程”它，即让它学习**有结构的、带标注的数据集**，这些数据代表了理想的交互示例。\n\n### \n\n### **后训练的方式**\n\n后训练阶段会创建**专门的数据集**，这些数据集包含**结构化的示例**，指导模型在不同情况下的回应方式。\n\n1.  指令/对话微调（Instruction/Conversation Fine-Tuning）\n    \n    目标让模型学会遵循指令、执行任务、进行多轮对话、遵守安全规范、拒绝恶意请求等。例如，InstructGPT（2022），OpenAI聘请了约40名合同工来创建这些标注数据集。这些人工标注者编写提示（Prompts）并提供基于安全指南的理想响应。如今，许多数据集由AI自动生成，再由人工审核和编辑以确保质量。\n    \n2.  领域特定微调（Domain-Specific Fine-Tuning）\n    \n    目标使模型适应特定领域，如医学、法律、编程等。\n    \n\n此外，后训练还会引入特殊token——这些token在预训练阶段并未使用，它们有助于模型理解**交互的结构**。这些token可以标记**用户输入的起始与结束**，以及**AI响应的起始位置**，确保模型能够正确区分**提示（Prompt）和回答（Reply）**。\n\n  \n\n**3\\. 推理（Inference）——模型如何生成新文本**\n--------------------------------\n\n推理（Inference）可以在**任何阶段**进行，甚至可以在**预训练中途**执行，以评估模型的学习效果。\n\n当模型接收到一组**输入token**后，它会根据在训练过程中学到的模式，为所有可能的**下一个token**分配概率。\n\n但模型**并非总是选择最可能的token**，而是会**在概率分布中进行采样**——类似于**抛掷一个带偏向的硬币**，其中高概率的token更有可能被选中。\n\n这个过程会**迭代进行**，每个新生成的token都会成为下一次预测的输入。\n\n由于**token选择是随机的**，即使相同的输入也可能**产生不同的输出**。随着推理的进行，模型可以生成**并未直接出现在训练数据中**，但符合**统计模式**的文本。\n\n**4\\. 幻觉（Hallucinations）——当LLM生成错误信息**\n--------------------------------------\n\n幻觉（Hallucination）是指**LLM生成虚假或错误的信息**。\n\n其根本原因在于：**LLM并不“知道”事实**——它只是根据训练数据**预测最可能的单词序列**。\n\n在早期，LLM的**幻觉问题十分严重**。\n\n例如，在下图的案例中，如果训练数据包含大量类似“谁是…”的问题，并且这些问题都有明确答案，那么模型会学习到：**这类查询应该总是有一个自信的回答**，即使它并没有相关知识。\n\n![Image 6: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/SaeK9tW7Buibv7KkmmNAvYicy1jv4CZ4q1nZ88FetuWgywNP4zw2yMX2A5D7YchyI9ibicRyxMwJ2Sbnp2UnBVoqXw/640?wx_fmt=png&from=appmsg)\n\n因此，当被问到一个**未知人物**时，模型不会默认回答“我不知道”，因为这种模式在训练过程中**并未被强化**。相反，它会基于已有模式**生成最可能的猜测**，这往往会导致**编造的信息**。\n\n### **如何减少幻觉？**\n\n#### \n\n#### **方法一：说“我不知道”**\n\n提高事实准确性需要明确地训练模型去识别它不知道的内容——这比看起来要复杂得多。\n\n这是通过自我询问（Self-Interrogation）来完成的，这是一个帮助定义模型知识边界的过程。\n\n自我询问可以通过另一个AI模型来自动化，该模型生成问题以探测知识盲点。如果它生成了错误的答案，就会加入新的训练示例，其中正确的回应是：“我不确定。能否提供更多上下文？”\n\n如果模型在训练中多次看到一个问题，它将为正确答案分配较高的概率。\n\n如果模型以前没有遇到过这个问题，它会在多个可能的token之间更均匀地分配概率，从而使输出更加随机。没有单一token被认为是最可能的选择。\n\n**微调**显式地训练模型处理低置信度的输出，并用预定义的回答来应对。例如，当我问ChatGPT-4o，“谁是 sjuehaxucwq xewdqdqw?”时，它正确地回应：“我不确定那是谁。能否提供更多上下文？”\n\n#### \n\n#### **方法二：进行网络搜索**\n\n一种更先进的方法是通过给予模型访问外部搜索工具，从而扩展模型的知识范围，超出其训练数据。\n\n从高层来看，当模型检测到不确定性时，它可以触发一次网络搜索。然后，搜索结果会被插入到模型的上下文窗口中——本质上允许这些新数据成为模型的工作记忆的一部分。模型在生成响应时会参考这些新信息。\n\n**5\\. 模糊记忆与工作记忆**\n-----------------\n\n一般来说，LLM有两种知识访问方式。\n\n*   模糊记忆模型在预训练过程中存储的知识。这是基于从大量互联网数据中学到的模式，但并不精确，也不可搜索。\n    \n*   工作记忆模型上下文窗口中的信息，在推理过程中可以直接访问。提供的任何文本都作为短期记忆，使模型能够在生成响应时回忆细节。\n    \n\n在上下文窗口中加入相关事实显著提高了响应的质量。\n\n**6\\. 自我认知**\n------------\n\n当被问到“你是谁？”或“是什么构建了你？”等问题时，LLM会根据它的训练数据生成一个统计上最合适的猜测，除非被显式地编程以准确回应。\n\nLLM没有真正的自我意识，它们的回应依赖于训练过程中看到的模式。\n\n为模型提供一致身份的一种方式是使用**系统提示（System Prompt）**，通过设置预定义的指令来描述模型自身、其能力以及其局限性。\n\n### \n\n### **7\\. 结束语**\n\n第一部分就到这里！希望这能帮助你建立起对LLM工作原理的直觉。在第二部分，我们将深入探讨强化学习以及一些最新的模型。\n\n**第2部分**\n\n### **之前，我们讨论了训练LLM的前两个主要阶段：**\n\n1.  ### **预训练从大量数据集中学习，形成基础模型。**\n    \n2.  ### **SFT（Supervised Fine-Tuning，监督微调）用精心挑选的示例来优化模型，使其更加实用。**\n    \n\n现在，我们将深入探讨下一个主要阶段：RL**（Reinforcement Learning，强化学习）**。尽管预训练和SFT已经是成熟的方法，但RL仍在不断发展，并且已成为训练流程中的关键环节。\n\n### \n\n### **RL的目的是什么？**\n\n人类和LLM处理信息的方式不同。对于我们来说——像基本的算术——是直观的，但LLM只将文本看作一串token序列，这对LLM来说并不直观。相反，LLM能够在复杂的主题上生成专家级的回答，仅仅因为它在训练过程中见过足够多的示例。\n\n这种认知差异使得人类注释者很难提供一组“完美”的标签，能够持续地引导LLM找到正确的答案。\n\nRL弥补了这一差距，它允许模型从自身的经验中学习。\n\n模型不仅仅依赖显式的标签，而是探索不同的token序列，并根据哪些输出最有用来获得反馈——奖励信号。随着时间的推移，模型学会了更好地与人类意图对齐。\n\n### \n\n### **RL背后的直觉**\n\nLLM是**随机的**——意味着它们的回答并不是固定的。即使是相同的提示，输出也会有所不同，因为它是从一个概率分布中采样的。\n\n我们可以利用这种随机性，通过并行生成成千上万，甚至数百万个可能的响应。可以把它看作是模型在探索不同的路径——有些是好的，有些是差的。我们的目标是鼓励它更多地选择较好的路径。\n\n为了做到这一点，我们让模型训练在那些导致更好结果的token序列上。与监督微调不同，在监督微调中，人类专家提供标签数据，强化学习则允许模型从自身的学习中获得进步。\n\n模型发现哪些响应最有效，并在每个训练步骤后更新它的参数。随着时间的推移，这使得模型在未来收到相似提示时，更有可能生成高质量的答案。\n\n### \n\n### **但是，如何确定哪些响应是最好的？我们应该进行多少RL训练？这些细节是很复杂的，要做到精准并不简单。**\n\n### \n\n### **RL并不是“新”的——它能超越人类专业水平（AlphaGo，2016）**\n\nRL的强大力量的一个很好的例子是DeepMind的AlphaGo，它是第一个击败职业围棋选手的AI，并最终超越了人类水平。\n\n在2016年的《自然》杂志论文中（如下图所示），当一个模型纯粹通过SFT训练（给模型大量好的例子让其模仿）时，模型能够达到人类水平的表现，但永远无法超越它。\n\n虚线代表韩国围棋选手李世石的表现。这是因为SFT关注的是复制，而非创新——它不能让模型发现超越人类知识的新策略。然而，RL使AlphaGo能够与自己对弈，改进策略，并最终超越人类的专业水平（蓝线）。\n\n![Image 7: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/SaeK9tW7Buibv7KkmmNAvYicy1jv4CZ4q1Wa4qxLpb4Zic3VGc4fyosT5iaZA8ks3BDPsQdG71j2hhp7f4ibCMkLaIw/640?wx_fmt=png&from=appmsg)\n\n### **RL代表了AI的一个令人兴奋的前沿——在我们将模型训练在一个多样且具有挑战性的问题池中时，模型能够探索超越人类想象的策略，从而优化其思维策略。**\n\n### \n\n### **RL基础回顾**\n\n让我们快速回顾一下典型RL设置的关键组成部分：\n\n![Image 8: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/SaeK9tW7Buibv7KkmmNAvYicy1jv4CZ4q1FT0ribAJxRXYlb4btUdnuA6zpPQaslZXrAHpMZOgBjw1ibcLwYUnfMTg/640?wx_fmt=png&from=appmsg)\n\n*   ### **Agent（智能体）** 学习者或决策者。它观察当前的状态（state），选择一个动作（action），然后根据结果（reward）更新其行为。\n    \n*   ### Environment（环境）智能体所操作的外部系统。\n    \n*   ### State（状态）在给定时间步t的环境快照。\n    \n\n在每个时间戳，agent在环境中执行一个动作，该动作将环境的状态改变为新的状态。智能体还会收到反馈，表明该动作的好坏。这个反馈称为奖励（reward），并以数字形式表示。正奖励鼓励该行为，负奖励则不鼓励该行为。\n\n通过使用来自不同状态和动作的反馈，智能体逐渐学习出最佳策略，以便在时间上最大化总奖励。\n\n### \n\n### **策略**\n\n策略是Agent的决策规则。如果Agent遵循一个好的策略，它将始终做出正确的决策，从而在多个步骤中获得更高的奖励。\n\n用数学术语来说，策略是一个函数，它确定给定状态下不同输出的概率：（πθ(a|s)）。\n\n### \n\n### **价值函数**\n\n估计处于某个状态下的好坏程度，考虑长期期望奖励。对于LLM（大语言模型）而言，奖励可能来自人类反馈或奖励模型。\n\n### \n\n### **Actor-Critic架构**\n\n这是一个流行的强化学习设置，结合了两个组件：\n\n1.  Actor（演员）学习并更新策略（πθ），决定在每个状态下应该采取哪个动作。\n    \n2.  Critic（评论者）评估价值函数（V(s)），为演员提供反馈，告知其选择的动作是否导致了好的结果。\n    \n\n**工作原理：**\n\n*   演员基于当前策略选择一个动作。\n    \n*   评论者评估结果（奖励 + 下一个状态）并更新其价值估计。\n    \n*   评论者的反馈帮助演员优化策略，使未来的动作能够获得更高的奖励。\n    \n\n### \n\n### **将其与LLM结合**\n\n状态可以是当前的文本（提示或对话），而动作则是生成的下一个token（词或子词）。奖励模型（例如人类反馈）告诉模型它生成的文本是好是坏。\n\n策略是模型选择下一个token的策略，而价值函数则估计当前文本上下文在最终生成高质量响应方面的有益程度。\n\n### \n\n### **DeepSeek-R1**\n\n为了强调RL的重要性，接下来我们将探索DeepSeek-R1，这是一种推理模型，在保持开源的同时达到了顶尖的性能。该论文介绍了两个模型：DeepSeek-R1-Zero和DeepSeek-R1。\n\n*   DeepSeek-R1-Zero仅通过大规模的RL进行训练，跳过了SFT。\n    \n*   DeepSeek-R1在此基础上构建，解决了遇到的挑战。\n    \n\n![Image 9: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/SaeK9tW7Buibv7KkmmNAvYicy1jv4CZ4q1P2xYPVlO0AeR63Up7guwmmibkmkQYAnOXOmgJW9VkwnGV3TG59GKkLA/640?wx_fmt=png&from=appmsg)\n\n让我们深入探讨一下这些关键点。\n\n### **1\\. RL算法：GRPO**\n\n一个关键的改变游戏规则的RL算法是**GRPO (Group Relative Policy Optimisation，群组相关策略优化)**，它是广受欢迎的PPO（Proximal Policy Optimisation，近端策略优化）的变种。GRPO在2024年2月的《DeepSeekMath》论文中被引入。\n\n**为什么选择GRPO而不是PPO？**\n\nPPO在推理任务中的表现较差，原因如下：\n\n*   依赖于评论者模型（Critic model）。\n    \n*   PPO需要一个单独的评论者模型，实际上会增加内存和计算开销。\n    \n*   训练评论者模型在处理细致或主观任务时可能变得复杂。\n    \n*   高计算成本，因为RL流水线需要大量资源来评估和优化响应。\n    \n*   绝对奖励评估。\n    \n\n当依赖于绝对奖励时——即只有一个标准或度量来判断答案是“好”还是“坏”——它很难捕捉到不同推理领域中开放性任务的细微差别。\n\n**GRPO是如何解决这些挑战的？**\n\nGRPO通过使用相对评估而消除了评论者模型——响应是在一个组内进行比较，而不是通过固定标准来判断。\n\n可以想象学生在解决问题。与其让老师单独批改每个学生的作业，不如让他们比较答案，从中学习。随着时间的推移，表现会趋向于更高质量。\n\n**GRPO如何融入整个训练过程？**\n\nGRPO通过修改损失计算方式，而保持其他训练步骤不变：\n\n1\\. 收集数据（查询 + 响应）\n\n对于LLM，查询就像是问题。\n\n旧策略（模型的旧快照）为每个查询生成多个候选答案。\n\n2\\. 分配奖励——每个组中的响应都会被评分（即“奖励”）。\n\n3\\. 计算GRPO损失通常，你会计算损失——这显示了模型预测与真实标签之间的偏差。然而，在GRPO中，你测量的是：\n\n3.1 新策略生成过去响应的可能性有多大？\n\n3.2 这些响应相对更好还是更差？\n\n3.3 应用裁剪以防止极端更新。\n\n这将得到一个标量损失。\n\n4\\. 反向传播 + 梯度下降\n\n反向传播计算每个参数对损失的贡献。\n\n梯度下降更新这些参数以减少损失。\n\n经过多次迭代，这会逐渐调整新策略，使其更倾向于产生高奖励响应。\n\n5\\. 偶尔更新旧策略，使其与新策略匹配。这为下一轮比较刷新了基准。\n\n### **2\\. CoT（Chain of Thought，思维链）**\n\n传统的LLM训练流程是预训练 → SFT → RL。然而，DeepSeek-R1-Zero跳过了SFT，允许模型直接探索CoT推理。\n\n就像人类在思考一个棘手问题时，CoT使得模型能够将问题分解为中间步骤，从而增强复杂的推理能力。OpenAI的o1模型也利用了这一点，正如其2024年9月报告中所指出的：o1的表现随着更多RL（训练时计算）和更多推理时间（测试时计算）的增加而提升。\n\nDeepSeek-R1-Zero表现出反思性倾向，能够自我精炼推理过程。论文中的一个关键图表显示，随着训练的进行，思考的深度增加，导致了更长（更多token）、更详细且更优的响应。\n\n![Image 10: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/SaeK9tW7Buibv7KkmmNAvYicy1jv4CZ4q1K447fzxLiavTIFkwY4Fnl2Is0r1zxxFofGpWDlFibEZPWhKYw1b3PibLw/640?wx_fmt=png&from=appmsg)\n\n在没有显式编程的情况下，它开始重新审视过去的推理步骤，从而提高了准确性。这突显了思维链推理作为RL训练的一种涌现特性。\n\n模型还经历了一个“啊哈时刻”（见下图）——这是一个令人着迷的例子，展示了RL如何导致意想不到且复杂的结果。\n\n![Image 11: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/SaeK9tW7Buibv7KkmmNAvYicy1jv4CZ4q1JlKzQMccMW01NEgHDfKQVh2KUsHABgUOF2j9m9FGe4obibETudTJh2w/640?wx_fmt=png&from=appmsg)\n\n注意：与DeepSeek-R1不同，OpenAI没有在o1中展示完整的推理链条，因为他们担心蒸馏风险——即有人试图模仿这些推理痕迹，通过模仿恢复大量的推理性能。相反，o1只会总结这些思维链条。\n\nRLHF（Reinforcement learning with Human Feedback，带有人工反馈的强化学习）\n\n对于具有可验证输出的任务（例如数学问题、事实问答），AI的回答可以轻松评估。但对于像总结或创意写作这样没有单一“正确”答案的领域，如何处理呢？\n\n这就是人工反馈的作用所在——但是天真的强化学习方法是不可扩展的。\n\n![Image 12: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/SaeK9tW7Buibv7KkmmNAvYicy1jv4CZ4q14iaTXrdEuvayWMXcS92wZ2QXykq7kBZahkUDwg0tfEZrkv2CUVQDYOg/640?wx_fmt=png&from=appmsg)\n\n让我们用一些任意数字来看一下朴素的方法。\n\n![Image 13: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/SaeK9tW7Buibv7KkmmNAvYicy1jv4CZ4q1siaG6yXM2dFia2JxEue5nftI83v7U5MouUbZFPCjCRMfImiaHrPFjaDnw/640?wx_fmt=png&from=appmsg)\n\n这需要十亿次人工评估！这太昂贵、缓慢且不可扩展。因此，一个更智能的解决方案是训练一个AI“奖励模型”来学习人类的偏好，从而大大减少人工工作量。\n\n与绝对评分相比，对响应进行排名也更容易且更直观。\n\nRLHF的优点：\n\n*   可以应用于任何领域，包括创意写作、诗歌、总结以及其他开放性任务。\n    \n*   对输出进行排名比人工标签生成创意输出更容易。\n    \n\nRLHF的缺点：\n\n*   奖励模型是近似的——它可能无法完美反映人类的偏好。\n    \n*   RL擅长利用奖励模型的漏洞——如果运行时间过长，模型可能会利用这些漏洞，生成荒谬的输出但仍获得高分。\n    \n\n需要注意的是，RLHF与传统的RL不同。\n\n对于可以进行经验验证的领域（例如数学、编程），RL可以无限运行并发现新的策略。而RLHF则更像是一个微调步骤，用来将模型与人类的偏好对齐。\n\n ",
    "created_at": "2025-03-11T06:05:24Z",
    "updated_at": "2025-03-14T10:25:09Z",
    "labels": [],
    "url": "https://github.com/kaozb/ai-arctl/issues/10"
  },
  {
    "id": 18,
    "title": "Top AI Agent 框架选型参考",
    "content": "Top AI Agent 框架选型参考\n===============\n  \n\n1\\. CrewAI：团队协作小能手2\\. LangGraph：定制界的 “扛把子”3\\. OpenAI Swarm：潜力股，但还在 “成长中”4\\. Magentic-One：复杂任务 “处理大师”5\\. PydanticAI：单 Agent 场景的 “小确幸”6\\. 选框架不迷茫，这些场景这样选\n\n如今 AI Agent 技术那叫一个突飞猛进，各大厂商和开源社区瞅准时机，纷纷亮出自家的 Agent 框架。这可让不少开发者和企业犯了难，这么多框架，到底哪个能在企业级能力、Agent 功能性和开发者体验之间找到完美平衡呢？别慌，今天就带大家深度剖析当下超火的五大 Agent 框架。\n\n先唠唠为啥企业级 Agent 框架这么重要。搞过 Agent 开发的小伙伴肯定知道，搭建一个强大又好用的 Agent 系统，难度系数可不低，从底层架构到上层应用，每个环节都得 “给力”，这时候就特别需要一个靠谱的框架在多个维度 “撑腰”。所以呢，咱从开发者体验、Agent 能力、企业级能力这三个关键维度，全方位对比这五大热门框架。\n\n1\\. CrewAI：团队协作小能手\n==================\n\nCrewAI 把 “crew（团队）” 概念玩得贼溜，主打一组协作的 Agent 携手完成任务。它既能当开源库，嵌入项目自由发挥；也能依托 CrewAI 平台，享受一站式服务。\n\n*   **优势**：\n    \n\n*   Agent 之间协作超丝滑，共享内存和消息传递两种 “交流方式” 任选，配合默契；\n    \n*   新手友好度拉满，各种组件像搭积木一样，咔咔一拼就能用；\n    \n*   就算是非技术人员，改改配置文件，也能对系统动手脚；\n    \n*   任务规划和执行稳稳当当，不整那些花里胡哨的。\n    \n\n*   **不足**：\n    \n\n*   想深度拓展功能有点难，自定义工具开发更是 “老大难”；\n    \n*   日志记录像是半成品，输出到文件都费劲；\n    \n*   企业级安全特性基本藏在付费平台版本里，免费版只能 “眼馋”。\n    \n\n*   **适用场景**：\n    \n\n*   简单 Agent 应用开发，速度能起飞；\n    \n*   还有那种需要非技术用户参与配置的场景，CrewAI 就是 “天选之子”。\n    \n*   但要是你对功能自定义要求极高，那可能得另寻他路。\n    \n\n2\\. LangGraph：定制界的 “扛把子”\n========================\n\nLangGraph 身为 LangChain 生态一员，靠图抽象把 Agent、工具还有其他 Agent 巧妙串联。节点代表 Agent 和工具，边则掌控节点调用时机，就像精密齿轮，环环相扣。\n\n*   **优势**：\n    \n\n*   灵活性和可定制性直接拉满，接口设计堪称一绝，在任何节点都能 “插一脚”，引入自定义行为；\n    \n*   不管多复杂的工具使用、Agent 层级结构，它都能轻松拿捏；\n    \n*   任务规划和执行能力那叫一个靠谱，让人安心。\n    \n\n*   **不足**：\n    \n\n*   学习曲线陡得像悬崖，新手想上手，得费不少功夫；\n    \n*   预构建组件少得可怜，好多功能都得开发者自己 “撸起袖子加油干”；\n    \n*   企业级能力，像安全性、日志记录这些，也都得额外开发，工作量不小。\n    \n\n*   **适用场景**：\n    \n\n*   适合那些已经在 Agent 开发领域摸爬滚打，积累了不少经验的团队；\n    \n*   要是你的应用对 Agent 交互和工具使用模式要求苛刻，LangGraph 绝对是不二之选。\n    \n\n3\\. OpenAI Swarm：潜力股，但还在 “成长中”\n==============================\n\nOpenAI Swarm 围绕 “swarm（蜂群）” 概念打造，Agent 组之间松散耦合、各自为政，这种设计理论上能带来超高灵活性。\n\n*   **优势**：\n    \n\n*   理论上支持高度灵活的Agent交互模式；\n    \n*   背后有 OpenAI 这个大厂 “站台”，技术实力有想象空间。\n    \n\n*   **不足**：\n    \n\n*   目前还处于实验阶段，框架像没完工的毛坯房，到处是 “窟窿”；\n    \n*   开发体验堪称 “噩梦”，代码复杂得像一团乱麻，调试起来让人头秃；\n    \n*   文档不仅少，还严重过时；\n    \n*   任务执行结果飘忽不定，缺乏稳定性；\n    \n*   企业级功能更是基本没有。\n    \n\n*   **适用场景**：\n    \n\n*   虽说顶着大厂光环，但就当下这状态，真心不建议用在生产环境。\n    \n*   开发难度大、结果不稳定这些问题，想构建稳定可靠的 Agent 系统，太难了。\n    \n\n4\\. Magentic-One：复杂任务 “处理大师”\n============================\n\nMagentic-One 由微软研究院操刀，基于 Autogen 工具包搭建。它把文件浏览器、编码器、执行器等不同角色的 Agent 串起来，合力攻克复杂任务。\n\n*   **优势**：\n    \n\n*   处理复杂任务能力超强，尤其是网络浏览、代码生成这块，堪称一绝；\n    \n*   日志记录和可观察性功能相当完善，方便排查问题；\n    \n*   组件重用性高，预构建的 Agent 拿来就能用，节省开发时间。\n    \n\n*   **不足**：\n    \n\n*   架构有点 “死板”，扩展起来困难重重；\n    \n*   自定义工具和 Agent 开发也不轻松；\n    \n*   依赖代码执行，安全风险高；\n    \n*   文档不够全面，有些细节还得自己摸索。\n    \n\n*   **适用场景**：\n    \n\n*   适合那些追求开箱即用，处理复杂任务的场景，特别是涉及网络搜索和代码生成的需求。\n    \n*   不过用之前，可得好好评估下安全风险。\n    \n\n5\\. PydanticAI：单 Agent 场景的 “小确幸”\n================================\n\nPydanticAI 是个 “新人” 框架，由 Pydantic 库的开发者打造。它提供了简化的抽象层和易用组件，不过主要服务于单 Agent 应用场景。\n\n*   **优势**：\n    \n\n*   和 Pydantic 生态系统无缝集成，兼容性超棒；\n    \n*   在单 Agent 场景下，用起来还算顺手。\n    \n\n*   **不足**：\n    \n\n*   多 Agent 交互支持基本为零；\n    \n*   开发体验不太好，大部分交互细节都得手动管理；\n    \n*   日志和调试信息严重缺失；\n    \n*   企业级功能更是 “一无所有”。\n    \n\n*   **适用场景**：\n    \n\n*   简单的单 Agent 应用可以考虑它，但要是企业级应用涉及多 Agent 协作，那它就不太行了。\n    \n\n6\\. 选框架不迷茫，这些场景这样选\n==================\n\n综合分析下来，不同需求有不同的最佳选择：\n\n*   **初次尝试 Agent 开发**：CrewAI 绝对是首选，上手轻松，预构建功能丰富，能帮新手快速建立信心。\n    \n*   **需要高度定制化**：LangGraph 凭借强大的灵活性，更适合经验丰富的开发团队。\n    \n*   **企业级应用**：简单应用场景，CrewAI 企业版能满足需求；要是有复杂定制需求，可以选 LangGraph，再自行开发企业级功能。\n    \n\n其他框架虽然也有闪光点，但 OpenAI Swarm 成熟度欠佳，Magentic-One 和 PydanticAI 扩展性受限，在企业级应用上或多或少有点 “拖后腿”。\n\n",
    "created_at": "2025-03-12T03:20:51Z",
    "updated_at": "2025-03-14T10:23:57Z",
    "labels": [],
    "url": "https://github.com/kaozb/ai-arctl/issues/18"
  },
  {
    "id": 2,
    "title": "大模型基础知识扫盲篇（上）--名词篇",
    "content": "大模型基础知识扫盲篇（上）--名词篇\n===============\n                                                                         \n\n             \n\n  \n\n![Image 1: cover_image](https://mmbiz.qpic.cn/mmbiz_jpg/icUqtxmPRjDGTYd1pxeGia411WmROHIvulLSbSwRqMkwlPwMuNwBaU0svlHKpmceKFvIgqVvX4ID9Nc5lZrKIDrg/0?wx_fmt=jpeg)\n\n大模型基础知识扫盲篇（上）--名词篇\n==================\n\n大数据启示录 [大数据启示录](javascript:void(0);)\n\n![Image 2: profile_qrcode](https://mp.weixin.qq.com/mp/qrcode?scene=10000005&size=102&__biz=Mzg4NDYzNjQ1Ng==&mid=2247500564&idx=1&sn=d478460d45960ccb2569f51d7d457240&send_time=)\n\n大数据启示录\n\n科普自媒体\n\nspark. flink.kubernetes.pulsar.iceberg.hudi.atlas.presto.paimon.starroks.doris.离线数仓.用户画像，实时数仓，数据中台，湖仓一体....等文章交流学习。\n\n152篇原创内容\n\n_2025年02月21日 00:01_\n\n  \n一：名词术语  \n\n============\n\n  \nAgents  \n\n------------\n\n###   \n智能体是什么？  \n\nAgent 是什么，直译过来就是代理，但在国内人工智能领域通常被译为智能体。从智能体这个名字可以大概想象出这个 Agents 可能与智能相关，此概念出现已经有相当长时间了。随着大模型的爆发现在 Agents 的驱动核心为大模型，似乎智能体（Agents）时代真要来临了。\n\n大模型大大降低了智能体实现的门槛，但如何用好智能体似乎各方都还在摸索中。目前智能体的应用中使用最广泛最多的应该还是在编程领域代码助手比较火爆，如 Cursor 等都是 AI 智能体。\n\n现在大模型主要有本文大模型、多模态大模型，可生成文字、逻辑推理、编写代码、生成图片视频等等能力。光有这些模型基础能力还不能够被称为智能体，智能体：顾名思义是一系列能力的集合体。在不同环境中其智能体的能力也不一样，智能体=大模型+工具集。\n\n在除了大模型的生成能力、逻辑推理能力、再加上其函数(工具)调用的能力呢，似乎已经看到了智能体的雏形。\n\n![Image 3: Image](https://mmbiz.qpic.cn/mmbiz_png/icUqtxmPRjDGTYd1pxeGia411WmROHIvulic9ezcibE6p0mz1CsZXwXa3WLdBh4skyvk2W7V9E7RrYnfF3cSCMHtzA/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)\n\n智能体 = 推理 + 生成 + 工具调用\n\n  \n智能体的两种模式\n-----------\n\n![Image 4: Image](https://mmbiz.qpic.cn/mmbiz_png/icUqtxmPRjDGTYd1pxeGia411WmROHIvulTkVG8WuehOOdBye9GaS45G4PqfEIzusnUtGBWwzcdaLkcBMB78xiaqA/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)\n\n串行 Workflow 模式: 初级智能体，此模式下智能体只能执行某些经过编排好的能力实现固定功能。\n\n![Image 5: Image](https://mmbiz.qpic.cn/mmbiz_png/icUqtxmPRjDGTYd1pxeGia411WmROHIvulgUs1BjPd1A2adwR4KiaIZBI4P6BN7adWsW3k5EYRUib8uTEW1ODqTU0w/640?wx_fmt=png&from=appmsg)\n\n智能规划模式： 高级智能体，完全由智能体规划任务，决定任务如何执行，是调用两个服务还是调用三个服务取决于任务还有规划的制定。\n\n已经有了高级智能体为什么还要去实现初级智能体，因为目前模型的意图识别、推理、规划能力还达不到指哪打哪 100%可靠的程度，这时候智能度越高越复杂的智能体可能也意味着出错的概率越大。所以使用简单又能够满足业务需求的初级智能体或许是更好的选择。\n\n目前好用的 Agent 平台是 Coze、Dify、MarsCode、FastGPT、AutoGpt...\n\n  \nPrompt  \n\n------------\n\n###   \nPrompt 是什么？  \n\n即：提示词。Prompt 是给予提供语言模型（LLM）的输入或查询，作为模型生成后续文本的起点或上下文，它指示模型应生成何种类型的响应或输出。 它可以是一个问题、一个指令、一个句子片段、一个故事的开头，或者任何形式的文本输入。模型会基于 Prompt 的内容和自身的预训练知识，生成与之相关的、连贯的、符合预期的文本输出。 Prompt 是一种通过设计特定的提示词或句子，引导模型生成更符合用户意图的输出的方法。例如，我们可以为模型添加一些关于期望回答的提示信息，以帮助模型更好地理解问答的结构和规则。\n\n![Image 6: Image](https://mmbiz.qpic.cn/mmbiz_png/icUqtxmPRjDGTYd1pxeGia411WmROHIvulF6Haw2BYp9c1tzkBM3XZhMJIDEjGWRlUaONzpvuO9ibTYZ0moy2gubA/640?wx_fmt=png&from=appmsg)\n\nPrompt 的组成包四个元素：\n\n*   Instruction（指令，必需）：告诉模型该怎么做，如何使用外部信息（如果提供），如何处理查询并构建 Out。\n    \n*   Context（上下文信息，可选）：充当模型的附加知识来源。这些可以手动插入到提示中，通过矢量数据库 （Vector Database） 检索（检索增强）获得，或通过其他方式（API、计算等）引入。\n    \n*   Input Data（需要处理的数据，可选）：通常（但不总是）是由人类用户（即提示者）In 到系统中的查询。\n    \n*   Output Indicator（要输出的类型或格式，可选）：标记要生成的文本的开头。 \n    \n*   ![Image 7: Image](https://mmbiz.qpic.cn/mmbiz_png/icUqtxmPRjDGTYd1pxeGia411WmROHIvulbCGJialXxNHvicdq5bHKXrKFbuiaIVIEajaMX66GxiaTRwKU7V4vrugSRA/640?wx_fmt=png&from=appmsg)\n    \n\n###   \nPrompt 编写原则  \n\n![Image 8: Image](https://mmbiz.qpic.cn/mmbiz_png/icUqtxmPRjDGTYd1pxeGia411WmROHIvulg1Dmddia6Y4ziaFDwDgyTeTcwmj6iatRsdYsW64ulchfficOyb7Zl0VDSQ/640?wx_fmt=png&from=appmsg)\n\n###   \n什么是 COT (Chain of Thought，CoT)?  \n\n一个完整的包含 CoT 的 Prompt 往往由指令（Instruction），逻辑依据（Rationale），示例（Exemplars）三部分组成。一般而言指令用于描述问题并且告知大模型的输出格式，逻辑依据即指 CoT 的中间推理过程，可以包含问题的解决方案、中间推理步骤以及与问题相关的任何外部知识，而示例则指以少样本的方式为大模型提供输入输出对的基本格式，每一个示例都包含：问题，推理过程与答案。\n\n![Image 9: Image](https://mmbiz.qpic.cn/mmbiz_png/icUqtxmPRjDGTYd1pxeGia411WmROHIvulTqRMG5bUy3sL98LkFGuaWTODPxnfz6BaKeZz1RMyT9LTmxhB23QxCg/640?wx_fmt=png&from=appmsg)\n\n以是否包含示例为区分，可以将 CoT 分为 Zero-Shot-CoT 与 Few-Shot-CoT，在上图中，Zero-Shot-CoT 不添加示例而仅仅在指令中添加一行经典的“Let's think step by step”，就可以“唤醒”大模型的推理能力。而 Few-Shot-Cot 则在示例中详细描述了“解题步骤”，让模型照猫画虎得到推理能力。 思维链的关键为，对于同类型的问题，提供推理过程示例以引发大模型的深度思考，从而参考示例实现推理。\n\nCOT 的关键在于示例的推理过程。思维链(CoT)提示通过中间推理步骤实现复杂的推理能力。你可以将它与少量提示结合起来，在需要推理才能做出反应的更复杂的任务中获得更好的结果。\n\n![Image 10: Image](https://mmbiz.qpic.cn/mmbiz_png/icUqtxmPRjDGTYd1pxeGia411WmROHIvulP4gI67CXwicVYXw2Yyc9AoSicbIXiaMQTOPeIWbmSHqgj2f2icYAH27zXg/640?wx_fmt=png&from=appmsg)\n\n如果对使用 CoT 的好处做一个总结，那么可以归纳为以下四点：\n\n*   增强了大模型的推理能力：CoT 通过将复杂问题分解为多步骤的子问题，相当显著的增强了大模型的推理能力，也最大限度的降低了大模型忽视求解问题的“关键细节”的现象，使得计算资源总是被分配于求解问题的“核心步骤”；\n    \n*   增强了大模型的可解释性：对比向大模型输入一个问题大模型为我们仅仅输出一个答案，CoT 使得大模型通过向我们展示“做题过程”，使得我们可以更好的判断大模型在求解当前问题上究竟是如何工作的，同时“做题步骤”的输出，也为我们定位其中错误步骤提供了依据；\n    \n*   增强了大模型的可控性：通过让大模型一步一步输出步骤，我们通过这些步骤的呈现可以对大模型问题求解的过程施加更大的影响，避免大模型成\n    \n*   增强了大模型的灵活性：仅仅添加一句“Let's think step by step”，就可以在现有的各种不同的大模型中使用 CoT 方法，同时，CoT 赋予的大模型一步一步思考的能力不仅仅局限于“语言智能”，在科学应用，以及 AI Agent 的构建之中都有用武之地。 高级的 Prompt 技术，主要有 零样本提示、少样本提示、链式思考（CoT）提示、链式提示、思维树 (ToT)、Active-Prompt。力。\n    \n\n###   \nPrompt 类型  \n\n![Image 11: Image](https://mmbiz.qpic.cn/mmbiz_png/icUqtxmPRjDGTYd1pxeGia411WmROHIvulyOibUYuhGHDxunjqqJj66xLb5R177G2ibIQ4SQLrBdmklFEjBRiaH4gUw/640?wx_fmt=png&from=appmsg)\n\n####   \nZero-Shot Prompting\n\n直接向模型提出问题，不需要任何案例，模型就能回答你的问题，基于模型训练的时候提供的大量数据，能做初步的判断。\n\n(1) Zero-Shot Prompting 技术依赖于预训练的语言模型。\n\n(2) 为了获得最佳性能，它需要大量的样本数据进行微调。像 ChatGPT 就是一个例子，它的样本数量是过千亿。\n\n(3) 由于Zero-Shot Prompting 技术的灵活性和通用性，它的输出有时可能不够准确，或不符合预期。这可能需要对模型进行进一步的微调或添加更多的提示文本来纠正。\n\n####   \nleast-To-Most COT（LtM 提示法）  \n\n整个提示过程会分为两个阶段进行，第一个阶段是自上而下的分解问题（Decompose Question into subquestion），第二个阶段是自下而上的依次解决问题（Sequentially Solve Subquestion），而整个依次回答问题的过程，其实就可以看成是 CoT 的过程，只不过 LtM 会要求模型根据每个不同的问题，单独生成解决问题的链路，以此做到解决问题流程的“千人千面”，从而能够更加精准的解决复杂推理问题。而整个过程问题的由少变多，则是 LEAST-TO-MOST 一词的来源。\n\nLtM 提示方法提出的初衷是为了解决 CoT 提示方法泛化能力不足的问题——即通过人工编写的思维链提示样本可能并不能够很好的迁移到别的问题当中去，换而言之，就是解决问题的流程迁移能力不足，即泛化能力不够。而这种泛化能力不足则会导致“新的问题”无法使用“老的模板”进行解决。例如此前的第四个推理问题就是如此。那即然要找到更加普适的解决问题的流程会非常复杂，那能否“千人千面”让大模型自己找到解决当前问题的思维链呢？答案是肯定的，谷歌大脑基于这个思路开发了一种全新的提示流程，即先通过提示过程让模型找到解决该问题必须要分步解决哪几个问题，然后再通过依次解决这些问题来解决最原始的问题。\n\n####   \n思维链（Chain of Thoughts, CoT）  \n\nJason Wei 等人（2022）引入的思维链（CoT）提示，通过中间推理步骤实现复杂的推理能力。可以将其与少样本提示相结合，以获得更好的结果，以便在回答之前进行推理的更复杂的任务。\n\n![Image 12: Image](https://mmbiz.qpic.cn/mmbiz_png/icUqtxmPRjDGTYd1pxeGia411WmROHIvulE79tRiaKWD2nWSHGcBqSjeK8rmrBIdIHtBNKibakyzd9bNhEwOibia4xGg/640?wx_fmt=png&from=appmsg)\n\n有两种方式增加 GPT 的推理能力，或者 CoT 能力：\n\n(1) 第一种：增加案例，如下所示，第一次回答错误，给一个计算过程的案例，GPT 可以通过案例学会简单推理。\n\n![Image 13: Image](https://mmbiz.qpic.cn/mmbiz_png/icUqtxmPRjDGTYd1pxeGia411WmROHIvul5KDJGLib1W0rv6gowrpI68NKRImK3ia140rwFyouHPemHCkRibXWv0icCw/640?wx_fmt=png&from=appmsg)\n\n第二种：增加关键句，Let's think step by step，测试人员测了很多类似的句子，最后发现这句话是效果最好的，这个时候不加案例，GPT 也具备一定的推理能力。\n\n![Image 14: Image](https://mmbiz.qpic.cn/mmbiz_png/icUqtxmPRjDGTYd1pxeGia411WmROHIvulnSqZbPuMGYic7UtoOtDW0icZQzLrhHsDCwjZBTqmkSlZv7Xlq7UVHukA/640?wx_fmt=png&from=appmsg)\n\n根据 Wei 等人的论文表明，它仅在大于等于 100B 参数的模型中使用才会有效。如果使用的是小样本模型，这个方法不会生效。\n\n####   \n自洽性（Self-Consistency）  \n\n是对 CoT 的一个补充，让模型生成多个思维链，然后取最多数答案的作为最终结果。其实重复运算多次，取概率最高的那一个，需要借助脚本辅助完成这个功能。\n\n![Image 15: Image](https://mmbiz.qpic.cn/mmbiz_jpg/icUqtxmPRjDGTYd1pxeGia411WmROHIvulXSM3la2E2wowoNicEXe4HAuqiaqlFZHeQ0Q15czk1kpK7t0xYl8fVqbg/640?wx_fmt=webp&from=appmsg)\n\n(1)从语言模型中生成多个不同的“推理路径（reasoning paths）”，这些路径可能因模型的随机性或不同的参数设置（如 temperature、top\\_p 等）而有所不同。有助于模型更全面地考虑问题，并可能导致更准确或更可靠的最终答案。\n\n(2) 对上一步生成的多个推理路径进行“边缘化（marginalize out）”以得到一个最终的、一致的答案。边缘化在这里意味着从多个可能的推理路径中找出最常见或最一致的答案。\n\n####   \n思维树（Tree-of-thought, ToT）  \n\nTree of Thoughts（ToT）框架，用于改进语言模型（LMs）的推理能力。该框架是对流行的“Chain of Thought”方法的一种泛化，允许模型在解决问题的过程中进行更多的探索和策略性前瞻。ToT 允许模型自我评估不同的选择，以决定下一步的行动，并在必要时进行前瞻或回溯，以做出全局性的选择。\n\n在 24 点游戏中，使用链式思考提示的 GPT-4 仅解决了 4%的任务，而使用 ToT 方法的成功率达到了 74%。\n\n####   \nAutomatic Prompt Engineer (APE)  \n\nAPE 探索了一种比 zero-shot CoT prompt 人工设定的\"Let's think step by step\" prompt 更优的指令，以使用 llm 生成和搜索候选解决方案的黑盒优化问题。对于不同的任务和模型，需要获取不同的指令语句。\n\n```\nhttps://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2211.01910.pdf\n```\n\n####   \nAutomatic Chain-of-Thought (Auto-CoT)  \n\n当用应用思维链提示时，该过程涉及手工编写有效和多样化的示例。这种手工工作可能导致次优解决方案。Zhang 等人(2022)提出了一种方法，通过利用带有“让我们一步一步思考”提示的 LLM，为一个接一个的演示生成推理链，从而消除人工操作。这个自动过程仍然可能在生成的链中出现错误。为了减轻错误的影响，正面过程的多样性很重要。这项工作提出了 Auto-CoT，采样多样性的问题，并编写推理链。 Auto-CoT 包括两个主要阶段: 段 1:问采用：:将给定数据集的问题划分为几个簇阶段):示范：样:从每个聚类中选择一个有代表性的问题，使用简单的来 oT 生成其推。\n\n![Image 16: Image](https://mmbiz.qpic.cn/mmbiz_png/icUqtxmPRjDGTYd1pxeGia411WmROHIvuleibn76R8RsSYthfb56RjgX3j7j9hA3Tk170wwZ8vZYrzeCibpRPm7Lcg/640?wx_fmt=png&from=appmsg)\n\n![Image 17: Image](https://mmbiz.qpic.cn/mmbiz_png/icUqtxmPRjDGTYd1pxeGia411WmROHIvulct7v82zM3pq11amN3TibAxKdUxNthJUdj6QvMD9oSibdkKeQpdOicVgRQ/640?wx_fmt=png&from=appmsg)\n\n####   \nReAct 框架  \n\nYao 等人（2022）引入了一个框架，其中 LLMs 以交错的方式生成推理轨迹和任务特定操作，并且允许 LLMs 与外部工具交互来获取额外信息，从而给出更可靠和实际的回应。ReAct 的灵感来自于“行为”和“推理”之间的协同作用，正是这种协同作用使得人类能够学习新任务并做出决策或推理。下图展示 ReAct 的一个示例，举例执行问题回答所涉及的不同步骤。\n\n![Image 18: Image](https://mmbiz.qpic.cn/mmbiz_png/icUqtxmPRjDGTYd1pxeGia411WmROHIvuliaH9NZMYe9iaxN4JKya7HPwHNAqso4uzuYZicpq565hH5gibjbHTibUtfGA/640?wx_fmt=png&from=appmsg)\n\n实现流程如下：（1）用 Prompt 实现一个样例，比如上面的模板：Thought:xxx ==\\> Action: Search\\[xxx\\]；（2）LLMs 会根据模板相同的逻辑，结合 CoT 思维链方式一步一步思考，并获取外部知识；（3）最后 Action: Finish 获取最终结果后结束。\n\n更多资料：https://zhuanlan.zhihu.com/p/688732784\n\n  \nLLM  \n\n---------\n\n###   \n概述：  \n\nLLM 是 Large Language Model 这三个单词的首字母缩写，意为大语言模型。大型语言模型（LLM）是一种基于深度学习技术的自然语言处理工具，能理解和生成文本。通过大量语料库训练，LLM 在翻译、写作、对话等任务中展现出卓越的能力。常见的应用包括自动问答、生成文本、文本摘要等。由于其多模态特性，LLM 还可用于图像和音频处理，为多领域带来创新可能。GPT、LLaMA、Mistral、BERT 等都是 LLM，LLM 是对训练文本信息的压缩，同时拥有了泛化能力，不同于数据库和搜索引擎，LLM 能创造性地生成历史上没有出现过的文本内容。\n\nGPT（Generative Pretrained Transformer）和 BERT（Bidirectional Encoder Representations from Transformers）这两个词中的 T 就是 Transformer 架构。Transformer 架构是一种基于自注意力机制的神经网络结构，它完全颠覆了之前以循环神经网络（RNN）为主导的序列建模范式。Transformer 架构的出现，实现了并行计算和高效的上下文捕获，极大地提高了自然语言处理的性能。可以说，先有 Transformer，后有 GPT 以及 BERT。 常见模型中的 7B,14B，32B...等参数 B 是 Billion 的缩写，指的是模型训练的参数数量。\n\n###   \nBERT 模型和 GPT 模型的区别  \n\nBERT：双向 预训练语言模型+fine-tuning（微调）\n\nGPT：自回归 预训练语言模型+Prompting（指示/提示）\n\nBERT 和 GPT 两者都是基于大语言模型的，他们在这一点上是相同的。他们的不同在于双向/自回归，fine-tuning/Prompting 这两个维度\n\nGPT的训练相对于BERT有以下不同之处：\n\n*   GPT使用的是自回归Transformer模型，而BERT使用的是双向Transformer模型。\n    \n*   GPT的预训练数据来源是大量的网络文本数据，而BERT的预训练数据来源是两个大型语料库，包括Wikipedia和BooksCorpus。\n    \n*   GPT预训练过程中，采用了语言模型的方法，即通过预测下一个词来学习语言模型，而BERT预训练过程中采用了双向预测的方法，即通过预测句子中丢失的词来学习语言模型。\n    \n*   GPT微调时，需要指定输入输出的语言模型任务，而BERT微调时，可以应用在多种任务上，例如文本分类、命名实体识别等。\n    \n\nGPT和BERT在使用场景上有明显的不同：\n\n*   GPT主要用于自然语言生成任务，如文本自动补全、问答系统、文本翻译等。它可以根据给定的文本上下文生成有意义的文本，并且能够产生连贯的、人类水平的文本。\n    \n*   BERT则主要用于自然语言理解任务，如问题回答、文本分类、句子关系分析等。它可以理解文本中的语义和关系，并能够找出语句之间的联系。\n    \n*   GPT在文本生成场景中更常见，如聊天机器人，智能问答系统等。BERT在文本理解场景中更常见，如文本分类，问题回答等。\n    \n*   GPT对于文本生成更为敏感，而BERT对于文本理解更为敏感。\n    \n*   GPT在进行文本生成时需要较长的上下文，而BERT在进行文本理解时需要较短的上下文。\n    \n*   总的来说，GPT主要用于文本生成任务，而BERT则主要用于文本理解任务。\n    \n\n  \n```\n架构：GPT 是单向生成模型，使用自回归架构；BERT 是双向编码模型，使用编码器架构。  \n训练目标：GPT 目标是自回归语言建模，生成下一个单词；BERT 目标是掩码语言建模，预测被掩码的单词。  \n应用场景：GPT 主要用于生成任务，如文本生成、对话系统；BERT 主要用于分类任务，如文本分类、命名实体识别。  \n训练数据：两者都使用大规模文本数据，但 GPT 只需要单向数据流，BERT 需要双向数据流。  \n模型大小：GPT 通常具有更大的参数量，BERT 相对较小。  \n训练方法：GPT 通过自回归训练，BERT 通过掩码训练。  \n性能和效率：GPT 在生成任务上表现优异，推理速度较慢；BERT 在分类任务上表现优异，推理速度较快。  \n扩展性：两者都可以通过微调进行多任务学习，但 GPT 在生成任务上更具优势。  \n```\n\n###   \n常见的LLM产品：  \n\n![Image 19: Image](https://mmbiz.qpic.cn/mmbiz_png/icUqtxmPRjDGTYd1pxeGia411WmROHIvul2LlnJMTbQFWtVcr3ibv8a9a9mGSwgH9ABKDXFDjrHiamnwtr0PD5vQhw/640?wx_fmt=png&from=appmsg)\n\n  \n```\n• ChatGPT：网页版；非国区应用商店可下载APP；  \n• Poe：网页版；非国区应用商店可下载APP；  \n• Coze：国际版；国内版  \n• Gemini：个人版；开发者版,100万上下文  \n• Arc Search：官网下载客户端；非国区应用商店可下载APP；  \n• Perplexity：网页版；非国区应用商店可下载APP；  \n• 通义：网页版；各大应用商店可下载APP；  \n• 秘塔：网页版  \n• Kimi：网页版；各大应用商店可下载APP；  \n• 文心一言：网页版；各大应用商店可下载APP；  \n• 海螺AI：网页版；各大应用商店可下载APP；  \n• 智谱清言：网页版；各大应用商店可下载APP；  \n• 豆包：网页版；各大应用商店可下载APP；  \n• Microsoft Copilot：网页版；非国区应用商店可下载APP；  \n• HuggingChat：网页版；非国区应用商店可下载APP；  \n• 讯飞星火：网页版；各大应用商店可下载APP；  \n• 百小应：网页版；各大应用商店可下载APP；  \n• DeepSeek：网页版；各大应用商店可下载APP；\n```\n\n###   \nLLM模型评测\n\n![Image 20: Image](https://mmbiz.qpic.cn/mmbiz_png/icUqtxmPRjDGTYd1pxeGia411WmROHIvulBmKMias8bvVqy0hPSGPlkh84CYyzXJ2llSC5SE1AtXzEea4W5ko3f0A/640?wx_fmt=png&from=appmsg)\n\n###   \n\n###   \nLLM与生成式AI的区别\n\n![Image 21: Image](https://mmbiz.qpic.cn/mmbiz_png/icUqtxmPRjDGTYd1pxeGia411WmROHIvulrDKMicwPXhmx69uF6fEuFJKYKqsvSjeiaVVkOEZS37lkRFyTnhic3bNQA/640?wx_fmt=png&from=appmsg)\n\n###   \n\n###   \nLLM 编程框架\n\n![Image 22: Image](https://mmbiz.qpic.cn/mmbiz_png/icUqtxmPRjDGTYd1pxeGia411WmROHIvul0YH5z1ycGl5jSicVicArSxusYETpT6GuDJ48PUHr1TlHI6DmHdxNKaXg/640?wx_fmt=png&from=appmsg)\n\n  \nAIGC  \n\n----------\n\n###   \n概述：  \n\nAIGC，即人工智能生成内容（Artificial Intelligence Generated Content），是一种利用人工智能算法和技术自动生成各种形式的内容的技术。这些内容包括文本、图像、音频、视频等。AIGC 又称生成式 AI ，它被认为是继专业生成内容和用户生成内容之后的新型内容创作方式。\n\n与传统 AI 不同，传统 AI 可以用来完成排序、分类、图像识别等任务。\n\n而 AIGC 则专注于内容创作，AIGC 专注于使用 AI 创建新的、原创的内容，可以生成文字、图像、音乐、视频等多种形式的内容，它不仅能提高内容创作的效率，还能在广告营销、教育、娱乐等领域带来革命性的变化。AIGC代表了人工智能技术在内容生成领域的最新进展，具有重要的应用价值和发展前景。\n\n###   \n原理说明：  \n\nAIGC 的核心原理主要依托于机器学习领域，其中尤以深度学习以及生成对抗网络（GAN）为主。通俗来讲，GAN 凭借两个处于对立态势的神经网络，即生成器和判别器，二者相互博弈，持续不断地提升所生成内容的质量水准。至于变换器（ Transformer ），其借助自注意力机制，具备理解上下文关联的能力，进而能够生成逻辑连贯的文本或者其他类型的内容。\n\n核心原理与效果技术：\n\n1:基于生成式对抗网络(GAN)-\\--核心思想是在通过两个神经网络——生成器（Generator）和判别器（Discriminator）的相互对抗来生成高质量的数据实例。\n\n2:基于自编码器(Autoencoder)\\---编码器负责将输入数据压缩成一个低维度的隐藏空间表示，而解码器则将这个隐藏空间表示还原回输入数据的形式。\n\n3:基于递归神经网络(RNN)\\---其核心思想是通过在输入序列中循环应用相同的网络结构来处理每个输入，并保留先前输入的信息，以便在处理当前输入时可以参考和使用。\n\n4:基于变换器(Transformer)\\---Transformer架构的核心是自注意力机制，这种机制允许模型在序列内的任意位置间直接进行交互，从而捕捉长距离依赖关系。与传统的递归神经网络（RNN）不同，Transformer完全基于注意力机制，不使用任何循环层或卷积层，这使得其能够并行化计算，显著提高训练速度。\n\n5:多模态生成-\\--多模态生成技术是一种通过将多种类型的数据（如文本、图像和音频）相互映射和融合的技术，旨在生成包含多模态元素的内容。其核心在于学习不同模态数据的统一表征，提取互补信息以促进合成任务的完成。这种技术的核心在于能够将不同模态的数据进行交互和组合，从而创造出新的内容。\n\n###   \nAIGC产品：  \n\n*   文本生成：OpenAI GPT系列、Google BERT系列、Anthropic Claude、Alibaba Qwen、Microsoft Copilot。\n    \n*   图像生成：DALL-E、Midjourney、Stable Diffusion、DeepArt、RunwayML。\n    \n*   音频生成：Jukebox、WaveNet、MusicGen、Amper Music、Descript。\n    \n*   视频生成：DeepMind VideoGen、RunwayML Video、Daz 3D、Synthesia、Adobe After Effects with AI Plugins，Sora,runway。\n    \n*   其他应用：Adobe Firefly、Notion AI、GitHub Copilot、Replit AI、Grammarly。\n    \n\n  \nRAG  \n\n---------\n\n###   \n概念：  \n\nRAG（Retrieval Augmented Generation）检索增强生成，即大模型LLM在回答问题或生成文本时，会先从大量的文档中检索出相关信息，然后基于这些检索出的信息进行回答或生成文本，从而可以提高回答的质量，而不是任由LLM来发挥。RAG技术使得开发者没有必要为每个特定的任务重新训练整个大模型，只需要外挂上相关知识库就可以，即可为模型提供额外的信息输入，提高回答的准确性。RAG技术工作流程如下图所示。\n\n![Image 23: Image](https://mmbiz.qpic.cn/mmbiz_png/icUqtxmPRjDGTYd1pxeGia411WmROHIvul33Dt7er7Kibw8nh2H9YA7xyHoWIQRs4M9tBaqNjbSed5vXqpMtNXh7w/640?wx_fmt=png&from=appmsg)\n\n![Image 24: Image](https://mmbiz.qpic.cn/mmbiz_png/icUqtxmPRjDGTYd1pxeGia411WmROHIvuldMpWkthTTYicpLVJOiaYfcicRHkLVZ7boHBBmBvhjYbgbibW7Wbd3UAtmw/640?wx_fmt=png&from=appmsg)\n\n![Image 25: Image](https://mmbiz.qpic.cn/mmbiz_png/icUqtxmPRjDGTYd1pxeGia411WmROHIvulu2fnfypJZKyib8oWhiaDHvgx6IicRaCwKBm8O4Qo8MpIgDhkURmFZWwFg/640?wx_fmt=png&from=appmsg)\n\n大致流程：\n\n1：知识文本切块处理成文件块。\n\n2:  文件块嵌入模型，创建索引。\n\n3: 存入向量数据库。\n\n4: 用户问题请求查询向量数据库\n\n5: 检索和召回，并自动排序。\n\n6: LLM 训练模型进行归纳\n\n7: 返回响应结果，输出回答。\n\n8:回答记录存入记忆库，检索和召回。\n\n检索： 当接收到用户查询时,使用检索索引找到最相关的文档。具体来讲，对用户输入的查询信息Embedding转化为向量，再到向量数据库中检索其他匹配的上下文信息。通过这种相似性搜索，可以找到向量数据库中最匹配的相关数据。\n\n增强： 将向量数据库中检索到的信息与用户查询信息放到我们自定义的提示模板中。\n\n生成： 最后将上面经过检索以及增强后的提示内容输入到LLM中，LLM根据上述信息生成最终结果。\n\n###   \nRAG能解决LLM的哪些问题  \n\n即使在LLM有较强的解决问题的能力，仍然需要RAG技术的配合，因为能够帮助解决LLM存在的以下几个问题。\n\n（1）模型幻觉问题：LLM文本生成的底层原理是基于概率进行生成的，在没有已知事实作为支撑的情况下，不可避免的会出现一本正经的胡说八道的情况。而这种幻觉问题的区分是比较困难的，因为它要求使用者自身具备相应领域的知识。\n\n（2）知识的局限性：模型自身的知识完全源于它的训练数据，而现有的主流大模型（ChatGPT、文心一言、通义千问…）的训练集基本都是构建于网络公开的数据，对于一些实时性的、非公开的或离线的数据是无法获取到的，这部分知识也就无从具备。\n\n（3）数据安全问题：开源的大模型是没有企业内部数据和用户数据的，如果企业想在保证数据安全的前提下使用LLM，一种比较好的解决办法就是把数据放在本地，企业数据的业务计算全部放在本地完成。而在线的LLM只是完成一个归纳总结的作用。\n\n###   \nRAG架构  \n\nRAG的架构如图中所示，简单来讲，RAG就是通过检索获取相关的知识并将其融入Prompt，让大模型能够参考相应的知识从而给出合理回答。因此，可以将RAG的核心理解为“检索+生成”，前者主要是利用向量数据库的高效存储和检索能力，召回目标知识；后者则是利用大模型和Prompt工程，将召回的知识合理利用，生成目标答案。\n\n![Image 26: Image](https://mmbiz.qpic.cn/mmbiz_jpg/icUqtxmPRjDGTYd1pxeGia411WmROHIvuluskndxNEGF0TdRKiaU98xSBBTnnDQVkpd0Q2jA7eot3rKFVuPZnBcKg/640?wx_fmt=webp&from=appmsg)\n\n完整的RAG应用流程主要包含两个阶段：\n\n（1）数据准备阶段：数据提取--\\>文本分割--\\>向量化（embedding）--\\>数据入库；\n\n（2）应用阶段：用户提问--\\>数据检索（检索）--\\>注入Prompt（增强）--\\>LLM生成答案（生成）。\n\n下面我们详细介绍一下各环节的技术细节和注意事项：\n\n####   \n1 数据准备阶段  \n\n数据准备一般是一个离线的过程，主要是将私域数据向量化后构建索引并存入数据库的过程。主要包括：数据提取、文本分割、向量化、数据入库等环节。\n\n![Image 27: Image](https://mmbiz.qpic.cn/mmbiz_jpg/icUqtxmPRjDGTYd1pxeGia411WmROHIvul6wOxIDvBia5Zw7f7HRVKbhdUMEIePdxwH7emljTXBkBdZwbGH7qxDUQ/640?wx_fmt=webp&from=appmsg)\n\n数据提取 \n\no 数据加载：包括多格式数据加载、不同数据源获取等，根据数据自身情况，将数据处理为同一个范式。 \n\no 数据处理：包括数据过滤、压缩、格式化等。 \n\no 元数据获取：提取数据中关键信息，例如文件名、Title、时间等。\n\n文本分割 \n\n文本分割主要考虑两个因素：(1) embedding模型的Tokens限制情况；(2) 语义完整性对整体的检索效果的影响。一些常见的文本分割方式如下：o 句分割：以”句”的粒度进行切分，保留一个句子的完整语义。常见切分符包括：句号、感叹号、问号、换行符等。o 固定长度分割：根据embedding模型的token长度限制，将文本分割为固定长度（例如256/512个tokens），这种切分方式会损失很多语义信息，一般通过在头尾增加一定冗余量来缓解。\n\n向量化（Embedding） \n\n向量化是一个将文本数据转化为向量矩阵的过程，该过程会直接影响到后续检索的效果。目前常见的Embedding模型基本能满足大部分需求，但对于特殊场景（例如涉及一些罕见专有词或字等）或者想进一步优化效果，则可以选择开源Embedding模型微调或直接训练适合自己场景的Embedding模型。\n\n数据入库 \n\n数据向量化后构建索引，并写入数据库的过程可以概述为数据入库过程，适用于RAG场景的数据库包括：FAISS、Chromadb、Milvus、ES等。一般可以根据业务场景、硬件、性能需求等多因素综合考虑，选择合适的数据库。\n\n#### 2 应用阶段  \n\n在应用阶段，我们根据用户的提问，通过高效的检索方法，召回与提问最相关的知识，并融入Prompt；大模型参考当前提问和相关知识，生成相应的答案。关键环节包括：数据检索、注入Prompt等。\n\n![Image 28: Image](https://mmbiz.qpic.cn/mmbiz_jpg/icUqtxmPRjDGTYd1pxeGia411WmROHIvuldEweMtGWPB6RxKneiaiayQAA0aBse87s1icq1F9ib2UwxaicaibCz5c33jFQ/640?wx_fmt=webp&from=appmsg)\n\n*   数据检索\n    \n\n常见的数据检索方法包括：相似性检索、全文检索等，根据检索效果，一般可以选择多种检索方式融合，提升召回率。o 相似性检索：即计算查询向量与所有存储向量的相似性得分，返回得分高的记录。常见的相似性计算方法包括：余弦相似性、欧氏距离、曼哈顿距离等。o 全文检索：全文检索是一种比较经典的检索方式，在数据存入时，通过关键词构建倒排索引；在检索时，通过关键词进行全文检索，找到对应的记录，比如ES。\n\n*   注入Prompt \n    \n    ![Image 29: Image](https://mmbiz.qpic.cn/mmbiz_jpg/icUqtxmPRjDGTYd1pxeGia411WmROHIvulzXLvQk1u5Vx0knbbWwPXpsU61aiaxULiae30IjDSs7xvibL1gic5hibUhmw/640?wx_fmt=webp&from=appmsg)\n    \n\nPrompt作为大模型的直接输入，是影响模型输出准确率的关键因素之一。在RAG场景中，Prompt一般包括任务描述、背景知识（检索得到）、任务指令（一般是用户提问）等，根据任务场景和大模型性能，也可以在Prompt中适当加入其他指令优化大模型的输出。\n\n*   LLM生成\n    \n\n在这个阶段，我们将经过检索增强的提示内容输入到大语言模型（LLM）中，以生成所需的输出。这个过程是RAG的核心，它利用LLM的强大生成能力，结合前两个阶段的信息，从而生成准确、丰富且与上下文相关的输出。\n\n###   \n常见的RAG开源框架  \n\n####   \nHaystack  \n\nHaystack 是一个强大而灵活的框架，用于构建端到端问题解答和搜索系统。它采用模块化架构，允许开发人员轻松创建各种 NLP 任务的管道，包括文档检索、问题解答和摘要：\n\n  \n```\n- 支持多种文档存储（Elasticsearch、FAISS、SQL 等）  \n- 与流行的语言模型（BERT、RoBERTa、DPR 等）集成  \n- 处理大量文件的可扩展架构  \n- 易于使用的 API，可用于构建自定义 NLP 管道\n```\n\nhttps://github.com/deepset-ai/haystack\n\n####   \nRAGFlow  \n\nRAGFlow 是 RAG 框架领域中一个相对较新的加入者，但由于其注重简洁性和效率，很快就获得了人们的青睐。该框架旨在通过提供一套预建组件和工作流来简化基于 RAG 的应用程序的构建过程：\n\n  \n```\n- 直观的工作流设计界面  \n- 针对常见用例的预配置 RAG 管道  \n- 与流行的矢量数据库集成  \n- 支持自定义嵌入模型\n```\n\nRAGFlow 的用户友好型方法使其成为开发人员的一个极具吸引力的选择，这些开发人员希望快速创建和部署 RAG 应用程序原型，而无需深入研究底层的复杂性。\n\nhttps://github.com/infiniflow/ragflow\n\n####   \nTxtai  \n\ntxtai 是一个多功能的人工智能数据平台，它超越了传统的 RAG 框架。它为构建语义搜索、语言模型工作流和文档处理管道提供了一套全面的工具：\n\n  \n```\n- 嵌入式数据库，用于高效的相似性搜索  \n- 用于集成语言模型和其他人工智能服务的 API  \n- 用于自定义工作流的可扩展架构  \n- 支持多种语言和数据类型\n```\n\ntxtai 的一体化方法使其成为那些希望在单一框架内实现各种人工智能功能的企业的绝佳选择。\n\nhttps://github.com/neuml/txtai \n\n####   \nMiniRAG  \n\n  \n```\n1. 轻量级：  \n  - 设计简洁，易于部署和使用，适合中小型项目和资源有限的环境。  \n2. 高效检索：  \n  - 使用高效的检索算法和数据结构，快速从大规模文档库中检索相关信息。  \n3. 灵活性：  \n  - 支持多种检索和生成模型，可以根据需求进行灵活配置。  \n4. 易于集成：  \n  - 提供简单的 API 接口，方便与其他系统和工具集成。  \n5. 成本效益：  \n  - 相比大型 RAG 系统，MiniRAG 的资源消耗较低，成本更低。  \n```\n\n```\nhttps://github.com/HKUDS/MiniRAG\n```\n\n####   \nlangflow\n\n  \n```\n1. 可视化界面：  \n  - 提供直观的拖放界面，用户无需编写代码即可构建复杂的 NLP 流程。  \n2. 模块化设计：  \n  - 支持多种 NLP 组件（如文本生成、文本分类、实体识别、情感分析等），可以灵活组合。  \n3. 易于使用：  \n  - 即使没有编程背景的用户也可以轻松构建和管理 NLP 流程。  \n4. 可扩展性：  \n  - 支持自定义组件和插件，可以根据需求扩展功能，提供 RESTful API，方便与其他系统集成。。  \n5. 社区支持：  \n  - 开源项目，拥有活跃的社区支持和丰富的文档资源。  \n6. 集成能力：  \n  - 可以与多种工具和平台集成，如 OpenAI API、Hugging Face Transformers 等。\n```\n\n  \n\nhttps://github.com/langflow-ai/langflow \n\n![Image 30: Image](https://mmbiz.qpic.cn/mmbiz_png/icUqtxmPRjDGTYd1pxeGia411WmROHIvulic3oQnqPzNaasoRA6WaCsJxEyc6tDC21TO66GrSTmXoNIm6T9nduTrw/640?wx_fmt=png&from=appmsg)\n\n  \n多模态  \n\n---------\n\n###   \n什么是多模态？  \n\n多模态是从多个模态表达或感知事物。多个模态也可归类为同质性的模态，例如从两台相机中分别拍摄的图片，异质性的模态，即图片与文本语言的关系。目前研究领域中主要是对图像，文本，语音三种模态的处理。之所以要对模态进行融合，是因为不同模态的表现方式不一样，看待事物的角度也会不一样，所以存在一些交叉（所以存在信息冗余），互补（所以比单特征更优秀）的现象，甚至模态间可能还存在多种不同的信息交互，如果能合理的处理多模态信息，就能得到丰富特征信息。即概括来说多模态的显著特点是：余度性 和 互补性 。 多模态融合重点关注深度学习模型中融合特征的阶段，无论是数据级、特征级还是建议级。\n\n一句话总结：就是融合了多种不同类型的信息，比如图像、文本、音频和视频等。目前最常见的是Vision+Language的结合形式。\n\n###   \n几种常见的多模态任务  \n\n多模态任务指的是涉及到多种模态（如视觉、语音、文本等）数据的任务。以下是一些常见的多模态任务：\n\n图像分类和描述：给定一张图片，需要将其分类到不同的类别，并且根据图片生成相应的文字描述。\n\n视频分析：对于一段视频，需要进行各种分析，如人物跟踪、动作识别、情感分析等。\n\n语音识别和生成：将语音转化为文字，或者根据给定的文本生成相应的语音。\n\n视觉问答：基于对图像的理解，回答与之相关的问题。\n\n多模态机器翻译：将不同模态的输入翻译成目标语言的输出，如将一段视频中的语音和图像翻译成另一种语言的文字和图像。\n\n多模态情感识别：利用图像、文本、语音等不同的模态数据来识别人的情感状态，如快乐、悲伤、愤怒等。 需要注意的是，\n\n多模态任务的范围很广，上述只是其中的一部分，实际应用还有很多其他的多模态任务。\n\n###   \n多模态大型语言模型  \n\n多模态大型语言模型（Multimodal Large Language Models，简称MLLMs）是一类结合了大型语言模型（Large Language Models，简称LLMs）的自然语言处理能力与对其他模态（如视觉、音频等）数据的理解与生成能力的模型。这些模型通过整合文本、图像、声音等多种类型的输入和输出，提供更加丰富和自然的交互体验。 MLLMs的核心优势在于它们能够处理和理解来自不同模态的信息，并将这些信息融合以完成复杂的任务。例如，MLLMs可以分析一张图片并生成描述性的文本，或者根据文本描述生成相应的图像。这种跨模态的理解和生成能力，使得MLLMs在多个领域，如自动驾驶、智能助理、内容推荐系统、教育和培训等，都有广泛的应用前景。\n\n![Image 31: Image](https://mmbiz.qpic.cn/mmbiz_png/icUqtxmPRjDGTYd1pxeGia411WmROHIvulZibibADicEzJdliawyYibAE9tMu7gZiaErGwnbkPibibnf6zzqtOvupdDDEnlA/640?wx_fmt=png&from=appmsg)\n\n上图中，我们可以看到MLLMs的核心组成部分，包括：\n\n*   Modality Encoder：负责将不同模态的输入数据编码为模型可理解的表示；（图像编码器、音频编码器、视频编码器...）\n    \n*   Input Projector：将不同模态的输入数据映射到共享的语义空间；\n    \n*   LLMs：大型语言模型，用于处理文本数据；\n    \n*   Output Projector：将模型生成的输出映射回原始模态的空间；\n    \n*   Modality Generator：根据输入数据生成对应的输出数据(图像生成、视频生成、音频生成) 可以看到LLMs还是处于核心位置，多模态是在LLMs的基础上进行扩展的。\n    \n\n扩展的方式是找到一个方法将不同模态的数据映射到LLMs可以接收的语义空间。接下来我们分别看看这几个组成部分的具体内容\n\n###   \n多模态的分类  \n\n静态多模态大模型：这个主要是处理静态数据，比如图片和文本。\n\n动态多模态大模型：涉及动态数据，比如视频和音频。\n\n垂直领域多模态：针对特定领域的多模态应用。\n\n![Image 32: Image](https://mmbiz.qpic.cn/mmbiz_png/icUqtxmPRjDGTYd1pxeGia411WmROHIvulUwfxCEdUhibsZlRbfib6M116v0jhVia51XTBqmJEDyPo8udicYlcrltBdw/640?wx_fmt=png&from=appmsg)\n\n###   \n多模态学习  \n\n多模态学习（Multimodal Learning）是一种利用来自不同感官或交互方式的数据进行学习的方法，这些数据模态可能包括文本、图像、音频、视频等。多模态学习通过融合多种数据模态来训练模型，从而提高模型的感知与理解能力，实现跨模态的信息交互与融合。\n\n接下来分三部分：模态表示、多模态融合、跨模态对齐，一起来总结下多模型的核心：多模态学习\n\n![Image 33: Image](https://mmbiz.qpic.cn/mmbiz_png/icUqtxmPRjDGTYd1pxeGia411WmROHIvulbdkTLsgJ6zvOwOQPFuIPia8eb3bENkueqgx2jxwB4pw4sXGFFcr1upQ/640?wx_fmt=png&from=appmsg)\n\n####   \n一：模态表示  \n\n#####   \n什么是模态表示（Modal Representation）？  \n\n模态表示是将不同感官或交互方式的数据（如文本、图像、声音等）转换为计算机可理解和处理的形式，以便进行后续的计算、分析和融合。\n\n*   文本模态的表示：文本模态的表示方法有多种，如独热表示、低维空间表示（如通过神经网络模型学习得到的转换矩阵将单词或字映射到语义空间中）、词袋表示及其衍生出的n-grams词袋表示等。目前，主流的文本表示方法是预训练文本模型，如BERT。\n    \n*   视觉模态的表示：视觉模态分为图像模态和视频模态。图像模态的表示主要通过卷积神经网络（CNN）实现，如LeNet-5、AlexNet、VGG、GoogLeNet、ResNet等。视频模态的表示则结合了图像的空间属性和时间属性，通常由CNN和循环神经网络（RNN）或长短时记忆网络（LSTM）等模型共同处理。\n    \n*   声音模态的表示：声音模态的表示通常涉及音频信号的预处理、特征提取和表示学习等步骤，常用的模型包括深度神经网络（DNN）、卷积神经网络（CNN）和循环神经网络（RNN）等。\n    \n\n#####   \n表征学习（Representation Learning）  \n\n旨在从原始数据中自动提取有效特征，形成计算机可理解的模态表示，以保留关键信息并促进跨模态交互与融合。 表征学习 表征学习（Representation Learning） ≈ 向量化（Embedding）\n\n[神经网络算法 - 一文搞懂Embedding（嵌入）](https://mp.weixin.qq.com/s?__biz=MzkzMTEzMzI5Ng==&mid=2247485705&idx=1&sn=9a17507d7df772170e96f1b63654e7fb&chksm=c26eeb16f51962009672985d95f8512566894c241786a64f6a1737d21f44aeb6bc8101c7671b&scene=21#wechat_redirect)\n\n[一文彻底搞懂Embedding - Word2Vec（Skip-Gram和CBOW）](https://mp.weixin.qq.com/s?__biz=MzkzMTEzMzI5Ng==&mid=2247491663&idx=1&sn=75dcb1b68bbc2f94b1d3ced557244230&chksm=c26d0250f51a8b464e2bde0008ec9db798049a93dd3b16eedfb789513e32e45fd98e8595cde8&scene=21#wechat_redirect)\n\n#####   \n什么是多模态联合表示（Joint Representation）？  \n\n多模态联合表示是一种将多个模态（如文本、图像、声音等）的信息共同映射到一个统一的多模态向量空间中的表示方法。 多模态联合表示通过神经网络、概率图模型将来自不同模态的数据进行融合，生成一个包含多个模态信息的统一表示。这个表示不仅保留了每个模态的关键信息，还能够在不同模态之间建立联系，从而支持跨模态的任务，如多模态情感分析、视听语音识别等。\n\n![Image 34: Image](https://mmbiz.qpic.cn/mmbiz_png/icUqtxmPRjDGTYd1pxeGia411WmROHIvuluuFxPg6ItgLECYkrusHD8USBCLt7FX3LXyBKZfibKp4m8wgx4f2PWAg/640?wx_fmt=png&from=appmsg)\n\n#####   \n多模态表示  \n\n什么是多模态协同表示（Coordinated Representation）？\n\n多模态协同表示是一种将多个模态的信息分别映射到各自的表示空间，但映射后的向量或表示之间需要满足一定的相关性或约束条件的方法。这种方法的核心在于确保不同模态之间的信息在协同空间内能够相互协作，共同优化模型的性能。\n\n![Image 35: Image](https://mmbiz.qpic.cn/mmbiz_png/icUqtxmPRjDGTYd1pxeGia411WmROHIvulGELkGoR1BkA3GpoIibaQVZ1kj29icyMBFAoZZDvyaIFlKem2T7AG07Eg/640?wx_fmt=png&from=appmsg)\n\n####   \n二、多模态融合  \n\n#####   \n什么是多模态融合（MultiModal Fusion）？  \n\n多模态融合能够充分利用不同模态之间的互补性，它将抽取自不同模态的信息整合成一个稳定的多模态表征。从数据处理的层次角度将多模态融合分为数据级融合、特征级融合和目标级融合。\n\n![Image 36: Image](https://mmbiz.qpic.cn/mmbiz_jpg/icUqtxmPRjDGTYd1pxeGia411WmROHIvulv8Apiaz3PQJb5IRk5wpRKwMrk8fbmbNty5yPDpVnvNptp8hI9pZxIibA/640?wx_fmt=jpeg&from=appmsg)\n\n1.  数据级融合（Data-Level Fusion）：\n    \n\n*   数据级融合，也称为像素级融合或原始数据融合，是在最底层的数据级别上进行融合。这种融合方式通常发生在数据预处理阶段，即将来自不同模态的原始数据直接合并或叠加在一起，形成一个新的数据集。\n    \n*   应用场景：适用于那些原始数据之间具有高度相关性和互补性的情况，如图像和深度图的融合。\n    \n\n1.  特征级融合（Feature-Level Fusion）：\n    \n\n*   特征级融合是在特征提取之后、决策之前进行的融合。不同模态的数据首先被分别处理，提取出各自的特征表示，然后将这些特征表示在某一特征层上进行融合。\n    \n*   应用场景：广泛应用于图像分类、语音识别、情感分析等多模态任务中。\n    \n\n1.  目标级融合（Decision-Level Fusion）：\n    \n\n*   目标级融合，也称为决策级融合或后期融合，是在各个单模态模型分别做出决策之后进行的融合。每个模态的模型首先独立地处理数据并给出自己的预测结果（如分类标签、回归值等），然后将这些预测结果进行整合以得到最终的决策结果。\n    \n*   应用场景：适用于那些需要综合考虑多个独立模型预测结果的场景，如多传感器数据融合、多专家意见综合等。\n    \n    ![Image 37: Image](https://mmbiz.qpic.cn/mmbiz_jpg/icUqtxmPRjDGTYd1pxeGia411WmROHIvul5rzEkBN4iadUr8XSkjUjLPyBGBCG67EvZEjG0HFqBZW51bNkRXpaLmQ/640?wx_fmt=jpeg&from=appmsg)\n    \n\n####   \n三、跨模态对齐  \n\n#####   \n什么是跨模态对齐（MultiModal Alignment）？  \n\n跨模态对齐是通过各种技术手段，实现不同模态数据（如图像、文本、音频等）在特征、语义或表示层面上的匹配与对应。跨模态对齐主要分为两大类：显式对齐和隐式对齐。\n\n![Image 38: Image](https://mmbiz.qpic.cn/mmbiz_png/icUqtxmPRjDGTYd1pxeGia411WmROHIvuloX3ygZTwVPicD4SBbWzJ0ico9QEXicn01fKqviaEmFw1s10SNxozAwFEiaA/640?wx_fmt=png&from=appmsg)\n\n#####   \n什么是显示对齐（Explicit Alignment）？  \n\n直接建立不同模态之间的对应关系，包括无监督对齐和监督对齐。\n\n无监督对齐：利用数据本身的统计特性或结构信息，无需额外标签，自动发现不同模态间的对应关系。\n\n*   CCA（典型相关分析）：通过最大化两组变量之间的相关性来发现它们之间的线性关系，常用于图像和文本的无监督对齐。\n    \n*   自编码器：通过编码-解码结构学习数据的低维表示，有时结合循环一致性损失（Cycle Consistency Loss）来实现无监督的图像-文本对齐。\n    \n\n监督对齐：利用额外的标签或监督信息指导对齐过程，确保对齐的准确性。\n\n*   多模态嵌入模型：如DeViSE（Deep Visual-Semantic Embeddings），通过最大化图像和对应文本标签在嵌入空间中的相似度来实现监督对齐。\n    \n*   多任务学习模型：同时学习图像分类和文本生成任务，利用共享层或联合损失函数来促进图像和文本之间的监督对齐。\n    \n\n![Image 39: Image](https://mmbiz.qpic.cn/mmbiz_jpg/icUqtxmPRjDGTYd1pxeGia411WmROHIvulsM1xDB0pLjNEH6QfPE27O3PtmD8A4NP8uWp5CkDiap9fOiaFCibMiaOcUA/640?wx_fmt=jpeg&from=appmsg)\n\n##### 什么是隐式对齐（Implicit Alignment）？  \n\n不直接建立对应关系，而是通过模型内部机制隐式地实现跨模态的对齐。这包括注意力对齐和语义对齐。\n\n注意力对齐：通过注意力机制动态地生成不同模态之间的权重向量，实现跨模态信息的加权融合和对齐。\n\n*   Transformer模型：在跨模态任务中（如图像描述生成），利用自注意力机制和编码器-解码器结构，自动学习图像和文本之间的注意力分布，实现隐式对齐。\n    \n*   BERT-based模型：在问答系统或文本-图像检索中，结合BERT的预训练表示和注意力机制，隐式地对齐文本查询和图像内容。\n    \n\n语义对齐：在语义层面上实现不同模态之间的对齐，需要深入理解数据的潜在语义联系。\n\n*   图神经网络（GNN）：在构建图像和文本之间的语义图时，利用GNN学习节点（模态数据）之间的语义关系，实现隐式的语义对齐。\n    \n*   预训练语言模型与视觉模型结合：如CLIP（Contrastive Language-Image Pre-training），通过对比学习在大量图像-文本对上训练，使模型学习到图像和文本在语义层面上的对应关系，实现高效的隐式语义对齐。\n    \n\n![Image 40: Image](https://mmbiz.qpic.cn/mmbiz_png/icUqtxmPRjDGTYd1pxeGia411WmROHIvul1ickvrAKaicfrzeeOAYq3VBBLzUXhkQb2L164AVq4sZakJJpOSOAzd9g/640?wx_fmt=png&from=appmsg)\n\n####   \n常见多模态大模型  \n\n#####   \n国际主流模型  \n\nOpenAI 系列\n\n*   GPT-4V (Vision)：支持文本和图像输入，能完成图像描述、视觉问答、图文推理等任务。\n    \n*   DALL-E 系列：DALL-E 2/3 通过文本生成高质量图像，支持多模态输入（如文本+图像编辑）。\n    \n*   CLIP：专注于图文匹配，通过对比学习实现跨模态理解（文本与图像的关联）。\n    \n\nGoogle 系列\n\n*   Gemini：原生多模态设计，支持文本、图像、音频、视频等多种模态的输入和输出。\n    \n*   Flamingo：由 DeepMind 开发，擅长视觉问答和对话，支持长上下文的多模态交互。\n    \n*   PALI & PALM-E：PALI 支持多语言多模态任务，PALM-E 结合机器人领域的多模态感知与控制。\n    \n\nMeta 系列\n\n*   ImageBind：结合六种模态（图像、文本、音频、深度、热成像、IMU 数据），实现跨模态检索与生成。\n    \n*   LLaVA：基于 LLaMA 的开源模型，通过视觉指令微调完成图文交互任务。\n    \n\n微软系列\n\n*   Kosmos 系列：Kosmos-1/2 支持文本、图像、音频输入，擅长图文对话和跨模态推理。\n    \n*   Visual ChatGPT：结合 ChatGPT 与视觉模型，支持多轮对话中的图像编辑和生成。\n    \n\n其他国际模型\n\n*   Stable Diffusion：文本生成图像的开源模型，支持多模态提示（如草图+文本）。\n    \n*   Fuyu-8B (Adept AI)“专为界面理解和多模态交互设计，适合 GUI 操作和图表分析。\n    \n*   IDEFICS：开源模型，支持图文对话，性能接近 Flamingo。\n    \n\n#####   \n国内代表性模型\n\n阿里云\n\n*   Qwen-VL：通义千问的多模态版本，支持图像理解、文本生成和跨模态任务。\n    \n*   Qwen-VL-Chat：针对对话优化的版本，支持多轮交互中的图文混合输入。\n    \n\n商汤科技\n\n*   InternVL：基于 InternLM 的多模态模型，擅长图文匹配和视觉推理。\n    \n\n深度求索 (DeepSeek)\n\n*   DeepSeek-VL：开源模型，支持图文对话、文档解析和视觉问答。\n    \n\n其他国内模型\n\n*   智谱AI 的 CogVLM：结合视觉与语言模型，支持细粒度图像理解。\n    \n*   腾讯 的 Hunyuan-VL：文生图与多模态对话能力结合，应用于内容生成场景。\n    \n\n#####   \n开源社区模型\n\nMiniGPT-4：基于 BLIP-2 和 Vicuna，通过轻量化设计实现类似 GPT-4V 的图文交互。\n\nmPLUG-Owl：支持多模态指令跟随，可处理文本、图像和视频。 OpenFlamingo：Flamingo 的开源复现版本，支持少样本学习\n\n  \nMCP  \n\n---------\n\nMCP（Model Context Protocol，模型上下文协议） 是由 Anthropic 推出的一种开放标准，旨在统一大型语言模型（LLM）与外部数据源和工具之间的通信协议。MCP 的主要目的在于解决当前 AI 模型因数据孤岛限制而无法充分发挥潜力的难题，MCP 使得 AI 应用能够安全地访问和操作本地及远程数据，为 AI 应用提供了连接万物的接口。\n\n![Image 41: Image](https://mmbiz.qpic.cn/mmbiz_png/icUqtxmPRjDGTYd1pxeGia411WmROHIvulCL61ubHKZyD9ic34s7X4yQlLnUmCJFAnTIF1pLVRtLQ434zE0thibg5Q/640?wx_fmt=png&from=appmsg)\n\nMCP协议的核心是将一般的AI AGENT函数调用的工程架构抽象为了客户端、服务器结构，可以理解为是对函数调用AGENT在工程层面实现了一个更好的抽象。抽象之后客户端可以是传统的服务请求、大模型请求、或者是一般的Tool请求等。服务器端的实现则是更适合大模型体质的方式，同时兼容非大模型的请求，服务器端的实现最核心的地方在于引入了Resources、Tools、Prompts等概念。\n\nResources主要作用是描述当前服务端，一般包含服务的唯一标识、服务的名称、服务的主要功能、以及其它相关信息（当通过大模型的客户端提问时，需要知道当前问题应该需要由哪个服务解决此时会依赖这个资源描述信息）。\n\nTools主要用于定义一组可用API，表示该服务可提供的功能，同时每个Tool都有类似Resources的描述，只不过Tool不需要唯一标识。\n\nPrompts主要作用是为大模型实现的客户端提供一些有价值的上下文信息（这是可选的），可以是模板方式生成、也可以是动态的，取决于当前服务具体的功能是什么。\n\n###   \nMCP的意义  \n\n1.  建立开放的集成标准： 通过标准化应用程序与LLM之间的上下文交互方式，提升模型的上下文感知能力和任务协作能力。\n    \n2.  加强数据安全与控制： 所有操作均需用户授权，且MCP服务部署于本地，有效避免数据外泄风险，保障数据安全。\n    \n3.  构建丰富的工具生态： 解决了过去LLM工具不兼容的问题，提供多样化的工具选择。\n    \n\n###   \nMCP架构  \n\n![Image 42: Image](https://mmbiz.qpic.cn/mmbiz_png/icUqtxmPRjDGTYd1pxeGia411WmROHIvulgcbiadQGYNHT4Zmb0HXy53ibjY000n3n58Ht15BialibKgErCy0rWJEU1g/640?wx_fmt=png&from=appmsg)\n\n  \n```\nMCP主机：像Claude Desktop、集成开发环境（IDEs）或希望通过MCP访问数据的AI工具这样的程序。  \nMCP客户端：与服务器保持1:1连接的协议客户端。  \nMCP服务器：通过标准化的模型上下文协议（MCP）暴露特定能力的轻量级程序。  \n本地数据源（注：目前主要还是本地化操作，对于云端操作还是有局限性）：计算机上的文件、数据库和服务，MCP服务器可以安全地访问。  \n远程服务：通过互联网可用的外部系统（例如，通过APIs），MCP服务器可以连接到这些系统。\n```\n\n###   \nMCP Client  \n\nMCP client 充当 LLM 和 MCP server 之间的桥梁，MCP client 的工作流程如下：\n\n*   MCP client 首先从 MCP server 获取可用的工具列表。\n    \n*   将用户的查询连同工具描述通过 function calling 一起发送给 LLM。\n    \n*   LLM 决定是否需要使用工具以及使用哪些工具。\n    \n*   如果需要使用工具，MCP client 会通过 MCP server 执行相应的工具调用。\n    \n*   工具调用的结果会被发送回 LLM。\n    \n*   LLM 基于所有信息生成自然语言响应。\n    \n*   最后将响应展示给用户。\n    \n\n  \n```\nimport asyncio  \nfrom typing import Optional  \nfrom contextlib import AsyncExitStack  \n  \nfrom mcp import ClientSession, StdioServerParameters  \nfrom mcp.client.stdio import stdio_client  \n  \nfrom anthropic import Anthropic  \nfrom dotenv import load_dotenv  \n  \nload_dotenv()  # 从.env加载环境变量  \n  \nclass MCPClient:  \n    def __init__(self):  \n# 初始化会话和客户端对象  \n        self.session: Optional[ClientSession] = None  \n        self.exit_stack = AsyncExitStack()  \n        self.anthropic = Anthropic()  \n  \n        async def connect_to_server(self, server_script_path: str):  \n\"\"\"连接到MCP服务器  \n  \n                参数:  \n                        server_script_path: 服务器脚本的路径（.py或.js）  \n                \"\"\"  \n                is_python = server_script_path.endswith('.py')  \n                is_js = server_script_path.endswith('.js')  \nif not (is_python or is_js):  \n                        raise ValueError(\"服务器脚本必须是.py或.js文件\")  \n  \ncommand = \"python\"if is_python else\"node\"  \n                server_params = StdioServerParameters(  \ncommand=command,  \n                        args=[server_script_path],  \n                        env=None  \n                )  \n  \n                stdio_transport = await self.exit_stack.enter_async_context(stdio_client(server_params))  \n                self.stdio, self.write = stdio_transport  \n                self.session = await self.exit_stack.enter_async_context(ClientSession(self.stdio, self.write))  \n  \n                await self.session.initialize()  \n  \n# 列出可用工具  \n                response = await self.session.list_tools()  \n                tools = response.tools  \nprint(\"\\n成功连接到服务器，工具列表:\", [tool.name for tool in tools])  \n  \n        async def process_query(self, query: str) -> str:  \n\"\"\"使用Claude及可用工具处理查询\"\"\"  \n                messages = [  \n                        {  \n\"role\": \"user\",  \n\"content\": query  \n                        }  \n                ]  \n  \n                response = await self.session.list_tools()  \n                available_tools = [{   \n\"name\": tool.name,  \n\"description\": tool.description,  \n\"input_schema\": tool.inputSchema  \n                } for tool in response.tools]  \n  \n# 初始Claude API调用  \n                response = self.anthropic.messages.create(  \n                        model=\"claude-3-5-sonnet-20241022\",  \n                        max_tokens=1000,  \n                        messages=messages,  \n                        tools=available_tools  \n                )  \n  \n# 处理响应和工具调用  \n                tool_results = []  \n                final_text = []  \n  \nfor content in response.content:  \nif content.type == 'text':  \n                                final_text.append(content.text)  \nelif content.type == 'tool_use':  \n                                tool_name = content.name  \n                                tool_args = content.input  \n  \n# 执行工具调用  \n                                result = await self.session.call_tool(tool_name, tool_args)  \n                                tool_results.append({\"call\": tool_name, \"result\": result})  \n                                final_text.append(f\"[调用工具 {tool_name}，参数 {tool_args}]\")  \n  \n# 将工具结果继续对话  \nif hasattr(content, 'text') and content.text:  \n                                        messages.append({  \n\"role\": \"assistant\",  \n\"content\": content.text  \n                                        })  \n                                messages.append({  \n\"role\": \"user\",   \n\"content\": result.content  \n                                })  \n  \n# 从Claude获取下一个响应  \n                                response = self.anthropic.messages.create(  \n                                        model=\"claude-3-5-sonnet-20241022\",  \n                                        max_tokens=1000,  \n                                        messages=messages,  \n                                )  \n  \n                                final_text.append(response.content[0].text)  \n  \nreturn\"\\n\".join(final_text)  \n  \n        async def chat_loop(self):  \n\"\"\"运行交互式聊天循环\"\"\"  \nprint(\"\\nMCP客户端已启动!\")  \nprint(\"输入您的查询，或输入'quit'退出。\")  \n  \nwhile True:  \n                        try:  \n                                query = input(\"\\n查询: \").strip()  \n  \nif query.lower() == 'quit':  \nbreak  \n  \n                                response = await self.process_query(query)  \nprint(\"\\n\" + response)  \n  \n                        except Exception as e:  \nprint(f\"\\n错误: {str(e)}\")  \n  \n        async def cleanup(self):  \n\"\"\"清理资源\"\"\"  \n                await self.exit_stack.aclose()  \n  \n# 入口点                  \nasync def main():  \nif len(sys.argv) < 2:  \nprint(\"用法: python client.py <path_to_server_script>\")  \n        sys.exit(1)  \n  \n    client = MCPClient()  \n    try:  \n        await client.connect_to_server(sys.argv[1])  \n        await client.chat_loop()  \n    finally:  \n        await client.cleanup()  \n  \nif __name__ == \"__main__\":  \n    import sys  \n    asyncio.run(main())  \n```\n\n你可以在 Example Clients 找到当前支持 MCP 协议的客户端程序。本文将会使用 Claude Desktop 作为 MCP client，你可以在此页面下载安装：https://claude.ai/download 。\n\n###   \nMCP Server  \n\nMCP server 是 MCP 架构中的关键组件，它可以提供 3 种主要类型的功能：\n\n资源（Resources）：类似文件的数据，可以被客户端读取，如 API 响应或文件内容。\n\n工具（Tools）：可以被 LLM 调用的函数（需要用户批准）。\n\n提示（Prompts）：预先编写的模板，帮助用户完成特定任务。\n\n这些功能使 MCP server 能够为 AI 应用提供丰富的上下文信息和操作能力，从而增强 LLM 的实用性和灵活性。 你可以在 MCP Servers Repository 和 Awesome MCP Servers 这两个 repo 中找到许多由社区实现的 MCP server。使用 TypeScript 编写的 MCP server 可以通过 npx 命令来运行，使用 Python 编写的 MCP server 可以通过 uvx 命令来运行。 MPC Server代码实现\n\n  \n```\nimport sqlite3  \nimport logging  \nfrom logging.handlers import RotatingFileHandler  \nfrom contextlib import closing  \nfrom pathlib import Path  \nfrom mcp.server.models import InitializationOptions  \nimport mcp.types as types  \nfrom mcp.server import NotificationOptions, Server  \nimport mcp.server.stdio  \nfrom pydantic import AnyUrl  \nfrom typing import Any  \n  \nlogger = logging.getLogger('mcp_sqlite_server')  \nlogger.info(\"Starting MCP SQLite Server\")  \n  \nPROMPT_TEMPLATE = \"\"\"  \nThe assistants goal is to walkthrough an informative demo of MCP. To demonstrate the Model Context Protocol (MCP) we will leverage this example server to interact with an SQLite database.  \nIt is important that you first explain to the user what is going on. The user has downloaded and installed the SQLite MCP Server and is now ready to use it.  \nThey have selected the MCP menu item which is contained within a parent menu denoted by the paperclip icon. Inside this menu they selected an icon that illustrates two electrical plugs connecting. This is the MCP menu.  \nBased on what MCP servers the user has installed they can click the button which reads: 'Choose an integration' this will present a drop down with Prompts and Resources. The user has selected the prompt titled: 'mcp-demo'.  \nThis text file is that prompt. The goal of the following instructions is to walk the user through the process of using the 3 core aspects of an MCP server. These are: Prompts, Tools, and Resources.  \nThey have already used a prompt and provided a topic. The topic is: {topic}. The user is now ready to begin the demo.  \nHere is some more information about mcp and this specific mcp server:  \n<mcp>  \nPrompts:  \nThis server provides a pre-written prompt called \"mcp-demo\" that helps users create and analyze database scenarios. The prompt accepts a \"topic\" argument and guides users through creating tables, analyzing data, and generating insights. For example, if a user provides \"retail sales\" as the topic, the prompt will help create relevant database tables and guide the analysis process. Prompts basically serve as interactive templates that help structure the conversation with the LLM in a useful way.  \nResources:  \nThis server exposes one key resource: \"memo://insights\", which is a business insights memo that gets automatically updated throughout the analysis process. As users analyze the database and discover insights, the memo resource gets updated in real-time to reflect new findings. The memo can even be enhanced with Claude's help if an Anthropic API key is provided, turning raw insights into a well-structured business document. Resources act as living documents that provide context to the conversation.  \nTools:  \nThis server provides several SQL-related tools:  \n\"read-query\": Executes SELECT queries to read data from the database  \n\"write-query\": Executes INSERT, UPDATE, or DELETE queries to modify data  \n\"create-table\": Creates new tables in the database  \n\"list-tables\": Shows all existing tables  \n\"describe-table\": Shows the schema for a specific table  \n\"append-insight\": Adds a new business insight to the memo resource  \n</mcp>  \n<demo-instructions>  \nYou are an AI assistant tasked with generating a comprehensive business scenario based on a given topic.  \nYour goal is to create a narrative that involves a data-driven business problem, develop a database structure to support it, generate relevant queries, create a dashboard, and provide a final solution.  \n  \nAt each step you will pause for user input to guide the scenario creation process. Overall ensure the scenario is engaging, informative, and demonstrates the capabilities of the SQLite MCP Server.  \nYou should guide the scenario to completion. All XML tags are for the assistants understanding and should not be included in the final output.  \n  \n1. The user has chosen the topic: {topic}.  \n  \n2. Create a business problem narrative:  \na. Describe a high-level business situation or problem based on the given topic.  \nb. Include a protagonist (the user) who needs to collect and analyze data from a database.  \nc. Add an external, potentially comedic reason why the data hasn't been prepared yet.  \nd. Mention an approaching deadline and the need to use Claude (you) as a business tool to help.  \n  \n3. Setup the data:  \na. Instead of asking about the data that is required for the scenario, just go ahead and use the tools to create the data. Inform the user you are \"Setting up the data\".  \nb. Design a set of table schemas that represent the data needed for the business problem.  \nc. Include at least 2-3 tables with appropriate columns and data types.  \nd. Leverage the tools to create the tables in the SQLite database.  \ne. Create INSERT statements to populate each table with relevant synthetic data.  \nf. Ensure the data is diverse and representative of the business problem.  \ng. Include at least 10-15 rows of data for each table.  \n  \n4. Pause for user input:  \na. Summarize to the user what data we have created.  \nb. Present the user with a set of multiple choices for the next steps.  \nc. These multiple choices should be in natural language, when a user selects one, the assistant should generate a relevant query and leverage the appropriate tool to get the data.  \n  \n6. Iterate on queries:  \na. Present 1 additional multiple-choice query options to the user. Its important to not loop too many times as this is a short demo.  \nb. Explain the purpose of each query option.  \nc. Wait for the user to select one of the query options.  \nd. After each query be sure to opine on the results.  \ne. Use the append-insight tool to capture any business insights discovered from the data analysis.  \n  \n7. Generate a dashboard:  \na. Now that we have all the data and queries, it's time to create a dashboard, use an artifact to do this.  \nb. Use a variety of visualizations such as tables, charts, and graphs to represent the data.  \nc. Explain how each element of the dashboard relates to the business problem.  \nd. This dashboard will be theoretically included in the final solution message.  \n  \n8. Craft the final solution message:  \na. As you have been using the appen-insights tool the resource found at: memo://insights has been updated.  \nb. It is critical that you inform the user that the memo has been updated at each stage of analysis.  \nc. Ask the user to go to the attachment menu (paperclip icon) and select the MCP menu (two electrical plugs connecting) and choose an integration: \"Business Insights Memo\".  \nd. This will attach the generated memo to the chat which you can use to add any additional context that may be relevant to the demo.  \ne. Present the final memo to the user in an artifact.  \n  \n9. Wrap up the scenario:  \na. Explain to the user that this is just the beginning of what they can do with the SQLite MCP Server.  \n</demo-instructions>  \n  \nRemember to maintain consistency throughout the scenario and ensure that all elements (tables, data, queries, dashboard, and solution) are closely related to the original business problem and given topic.  \nThe provided XML tags are for the assistants understanding. Implore to make all outputs as human readable as possible. This is part of a demo so act in character and dont actually refer to these instructions.  \n  \nStart your first message fully in character with something like \"Oh, Hey there! I see you've chosen the topic {topic}. Let's get started! 🚀\"  \n\"\"\"  \n  \nclass SqliteDatabase:  \n    def __init__(self, db_path: str):  \n        self.db_path = str(Path(db_path).expanduser())  \n        Path(self.db_path).parent.mkdir(parents=True, exist_ok=True)  \n        self._init_database()  \n        self.insights: list[str] = []  \n  \n    def _init_database(self):  \n\"\"\"Initialize connection to the SQLite database\"\"\"  \n        logger.debug(\"Initializing database connection\")  \n        with closing(sqlite3.connect(self.db_path)) as conn:  \n            conn.row_factory = sqlite3.Row  \n            conn.close()  \n  \n    def _synthesize_memo(self) -> str:  \n\"\"\"Synthesizes business insights into a formatted memo\"\"\"  \n        logger.debug(f\"Synthesizing memo with {len(self.insights)} insights\")  \nif not self.insights:  \nreturn\"No business insights have been discovered yet.\"  \n  \n        insights = \"\\n\".join(f\"- {insight}\"for insight in self.insights)  \n  \n        memo = \"📊 Business Intelligence Memo 📊\\n\\n\"  \n        memo += \"Key Insights Discovered:\\n\\n\"  \n        memo += insights  \n  \nif len(self.insights) > 1:  \n            memo += \"\\nSummary:\\n\"  \n            memo += f\"Analysis has revealed {len(self.insights)} key business insights that suggest opportunities for strategic optimization and growth.\"  \n  \n        logger.debug(\"Generated basic memo format\")  \nreturn memo  \n  \n    def _execute_query(self, query: str, params: dict[str, Any] | None = None) -> list[dict[str, Any]]:  \n\"\"\"Execute a SQL query and return results as a list of dictionaries\"\"\"  \n        logger.debug(f\"Executing query: {query}\")  \n        try:  \n            with closing(sqlite3.connect(self.db_path)) as conn:  \n                conn.row_factory = sqlite3.Row  \n                with closing(conn.cursor()) as cursor:  \nif params:  \n                        cursor.execute(query, params)  \nelse:  \n                        cursor.execute(query)  \n  \nif query.strip().upper().startswith(('INSERT', 'UPDATE', 'DELETE', 'CREATE', 'DROP', 'ALTER')):  \n                        conn.commit()  \n                        affected = cursor.rowcount  \n                        logger.debug(f\"Write query affected {affected} rows\")  \nreturn [{\"affected_rows\": affected}]  \n  \n                    results = [dict(row) for row in cursor.fetchall()]  \n                    logger.debug(f\"Read query returned {len(results)} rows\")  \nreturn results  \n        except Exception as e:  \n            logger.error(f\"Database error executing query: {e}\")  \n            raise  \n  \nasync def main(db_path: str):  \n    logger.info(f\"Starting SQLite MCP Server with DB path: {db_path}\")  \n  \n    db = SqliteDatabase(db_path)  \n    server = Server(\"sqlite-manager\")  \n  \n# Register handlers  \n    logger.debug(\"Registering handlers\")  \n  \n    @server.list_resources()  \n    async def handle_list_resources() -> list[types.Resource]:  \n        logger.debug(\"Handling list_resources request\")  \nreturn [  \n            types.Resource(  \n                uri=AnyUrl(\"memo://insights\"),  \n                name=\"Business Insights Memo\",  \n                description=\"A living document of discovered business insights\",  \n                mimeType=\"text/plain\",  \n            )  \n        ]  \n  \n    @server.read_resource()  \n    async def handle_read_resource(uri: AnyUrl) -> str:  \n        logger.debug(f\"Handling read_resource request for URI: {uri}\")  \nif uri.scheme != \"memo\":  \n            logger.error(f\"Unsupported URI scheme: {uri.scheme}\")  \n            raise ValueError(f\"Unsupported URI scheme: {uri.scheme}\")  \n  \n        path = str(uri).replace(\"memo://\", \"\")  \nif not path or path != \"insights\":  \n            logger.error(f\"Unknown resource path: {path}\")  \n            raise ValueError(f\"Unknown resource path: {path}\")  \n  \nreturn db._synthesize_memo()  \n  \n    @server.list_prompts()  \n    async def handle_list_prompts() -> list[types.Prompt]:  \n        logger.debug(\"Handling list_prompts request\")  \nreturn [  \n            types.Prompt(  \n                name=\"mcp-demo\",  \n                description=\"A prompt to seed the database with initial data and demonstrate what you can do with an SQLite MCP Server + Claude\",  \n                arguments=[  \n                    types.PromptArgument(  \n                        name=\"topic\",  \n                        description=\"Topic to seed the database with initial data\",  \n                        required=True,  \n                    )  \n                ],  \n            )  \n        ]  \n  \n    @server.get_prompt()  \n    async def handle_get_prompt(name: str, arguments: dict[str, str] | None) -> types.GetPromptResult:  \n        logger.debug(f\"Handling get_prompt request for {name} with args {arguments}\")  \nif name != \"mcp-demo\":  \n            logger.error(f\"Unknown prompt: {name}\")  \n            raise ValueError(f\"Unknown prompt: {name}\")  \n  \nif not arguments or \"topic\" not in arguments:  \n            logger.error(\"Missing required argument: topic\")  \n            raise ValueError(\"Missing required argument: topic\")  \n  \n        topic = arguments[\"topic\"]  \n        prompt = PROMPT_TEMPLATE.format(topic=topic)  \n  \n        logger.debug(f\"Generated prompt template for topic: {topic}\")  \nreturn types.GetPromptResult(  \n            description=f\"Demo template for {topic}\",  \n            messages=[  \n                types.PromptMessage(  \n                    role=\"user\",  \n                    content=types.TextContent(type=\"text\", text=prompt.strip()),  \n                )  \n            ],  \n        )  \n  \n    @server.list_tools()  \n    async def handle_list_tools() -> list[types.Tool]:  \n\"\"\"List available tools\"\"\"  \nreturn [  \n            types.Tool(  \n                name=\"read-query\",  \n                description=\"Execute a SELECT query on the SQLite database\",  \n                inputSchema={  \n\"type\": \"object\",  \n\"properties\": {  \n\"query\": {\"type\": \"string\", \"description\": \"SELECT SQL query to execute\"},  \n                    },  \n\"required\": [\"query\"],  \n                },  \n            ),  \n            types.Tool(  \n                name=\"write-query\",  \n                description=\"Execute an INSERT, UPDATE, or DELETE query on the SQLite database\",  \n                inputSchema={  \n\"type\": \"object\",  \n\"properties\": {  \n\"query\": {\"type\": \"string\", \"description\": \"SQL query to execute\"},  \n                    },  \n\"required\": [\"query\"],  \n                },  \n            ),  \n            types.Tool(  \n                name=\"create-table\",  \n                description=\"Create a new table in the SQLite database\",  \n                inputSchema={  \n\"type\": \"object\",  \n\"properties\": {  \n\"query\": {\"type\": \"string\", \"description\": \"CREATE TABLE SQL statement\"},  \n                    },  \n\"required\": [\"query\"],  \n                },  \n            ),  \n            types.Tool(  \n                name=\"list-tables\",  \n                description=\"List all tables in the SQLite database\",  \n                inputSchema={  \n\"type\": \"object\",  \n\"properties\": {},  \n                },  \n            ),  \n            types.Tool(  \n                name=\"describe-table\",  \n                description=\"Get the schema information for a specific table\",  \n                inputSchema={  \n\"type\": \"object\",  \n\"properties\": {  \n\"table_name\": {\"type\": \"string\", \"description\": \"Name of the table to describe\"},  \n                    },  \n\"required\": [\"table_name\"],  \n                },  \n            ),  \n            types.Tool(  \n                name=\"append-insight\",  \n                description=\"Add a business insight to the memo\",  \n                inputSchema={  \n\"type\": \"object\",  \n\"properties\": {  \n\"insight\": {\"type\": \"string\", \"description\": \"Business insight discovered from data analysis\"},  \n                    },  \n\"required\": [\"insight\"],  \n                },  \n            ),  \n        ]  \n  \n    @server.call_tool()  \n    async def handle_call_tool(  \n        name: str, arguments: dict[str, Any] | None  \n    ) -> list[types.TextContent | types.ImageContent | types.EmbeddedResource]:  \n\"\"\"Handle tool execution requests\"\"\"  \n        try:  \nif name == \"list-tables\":  \n                results = db._execute_query(  \n\"SELECT name FROM sqlite_master WHERE type='table'\"  \n                )  \nreturn [types.TextContent(type=\"text\", text=str(results))]  \n  \nelif name == \"describe-table\":  \nif not arguments or \"table_name\" not in arguments:  \n                    raise ValueError(\"Missing table_name argument\")  \n                results = db._execute_query(  \n                    f\"PRAGMA table_info({arguments['table_name']})\"  \n                )  \nreturn [types.TextContent(type=\"text\", text=str(results))]  \n  \nelif name == \"append-insight\":  \nif not arguments or \"insight\" not in arguments:  \n                    raise ValueError(\"Missing insight argument\")  \n  \n                db.insights.append(arguments[\"insight\"])  \n                _ = db._synthesize_memo()  \n  \n# Notify clients that the memo resource has changed  \n                await server.request_context.session.send_resource_updated(AnyUrl(\"memo://insights\"))  \n  \nreturn [types.TextContent(type=\"text\", text=\"Insight added to memo\")]  \n  \nif not arguments:  \n                raise ValueError(\"Missing arguments\")  \n  \nif name == \"read-query\":  \nif not arguments[\"query\"].strip().upper().startswith(\"SELECT\"):  \n                    raise ValueError(\"Only SELECT queries are allowed for read-query\")  \n                results = db._execute_query(arguments[\"query\"])  \nreturn [types.TextContent(type=\"text\", text=str(results))]  \n  \nelif name == \"write-query\":  \nif arguments[\"query\"].strip().upper().startswith(\"SELECT\"):  \n                    raise ValueError(\"SELECT queries are not allowed for write-query\")  \n                results = db._execute_query(arguments[\"query\"])  \nreturn [types.TextContent(type=\"text\", text=str(results))]  \n  \nelif name == \"create-table\":  \nif not arguments[\"query\"].strip().upper().startswith(\"CREATE TABLE\"):  \n                    raise ValueError(\"Only CREATE TABLE statements are allowed\")  \n                db._execute_query(arguments[\"query\"])  \nreturn [types.TextContent(type=\"text\", text=\"Table created successfully\")]  \n  \nelse:  \n                raise ValueError(f\"Unknown tool: {name}\")  \n  \n        except sqlite3.Error as e:  \nreturn [types.TextContent(type=\"text\", text=f\"Database error: {str(e)}\")]  \n        except Exception as e:  \nreturn [types.TextContent(type=\"text\", text=f\"Error: {str(e)}\")]  \n  \n    async with mcp.server.stdio.stdio_server() as (read_stream, write_stream):  \n        logger.info(\"Server running with stdio transport\")  \n        await server.run(  \n            read_stream,  \n            write_stream,  \n            InitializationOptions(  \n                server_name=\"sqlite\",  \n                server_version=\"0.1.0\",  \n                capabilities=server.get_capabilities(  \n                    notification_options=NotificationOptions(),  \n                    experimental_capabilities={},  \n                ),  \n            ),  \n        )  \n```\n\n  \n扩散模型  \n\n----------\n\n###   \n什么是扩散模型？  \n\n扩散模型（Diffusion Models）是一类基于概率生成模型的深度学习方法，近年来在图像生成、语音合成、文本生成等领域取得了显著的成果。它通过模拟物理扩散过程，将数据逐步转化为噪声，再学习一个逆向过程，从噪声中逐步恢复出原始数据，最终实现高质量的生成。 扩散模型的核心思想包括两个主要过程：\n\n*   正向扩散过程（Forward Diffusion Process） 逐步向数据中添加噪声，使其转变为纯噪声。 通常用一个马尔可夫链表示，每一步加少量高斯噪声。\n    \n*   逆向生成过程（Reverse Generation Process） 学习一个逆向扩散的马尔可夫链，从噪声中逐步去除噪声，恢复出原始数据。 通过神经网络来预测并消除各步所添加的噪声。\n    \n\n通过这两个过程，可以在训练时把真实数据变成纯噪声，然后在生成时从纯噪声“还原”出逼真的数据样本。 以下是一个简化版扩散模型示例代码：\n\n  \n```\nimport torch  \nimport torch.nn as nn  \nimport torch.optim as optim  \nfrom torch.distributions.normal import Normal  \n  \n# 定义去噪网络模型（U-Net 的简化版本）  \nclass SimpleDenoiseNet(nn.Module):  \n    def __init__(self):  \n        super(SimpleDenoiseNet, self).__init__()  \n        self.fc1 = nn.Linear(28*28, 256)  \n        self.fc2 = nn.Linear(256, 256)  \n        self.fc3 = nn.Linear(256, 28*28)  \n  \n    def forward(self, x, t):  \n# 网络接受噪声图像和时间步t  \n        x = torch.cat([x, t], dim=-1)  \n        x = torch.relu(self.fc1(x))  \n        x = torch.relu(self.fc2(x))  \nreturn self.fc3(x)  \n  \n# 正向过程：逐步添加高斯噪声  \ndef forward_process(x0, timesteps, beta):  \n    noise = Normal(0, 1).sample(x0.shape).to(x0.device)  \n    alpha = 1.0 - beta  \n    alpha_cumprod = torch.cumprod(alpha, dim=0)  \n  \n    xt = x0 * alpha_cumprod.sqrt() + noise * (1.0 - alpha_cumprod).sqrt()  \nreturn xt, noise  \n  \n# 逆向过程：通过训练的去噪网络恢复原始数据  \ndef reverse_process(denoise_net, xt, timesteps, beta):  \n    alpha = 1.0 - beta  \n    alpha_cumprod = torch.cumprod(alpha, dim=0)  \n  \n    predicted_noise = denoise_net(xt, timesteps)  \n    predicted_x0 = (xt - (1.0 - alpha_cumprod).sqrt() * predicted_noise) / alpha_cumprod.sqrt()  \nreturn predicted_x0  \n  \n# 训练函数  \ndef train_diffusion_model(denoise_net, dataloader, epochs, timesteps, beta):  \n    optimizer = optim.Adam(denoise_net.parameters(), lr=1e-3)  \n    loss_fn = nn.MSELoss()  \n  \nfor epoch in range(epochs):  \nfor x0 in dataloader:  \n            x0 = x0.view(x0.size(0), -1).to(device)  \n            t = torch.randint(0, timesteps, (x0.size(0), 1)).float().to(x0.device)  \n  \n            xt, noise = forward_process(x0, t, beta)  \n            predicted_x0 = reverse_process(denoise_net, xt, t, beta)  \n  \n            loss = loss_fn(predicted_x0, x0)  \n            optimizer.zero_grad()  \n            loss.backward()  \n            optimizer.step()  \n  \nprint(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")  \n  \n# 超参数设置  \ntimesteps = 1000  \nbeta = torch.linspace(1e-4, 0.02, timesteps).to(device)  \ndenoise_net = SimpleDenoiseNet().to(device)  \n  \n# 训练模型  \ntrain_diffusion_model(denoise_net, dataloader, epochs=10, timesteps=timesteps, beta=beta)  \n```\n\n###   \n扩散模型的类型  \n\n扩散模型的类型主要包括以下几种：\n\n1.  去噪扩散概率模型 (DDPM):\n    \n\n*   这是一种通过逐步添加噪声到数据中，形成正向扩散过程，然后学习如何从噪声中恢复出原始数据的模型。\n    \n*   DDPM通过一个马尔可夫链来实现数据的生成过程，首先将数据逐步加噪，形成一个完全随机的噪声分布，然后通过学习反向过程，将噪声逐步去除，恢复出高质量的样本。\n    \n*   在图像生成任务中，DDPM显示出优越性能，例如在CIFAR-10数据集上的Inception分数达到9.46，FID分数为3.17。\n    \n\n1.  基于分数的生成模型 (SGM):\n    \n\n*   SGMs是一种新兴的生成模型，主要通过学习数据分布的得分函数来实现样本生成。\n    \n*   这种方法不直接建模数据的概率分布，而是通过对数概率密度函数的梯度进行建模。\n    \n*   SGMs利用随机微分方程(SDE)来描述扩散过程，并通过Langevin动力学进行采样。在图像生成任务中，SGMs能够生成与GAN相媲美的样本质量。\n    \n\n1.  随机微分方程 (SDE):\n    \n\n*   SDE作为描述随时间变化的随机过程的重要工具，广泛应用于物理学、金融学等多个领域。\n    \n*   在金融市场中，SDE尤其擅长处理那些对市场结果产生重大影响的随机因素。通过SDE，我们可以对这类金融衍生品(如原油期货合约)进行精确计算，不仅能建模价格波动，还能准确估算优惠价格，为市场参与者提供更为可靠的决策依据。\n    \n\n###   \n市场上的主要扩散模型产品  \n\n  \n```\nDALL-E：DALL-E是由OpenAI开发的一系列AI图像生成器，能够根据自然语言描述生成逼真的图像和艺术作品。DALL-E 2于2022年4月推出，能够更好地理解和处理复杂的文本描述。现在OpenAI已经把DALL-E集成到它的ChatGPT系列产品中。  \nStable Diffusion：由Stability AI创立的标准扩散模型，实质为两阶段训练过程，在多主题提示、无条件图像生成、文本到图像合成以及超分辨率任务中取得明显的优势。同时，通过克服像素空间操作的计算挑战，Stable Diffusion可以满足用户的可扩展性和质量需求。此外，DreamStudio作为由Stability AI开发的Stable Diffusion的简化版本，允许用户通过简单的文本输入生成高质量的图像。  \nSora：Sora是OpenAI在2024年2月发布的首个文本生成视频模型，继承了DALL-E 3的画质和遵循指令能力，能根据用户文本提示快速制作长达一分钟的高保真视频，还可从静态图像生成视频。Sora可以理解复杂场景中元素的物理属性及关系，生成具有多个角色、特定运动的复杂场景，具有高度可定制性和可扩展性。  \nMidjourney：Midjourney提供更多梦幻般的艺术风格视觉效果，如安迪・沃霍尔、达芬奇、达利和毕加索等，还能识别特定镜头或摄影术语，从而吸引那些从事科幻文学或需要更多艺术风格作品的人。Midjourney更像是一种绘画工具，它旨在提供更高的图像质量、更多样化的输出、更广泛的风格范围和更好的图像动态范围。  \nImagen：由Google开发的基于扩散的图像生成模型，利用大型Transformer语言模型的功能来理解文本，同时依靠扩散模型的强大功能来生成保真度极高的高质量图像，采用多尺度生成策略和噪声调节增强技术，可生成高分辨率、细节丰富、色彩准确的图像。Imagen使用相当大的无分类器指导权重来指导和控制图像生成，从而增强了照片真实感和图像文本对齐。  \n```\n\n  \n  \n\n------\n\n模型蒸馏  \n\n-------\n\n###   \n模型蒸馏的概念  \n\n模型蒸馏（Model Distillation）：是一种模型压缩和知识迁移的技术，旨在将一个大型、复杂且性能优异的教师模型（Teacher Model）中的知识传递给一个较小、计算效率更高的学生模型（Student Model），将复杂且大的模型作为Teacher，Student模型结构较为简单，用Teacher来辅助Student模型的训练，Teacher学习能力强，可以将它学到的知识迁移给学习能力相对弱的Student模型，以此来增强Student模型的泛化能力，复杂笨重但是效果好的Teacher模型不上线，就单纯是个导师角色，真正部署上线进行预测任务的是灵活轻巧的Student小模型。 其核心思想是利用教师模型输出的软标签（soft targets）—— 即概率分布而非硬标签（hard labels），来指导学生模型的训练。通过这种方式，学生模型不仅学习到数据的类别信息，还能够捕捉到类别之间的相似性和关系，从而提升其泛化能力。 蒸馏过程通常包括以下几个步骤：\n\n![Image 43: Image](https://mmbiz.qpic.cn/mmbiz_png/icUqtxmPRjDGTYd1pxeGia411WmROHIvuleIfAkuMNHvlGM5vA1xtibvAdycbxqGxibJUxTbDd6IvUJAmTmIBIEh7g/640?wx_fmt=png&from=appmsg)\n\n1.  训练教师模型：首先训练一个大型的、性能较好的模型作为教师模型。教师模型可以是任何高性能的深度学习模型，如深层神经网络、卷积神经网络（CNN）、Transformer等。\n    \n2.  生成软标签：训练好的教师模型对训练数据进行预测，获得每个样本的概率分布。这些概率分布作为软标签，包含了类别之间的相对关系信息。\n    \n3.  训练学生模型：使用这些软标签来训练学生模型，使其能够模仿教师模型的行为。\n    \n4.  优化损失函数：在训练过程中，通常会结合学生模型自身的损失和蒸馏损失，以确保学生模型不仅学习到输入数据的特征，还能捕捉到教师模型的“隐含知识”。\n    \n\n该方法的优势在于能够在不显著损失性能的情况下，显著减少模型大小和计算需求，特别适用于资源受限的设备，如移动设备和嵌入式系统。\n\n1、蒸馏的知识迁移优势\n\n*   模型 A 是通过蒸馏从一个更大、更强的模型（教师模型）中获得知识的。蒸馏的过程并不仅仅是复制大模型的输出，而是让小模型学习到大模型的决策过程、内部表示和隐含知识。这样，模型 A 在训练过程中能够 接收到更多的高质量指导，尤其是在复杂的推理、模式识别和特征提取方面。\n    \n*   通过蒸馏，模型 A 实际上学会了一个已经“成熟”的模型的很多优点，比如对上下文的理解能力、处理边缘情况的能力以及通过大量训练积累的 先验知识，这些是从零训练的模型（B）很难在同样的数据量和训练时间下学到的。\n    \n\n2、训练过程中的指导作用\n\n*   在模型 B 的训练过程中，它是从随机初始化开始的，没有任何先前的知识。它的每一个参数都是从头开始学习，可能需要更多的训练数据和更长的时间，才能逐步接近其理论上的最优状态。\n    \n*   与之对比，模型 A 通过蒸馏直接从教师模型（通常具有强大的能力）中学习。这意味着模型 A 的学习过程是高效的，它利用教师模型的“智慧”来进行学习，在较少的训练数据和计算资源下可能就能表现得很好。\n    \n\n3、大模型的泛化能力\n\n*   大模型（即教师模型）通常具有很强的泛化能力，因为它是在大量的数据上训练出来的。通过蒸馏，小模型（A）能够继承教师模型的一部分泛化能力，尤其是在不确定的、少见的模式识别上，这对于提高模型的性能是非常有帮助的。\n    \n*   模型B从零开始，缺乏这种来自大模型的“润色”或高质量的指导，因此在面对复杂的、边缘的或数据稀缺的任务时，B 模型的表现可能会较差，尤其是在数据量有限的情况下。 说明一下，在做模型蒸馏时，教师模型和学生模型的架构可以不同。蒸馏的核心在于将教师模型的知识（如输出分布或中间特征）传递给学生模型，而不是直接复制其架构。这种灵活性使得蒸馏可以应用于不同架构的模型之间\n    \n\n###   \n模型量化（Model Quantization）：  \n\n模型量化是一种通过减少模型参数和计算表示精度来压缩模型的技术。其主要目的是将浮点数参数转换为低精度整数（如8位或更低），从而减少存储需求和计算成本。量化过程通常分为以下几种：\n\n1.  后训练量化  ：在模型训练完成后进行量化，通过统计分析确定最佳的量化比特数，并对权重和激活值进行量化。\n    \n2.  量化感知训练  ：在训练过程中加入量化噪声，使模型在训练阶段就适应低精度表示，从而提高量化后的性能。\n    \n3.  混合精度训练  ：结合不同精度的数据类型进行训练，以平衡精度和计算效率。 量化的主要优点是能够在保持较高精度的同时显著减少模型的存储和计算需求，因此也非常适合用于边缘设备和实时应用。\n    \n\n模型量化分类：\n\n*   4.1 线性量化\n    \n\n*   4.1.1 对称量化\n    \n*   4.1.2 非对称量化\n    \n\n*   4.2 逐层量化、逐组量化和逐通道量化\n    \n*   4.3 在线量化和离线量化\n    \n*   4.4 比特量化\n    \n\n*   4.5 权重量化和权重激活量化\n    \n\n```\n资料链接：https://blog.csdn.net/WZZ18191171661/article/details/103332338/\n```\n\n**模型蒸馏:**主要通过知识迁移来实现小型化，适用于需要高效推理但对精度要求较高的场景。\n\n**模型量化****:**通过降低参数精度来减少存储和计算成本，适用于资源受限的设备和需要快速推理的应用场景。\n\n![Image 44: Image](https://mmbiz.qpic.cn/mmbiz_png/icUqtxmPRjDGTYd1pxeGia411WmROHIvulxjcRXK0JC71oRe352AeMRQwicOqardXtJZSibOzJLpzDFEekXYzAVacA/640?wx_fmt=png&from=appmsg)\n\n  \n\n  \nEmbedding模型  \n\n-----------------\n\nEmbedding: 这是一个通用术语，指的是将数据（可以是词、句子、图像等）转换成数值向量形式的过程。这些向量捕捉了数据的某些特征或属性，使得机器学习算法能够处理。可以应用于多种类型的数据，不仅限于文本，还可以是图像、声音等，而词嵌入特指文本中的单词或短语的嵌入。 Embedding 通常指将高维度的数据映射到低维度的空间中 。\n\n词嵌入（Word Embedding）: 词嵌入是特定于文本数据的嵌入形式，它将单词或短语转换成向量。这些向量能够表示单词的语义和语法特征，使得语义上相似的单词在向量空间中彼此接近。是嵌入技术在文本处理领域的应用。词嵌入生成的向量成为向量模型的输入，向量模型利用这些向量来进行各种下游任务。\n\n向量模型（Vector Model）: 向量模型通常指的是使用向量表示来处理数据的模型。在NLP中，这通常意味着使用词嵌入作为输入特征的模型。向量模型可以是用于分类、聚类、相似性度量等任务的任何机器学习或深度学习模型。是一个更广泛的概念，它不仅包括使用词嵌入的模型，还可以包括使用其他类型嵌入的模型。\n\n一句话总结，词嵌入是嵌入技术在语言处理领域的具体实例，而向量模型则是利用这些嵌入向量进行任务处理的模型。在NLP中，词嵌入向量作为特征输入，使得向量模型能够理解和处理人类语言。\n\n###   \nEmbeddings 分类及对应模型  \n\nEmbeddings 有许多种类别和变体，每种类型的 Embeddings 都有其特定的设计目标和应用场景，共同点在于它们都致力于将复杂而抽象的对象结构化并压缩到便于计算和比较的数值形式，以下是几种常见的 Embeddings 类型：\n\n####   \n词嵌入  \n\nWord2Vec: 包括 CBOW (Continuous Bag-of-Words) 和 Skip-Gram 模型，由 Google 提出，用于学习单词之间的语义关系。 GloVe (Global Vectors for Word Representation): 由斯坦福大学开发，旨在结合全局统计信息和局部上下文窗口的优势来生成单词嵌入。 FastText: 由 Facebook AI 团队推出，不仅考虑单个单词，还考虑内部字符 n-gram，对于罕见词汇有更好的表现。 ELMo (Embeddings from Language Models): 利用双向 LSTM 对整个句子进行建模，产生上下文敏感的单词嵌入。\n\n####   \n情景化话的词嵌入  \n\nBERT (Bidirectional Encoder Representations from Transformers): 由 Google 推出，利用Transformer架构的预训练模型，能够根据上下文提供动态的单词嵌入。 GPT (Generative Pre-training Transformer) 及其后续版本 GPT-2/3/4：由 OpenAI 开发，也是基于Transformer的自回归模型，同样能产出上下文相关的嵌入。 XLNet、RoBERTa 等都是BERT之后改进或扩展的预训练模型。\n\n####   \n句子和文档嵌入  \n\nDoc2Vec: 扩展了 Word2Vec，能够为整个文档生成统一的向量表示。 Average Word Embeddings: 将一段文本中所有单词的嵌入取平均作为整体的文本表示。 Transformers Sentence Embeddings: 如BERT的\\[CLS\\]标记对应的向量，或者专门针对句子级别的模型如Sentence-BERT。\n\n####   \n实体/概念嵌入  \n\nKnowledge Graph Embeddings: 如 TransE、DistMult、ComplEx 等，用于将知识图谱中的实体和关系嵌入到低维向量空间中。\n\n####   \n其他类型  \n\n图像 Embeddings: 使用卷积神经网络（CNN ）进行图像特征提取，得到的特征向量即为图像嵌入。 音频 Embeddings: 在语音识别和声纹识别中，将声音信号转化为有意义的向量表示。 用户/物品 Embeddings：在推荐系统中，将用户行为或物品属性映射到低维空间以进行协同过滤或基于内容的推荐。 还有一种图 Embeddings：是用于学习图结构的表示学习方法，将图中的节点和边映射到低维向量空间 中。通过学习图嵌入，可以将复杂的图结构转化为向量表示，以捕捉节点之间的结构和关联关系。这些方法可 以通过DeepWalk、Node2Vec、GraphSAGE等算法来实现。图嵌入在图分析、社交网络分析、推荐系统等领 域中广泛应用，用于发现社区结构、节点相似性、信息传播等图属性。 以下是5个主流的Embedding模型，推荐给大家用于搭建RAG系统做参考：\n\n  \n```\nBGE Embedding：由智源研究院开发，支持多语言，提供多个版本，包括高效的reranker。该模型开源且许可宽松，适用于检索、分类、聚类等任务。  \nGTE Embedding：由阿里巴巴达摩院推出，基于BERT框架，适用于信息检索和语义相似性判断等场景，性能卓越。  \nJina Embedding：由Jina AI的Finetuner团队打造，基于Linnaeus-Clean数据集训练，适用于信息检索和语义相似性判断，性能出众。  \nConan-Embedding：这是一个针对中文优化的Embedding模型，在C-MTEB上达到了SOTA（State-of-the-Art）水平，特别适合需要高精度中文语义表示的RAG系统。  \ntext-embedding-ada-002：由Xenova团队开发，与Hugging Face库兼容，提供高质量的文本向量表示，适用于多种NLP任务。  \n```\n\n###   \nEmbeddings 常规文本嵌入模型对比与选型  \n\n下是针对 mxbai-embed-large、bge-m3、bge-large、nomic-embed-text、m3e-base、GTE-Qwen2-7B-instruct、text-embedding-ada-002 等文本嵌入模型的详细对比与选择指南，结合性能、场景和资源需求：\n\n模型对比表\n\n![Image 45: Image](https://mmbiz.qpic.cn/mmbiz_png/icUqtxmPRjDGTYd1pxeGia411WmROHIvulhBNPQcnBANFbhhWD8Fvq0d276r3OFibhMggmMzPzRibC16MO64w3kRzA/640?wx_fmt=png&from=appmsg)\n\n![Image 46: Image](https://mmbiz.qpic.cn/mmbiz_png/icUqtxmPRjDGTYd1pxeGia411WmROHIvulXyeicqag7EYSwsA54egp1K6rTUUyTnyVHTW85z0jMWcibVwKCBFYuK0g/640?wx_fmt=png&from=appmsg)\n\n####   \n关键指标对比  \n\n![Image 47: Image](https://mmbiz.qpic.cn/mmbiz_png/icUqtxmPRjDGTYd1pxeGia411WmROHIvulOTWp2XXLpeq9YaZfEUPQZmicrcJvKGyKQnH0HgeIHzGom53aohG1NLA/640?wx_fmt=png&from=appmsg)\n\n####   \n场景化选择指南  \n\n#####   \n1\\. 中文场景优先  \n\n*   短文本匹配（如搜索推荐、问答）：\n    \n\n*   首选：m3e-base（轻量高效，中文优化）\n    \n*   备选：bge-large（更高精度）\n    \n\n*   长文本理解（如文档摘要、知识库）：\n    \n\n*   开源：mxbai-embed-large（长上下文支持）\n    \n*   轻量替代：bge-large（需分块处理）\n    \n\n#####   \n2\\. 多语言混合场景  \n\n*   混合检索系统：\n    \n\n*   必选：bge-m3（密集+稀疏混合架构）\n    \n\n*   纯密集向量检索：\n    \n\n*   高性能：mxbai-embed-large\n    \n*   经济型：text-embedding-ada-002（预算充足时）\n    \n\n#####   \n3\\. 资源敏感场景  \n\n*   低算力CPU部署：\n    \n\n*   首选：m3e-base（500MB，实时响应）\n    \n*   中文任务：bge-large\n    \n\n*   GPU服务器部署：\n    \n\n*   长文本：mxbai-embed-large\n    \n*   多任务通用：GTE-Qwen2-7B（需充足算力）\n    \n\n#####   \n4\\. 研究/可解释性需求  \n\n*   必选：nomic-embed-text（可视化工具链完善）\n    \n*   替代：自行微调 bge-large（需领域数据）\n    \n\n#####   \n5\\. 商业快速集成  \n\n*   无开发资源：text-embedding-ada-002（OpenAI API）\n    \n*   阿里生态整合：GTE-Qwen2-7B（适配阿里云服务）\n    \n\n####   \n部署建议\n\n开源模型优化：\n\n*   量化压缩：使用 bitsandbytes 对 bge-large/m3e-base 进行8-bit量化。\n    \n*   检索加速：搭配 FAISS 或 Milvus 构建索引。\n    \n*   长文本分块：对 bge-large 使用滑动窗口（如256 tokens重叠）。\n    \n\n商业API避坑：\n\n*   成本控制：优先选择 text-embedding-3-small（性能相近，价格更低）。\n    \n*   缓存策略：对重复查询结果做本地缓存。\n    \n\n混合架构示例：\n\n  \n```\n# 混合使用 bge-m3 和 mxbai-embed-large  \nfrom sentence_transformers import SentenceTransformer  \n  \n# 第一阶段：快速稀疏检索（bge-m3稀疏模式）  \nsparse_model = SentenceTransformer(\"BAAI/bge-m3\")  \nsparse_vectors = sparse_model.encode(texts, return_sparse=True)  \n  \n# 第二阶段：精准密集检索（mxbai-embed-large）  \ndense_model = SentenceTransformer(\"mixedbread-ai/mxbai-embed-large-v1\")  \ndense_vectors = dense_model.encode(top_k_candidates)\n```\n\n",
    "created_at": "2025-03-10T03:36:34Z",
    "updated_at": "2025-03-14T09:00:22Z",
    "labels": [],
    "url": "https://github.com/kaozb/ai-arctl/issues/2"
  },
  {
    "id": 9,
    "title": "一文搞懂大模型预训练PT与有监督微调SFT",
    "content": "一文搞懂大模型预训练PT与有监督微调SFT\n===============\n                                                                         \n\n             \n\n  \n\n![Image 1: cover_image](https://mmbiz.qpic.cn/sz_mmbiz_jpg/Zvl9ickIYtdJh6ZicJjnaJxObBOyAJf6pHgtrx9ZRHauRWGEcvMMeEylHaLWpNLO5uASaKuaHApkdaoLDHDdbFzA/0?wx_fmt=jpeg)\n\n一文搞懂大模型预训练PT与有监督微调SFT\n=====================\n\n[小喵学AI](javascript:void(0);)\n\n![Image 2: profile_qrcode](https://mp.weixin.qq.com/mp/qrcode?scene=10000005&size=102&__biz=Mzg2MzkwNDM0OQ==&mid=2247488180&idx=1&sn=28399ffd485eba228a87f542003265dc&send_time=)\n\n小喵学AI\n\n专注于分享C++/Python编程、计算机视觉、自然语言处理、大模型等深度学习与人工智能领域干货、应用。\n\n154篇原创内容\n\n_2024年07月19日 08:04_\n\n在理解LLM预训练和微调的原理之前，我们先解释三个基础概念。\n\n**「Token」**：在自然语言处理中，一个“token”是语言的基本单位，它可以是一个词、一个字或一个标点符号。例如，句子“我喜欢冬天”被切分为3个tokens：\"我\"、\"喜欢\"、\"冬天\"。\n\n**「Prediction」**：预测是指模型基于当前输入序列预测下一个可能出现的token。这是语言模型的核心任务之一。\n\n**「Train」**：训练则是指模型逐渐学会识别和预测文本中的模式的过程。例如在“我喜欢X”的模式中，模型会观察到“我喜欢”后面可能跟着许多不同的词，但有些词（如“你”、“北京”、“世界”）出现的频率更高。通过这种方式，模型不仅学会预测下一个词，还学会更深层次的语言结构和语义关系，这使得它在处理诸如文本生成、情感分析、机器翻译等NLP任务时更加有效。\n\n要理解这一训练过程，最主要就是明白**「预训练的数据如何构造、数据怎么喂给模型、模型输出是是什么以及如何计算loss。」**\n\n什么是token？\n---------\n\ntoken是指文本中的一个词或者子词，给定一句文本，送入语言模型之前，首先对原始文本进行tokenize，也就是将一个文本序列拆分为离散的token序列。\n\n![Image 3: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/Zvl9ickIYtdJh6ZicJjnaJxObBOyAJf6pHDCAv5nQflW9RNlEHQw9vrm0m4zQAkic5PjfPtuRAIZCDKDle8L4jOxQ/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)\n\ntokenize是在大量未标注的文本数据上进行训练，创建一个固定的词表，这个词表包含了模型能够理解和操作的所有tokens。\n\ntokenizer将文本转换为tokens序列之后，下来就是词嵌入，将每个token转换为其对应的向量表示，捕捉token的语义和上下文信息，使得模型能够在数学空间中进行计算和推理。\n\n![Image 4: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/Zvl9ickIYtdJh6ZicJjnaJxObBOyAJf6pHpjlfDy6HVryqzgdbKBa4Sm5oa8WFZRXxDVIeOJwlRVQZDvrheYgdzw/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)\n\n我们知道文本序列是有顺序的，而常见的语言模型都是基于self-attention机制的Transformer结构，而自注意力机制本身并未考虑序列中元素相对位置信息，因为需要手动加上位置编码，也就是每个token位置有个位置嵌入，与对应位置的token embedding相加。\n\n![Image 5: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/Zvl9ickIYtdJh6ZicJjnaJxObBOyAJf6pHjicafxTZO6t3N7veeMEVVDKZEhHLbN0mz2MIldV5Z6ib3T4pbmsSPHHQ/640?wx_fmt=png&from=appmsg)\n\n模型训练或推理阶段经常会出现Context Length这个术语，这是指模型在一次前向传播中能够有效处理的token序列的最大长度，在训练阶段，如果模型只学习了较短的序列的位置embedding，那模型在推理阶段就不能适用于较长文本。\n\n![Image 6: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/Zvl9ickIYtdJh6ZicJjnaJxObBOyAJf6pHIQNFoOI7WrHLx6Q3rpZNQnJb68QGeeO19kOu6IZjJmXbubpuwNkrVg/640?wx_fmt=png&from=appmsg)\n\n预训练Pre-train\n------------\n\n输入序列经过token embedding和位置embedding处理后，会形成一个融合了词义信息和位置信息的嵌入向量序列，进而送入Decoder-only架构的Transformer模型中。\n\n![Image 7: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/Zvl9ickIYtdJh6ZicJjnaJxObBOyAJf6pHFkHeKyht7bIWEt35X5HYZ3xBf6LS6Iib5xzTS2njxYFMyMHibHgbYDAg/640?wx_fmt=png&from=appmsg)\n\nTransformer模型会为每个输入token生成一个输出embedding，这个输出embedding包含了丰富的上下文信息，可用于预测序列中的下一个token。这个过程也可以当作一个分类问题看待，具体如下：\n\n1.  线性层映射：输出embedding通过一个线性层，其输出维度等于词表大小。这个线性层实际上是一个矩阵乘法，将每个token的embedding映射到一个与词表大小相同的向量上。这个向量中的每个元素可以看做是下一个token输入词表中相应类别的原始分数。\n    \n2.  Softmax变换：为了将这些原始分数转化为概率分布，需要应用Softmax函数。Softmax函数将每个元素转换为概率值，并确保所有概率值之和为1。\n    \n3.  训练：在训练阶段，最大化概率使得它能够预测真实的下一个token。\n    \n4.  推理：在推理阶段，模型根据最后一个生成token的输出概率分布采样下一个token。\n    \n\n![Image 8: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/Zvl9ickIYtdJh6ZicJjnaJxObBOyAJf6pHYVTaibEfvk3utKQ7FrqwcaI4mJxG3lvrOE8dHRBEKCC1ZMZVMIiacAGQ/640?wx_fmt=png&from=appmsg)\n\n在训练阶段，decoder-only架构的Transformer模型利用因果自注意力（Causal Self-Attention）机制，能够一次性对整个输入序列的每个位置的token预测其下一个token，并计算所有位置token的损失。\n\n下面通过一个完整的例子介绍这个过程。假设有一个预训练数据集，\n\n> ❝你知道什么是预训练吗？\n> \n> ❞\n\n假设经过tokenize后文本分成token：\n\n```\n你：2知道: 5什么：6是:1预训练:8吗:7？:6\n```\n\n原来的数据变为如下序列，后面补了三个0（假设我们希望最大序列长度是10）。\n\n> ❝2 5 6 1 8 7 6 0 0 0\n> \n> ❞\n\n预测下一个token就类似于2预测5，2、5预测6，...，以此类推，但是这样拆成很多歌数据段比较低效，**「因此可以考虑使用移位构造数据。」**\n\n即：\n\n*   输入X：2 5 6 1 8 7 6 0 0 0\n    \n*   输出targets：5 6 1 8 7 6 0 0 0\n    \n\n这样就可以一次性把整条序列喂给模型，计算一次就包含了6个预测下一个token的损失了。这里模型的设计理念是：不能让输入看到后面的词（如果看得到的话就没必要进行预测了），也就是“你”在模型内看不到“知道”，“你 知道”在模型内看不到“什么”，这个可以通过注意力机制实现。\n\n通过移位构造的输入序列维度是(1,10)，其中1代表批量大小（这里为单样本训练），10代表序列长度。经过Embedding层后，数据形状变为(1,10,768)，这里假设词嵌入维度是768。\n\n再利用Transformer处理，Transformer接收嵌入向量作为输入，且是一个黑盒，其输出的形状保持不变，即仍为(1,10,768)。\n\n为了将Transformer的输出转化为词表大小的分类概率分布，引入一个线性层（全连接层）：\n\n```\noutput_layer = nn.Linear(768, vocab_size, bias=False)\n```\n\n其中vocab\\_size是词汇表的大小。应用这个线性变换后，得到的logits形状为(1, 10, vocab\\_size)，这意味着对于序列中的每个位置，模型都给出了一个关于词表中每个词的概率分布。\n\n最后，通过交叉熵损失函数F.cross\\_entropy计算模型预测的logits与真实的targets之间的交叉熵损失loss，并通过ignore\\_index=0参数指定忽略填充位置（值为0）的损失，避免它们影响模型的学习。\n\n```\nloss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=0)\n```\n\n有监督微调Supervised fine-tuning\n---------------------------\n\n有监督微调SFT即是指在预训练好的LLM基础上，利用带有明确标签的（supervised）数据集来进一步训练模型，使之能够执行特定的下游任务。\n\n**「通常LLM的PT过程是无监督的，Fine-tuning过程是有监督的。」**\n\nSFT时，模型权重会根据与真实标签的差异进行调整。通过这个微调过程，模型能够捕捉到标签数据中特定于某一任务的模式和特点，使得模型更加精确，更好地适应某一特定任务。\n\n举个简单的例子，有个已经训练好的LLM，当输入“I can't log into my account.What should I do?”时，它可能简单地回答：“Try to reset your password using the 'Forgot password' option.”\n\n![Image 9: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/Zvl9ickIYtdJh6ZicJjnaJxObBOyAJf6pHlibOfMbWrhU9tyURTlMG5CyLwyEUrkExZ5IvC6hJ55sOmDrV98dNLgg/640?wx_fmt=png&from=appmsg)\n\n这个回答很直接，适用于一般问题，但如果是客服场景，可能就不太合适了。一个好的客服回答应该更有同情心，并且可能不会这么直接，甚至可能包含联系信息或其他细节。这时候，有监督微调就显得非常重要了。\n\n经过有监督微调后，模型可以提供更加符合特定指导原则的答案。当输入“I can't log into my account.What should I do?”时，可能会回答“I'm sorry to hear you're having trouble logging in. You can try resetting your password using the 'Forgot password' option on the login page.”\n\n![Image 10: Image](https://mmbiz.qpic.cn/sz_mmbiz_png/Zvl9ickIYtdJh6ZicJjnaJxObBOyAJf6pHKee16mG72WUcias4ibPEX5Ll8Zm3xwQlXRe2v0lDOgVmSzG4spBJWMog/640?wx_fmt=png&from=appmsg)\n\n理解了SFT的基本概念后，我们再从数据构造到模型输出、计算loss步骤看一下SFT实现原理。\n\nSFT每条样本由两部分组成——提示(prompt)和答案（answer）。例如，\n\n```\nprompt: 翻译以下句子: What is Supervised fine-tuninganswer: 什么是有监督微调\n```\n\n它的本质其实也是预测下一个token，只是我们更希望模型关注answer部分的预测，这可以通过生成一个mask向量屏蔽不希望计算loss的部分，下面就是数据构造的一个示意：\n\n*   将prompt和answer拼接起来，并在answer前后分别添加开始（\\[bos\\]）和结束（\\[eos\\]）标记。\n    \n*   计算prompt/instruction的长度，以及后面需要填充的长度。\n    \n*   生成一个向量mask，其中answer部分为1，其它部分为0，以此来指示模型仅关注答案部分的预测损失。\n    \n\n```\ninput_id=prompt+[bos]+answer+[eos]context_length = input_id.index(bos)mask_position = context_length - 1pad_len = max_length - len(input_id)input_id = input_id + [pad] * pad_lenloss_mask = [0]*context_length+[1]*(len(input_id[mask_position+1:])) + [0]*pad_len\n```\n\n将构造好的input\\_id转为词嵌入embedding，经过Transformer模型处理，输出维度依然是(1,10,vocab\\_size)，\n\n```\nlogits=output_layer(transformer(X))\n```\n\n进一步就可以计算answer部分的loss了，其实就是通过mask把不希望考虑的地方乘以0，保留answer部分loss。\n\n```\nloss_mask = loss_mask.view(-1)loss = torch.sum(loss*loss_mask)/loss_mask.s\n```\n\n有了loss，进行反向传播更新模型参数就OK。\n\n预览时标签不可点\n\n",
    "created_at": "2025-03-10T07:32:24Z",
    "updated_at": "2025-03-14T07:55:23Z",
    "labels": [],
    "url": "https://github.com/kaozb/ai-arctl/issues/9"
  },
  {
    "id": 1,
    "title": "传统 RAG vs. Agentic RAG：动态图示清晰解析",
    "content": "传统 RAG vs. Agentic RAG：动态图示清晰解析\n===============\n                                                                         \n\n             \n\n  \n\n![Image 1: cover_image](https://mmbiz.qpic.cn/sz_mmbiz_jpg/SaeK9tW7Buib02aUGlGKOTroKic46Sa1ordjI7MicBwPhwjYojsaJnpOlCVByZBefyuRQYN27efsNe5AOQZJFCia6A/0?wx_fmt=jpeg)\n\n传统 RAG vs. Agentic RAG：动态图示清晰解析\n\n传统 RAG 存在许多问题：\n\n*   它只检索一次并生成一次。如果上下文信息不足，无法动态搜索更多信息。\n    \n*   无法处理复杂查询的推理问题。\n    \n*   系统无法根据问题调整其策略。\n    \n\n![Image 3: Image](https://mmbiz.qpic.cn/sz_mmbiz_gif/SaeK9tW7Buib02aUGlGKOTroKic46Sa1or53A4fBvpPTiaZv0gcx6LPySZFLbeAtXUFywz1L6MsqIEGY7XZ3Kgic3Q/640?wx_fmt=gif&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)\n\nAgentic RAG 尝试解决这些问题。\n\n以下图示展示了它与传统 RAG 的不同之处。\n\n核心思想是在 RAG 的每个阶段引入智能化（Agentic）行为。\n\n![Image 4: Image](https://mmbiz.qpic.cn/sz_mmbiz_gif/SaeK9tW7Buib02aUGlGKOTroKic46Sa1orFMvJecMYkpWGGibeswdw4mQYBJWTIsF7z4Ioiaj6NllvgG7rqQueD7SA/640?wx_fmt=gif&from=appmsg)\n\n第 1-2 步）Agent 会重写查询（如纠正拼写错误等）。\n\n第 3-8 步）Agent 决定是否需要更多上下文信息：\n\n*   如果不需要，重写后的查询直接发送给 LLM。\n    \n*   如果需要，智能代理会找到最佳的外部来源以获取上下文，并将其传递给 LLM。\n    \n\n第 9 步）系统生成响应。\n\n第 10-12 步）智能代理检查答案是否相关：\n\n*   如果相关，则返回响应。\n    \n*   如果不相关，则返回第 1 步重新开始。\n    \n\n![Image 5: Image](https://mmbiz.qpic.cn/sz_mmbiz_gif/SaeK9tW7Buib02aUGlGKOTroKic46Sa1orU9vI7Z9acufOYffHm8mqRGxPcT6oPZlDM0etLeqn9c3PkcHsMzGscw/640?wx_fmt=gif&from=appmsg)\n\n这一过程会重复几次，直到得到合适的回答，或者系统承认无法回答该查询为止。\n\n这使得 RAG 更加健壮，因为 Agent 可以确保每个环节的结果都与目标一致。\n\n需要说明的是，上图只是 Agentic RAG 系统众多架构之一。\n\n你可以根据具体的使用场景对其进行调整和适配。\n\n![Image 6: Image](https://mmbiz.qpic.cn/mmbiz_gif/YSugV5KTRwUe3icAJT8QUSoK7ybHA7ds62KDx6ibQibff6Yv0EYlA8VIDH5vyjH6IdiaEqeNRMAIMRpUJrdbgGI4EA/640?wx_fmt=gif&tp=webp&wxfrom=5&wx_lazy=1)\n\n\n",
    "created_at": "2025-03-10T03:23:13Z",
    "updated_at": "2025-03-14T06:05:30Z",
    "labels": [],
    "url": "https://github.com/kaozb/ai-arctl/issues/1"
  },
  {
    "id": 3,
    "title": "大白话带你了解：智能体、LLM、RAG和提示词工程，轻松构建下一代应用",
    "content": "大白话带你了解：智能体、LLM、RAG和提示词工程，轻松构建下一代应用\n===============\n                                                                         \n\n             \n\n  \n\n![Image 1: cover_image](https://mmbiz.qpic.cn/mmbiz_jpg/Bibg0wltSUNTcpNzL8A7SPLrwECzVJ8O3mvFic7HEpa8cW0SwXSfYFCRwEicFXicUFoN1eIomjo2z82aczYHyicekqg/0?wx_fmt=jpeg)\n\n大白话带你了解：智能体、LLM、RAG和提示词工程，轻松构建下一代应用\n===================================\n\nOriginal 何三 [何三笔记](javascript:void(0);)\n\n![Image 2: profile_qrcode](https://mp.weixin.qq.com/mp/qrcode?scene=10000005&size=102&__biz=MzA4NTI3OTcyMA==&mid=2649629233&idx=1&sn=20ccaeb71d85f3865c7602fa72cc681a&send_time=)\n\n何三笔记\n\n互联网自媒体\n\n专注互联网技术与创业，提供最具价值的网络创业干货。\n\n191篇原创内容\n\n_2025年02月19日 01:01_\n\n今天主要来聊一聊Ai大模型中的几个概念\n\n这两年AI应用开发火得不行，但很多小伙伴被一堆专业名词绕晕了。今天咱们就来掰开揉碎说说几个最关键的术语，保证看完你就能和工程师聊上两句了。\n\n**一、AI里的\"打工人\"——智能体**\n\n想象有个24小时待命的虚拟员工，这就是智能体（Agent）。它和传统AI最大的区别就像人类和机器的区别：传统AI只能按固定剧本走，而智能体更像真人，能自己观察环境、思考对策、调用工具完成任务。\n\n![Image 3: 图片](https://mmbiz.qpic.cn/sz_mmbiz_png/XPuxCqAicMPPrp8FEjUFkmSzg0qABkdU8iboGXpEicrnW1AX6zgx3BhxoQzNiaWWUEkGd5UXxsibT6lxHQY1K1WfLYQ/640?wx_fmt=png&from=appmsg&wxfrom=5&wx_lazy=1&wx_co=1&tp=webp)\n\n现在很多企业都在搞的智能体平台，本质上就是给这些\"虚拟员工\"配办公室。平台要解决的核心问题就是：怎么让这些智能体记性好（长期记忆+短期记忆）、会做计划（任务分解）、能调用各种工具（比如查数据库、调API），这样才能适应各种复杂场景。\n\n**二、AI的大脑——大语言模型（LLM）**\n\nLLM就是大家常说的\"大模型\"，比如ChatGPT。它的核心能力就两点：理解人话和说人话。训练过程分两个阶段：\n\n1.  预训练：相当于让AI上完九年义务教育，通过海量文本学习基础语言规律\n    \n2.  微调：类似专业培训，针对具体任务（比如客服、翻译）进行专项训练\n    \n\n现在很多AI应用开发，其实就是通过API调取这些大模型的\"脑力\"。不过要注意，这些模型动辄几十亿参数（比如通义千问有70亿参数），就像个超级学霸，但需要大量算力资源供着。\n\n**三、给AI配个资料库——RAG技术**\n\n大模型有个致命弱点：遇到训练数据里没有的知识就容易胡说八道（业内叫\"幻觉\"）。这就好比让学霸参加没复习过的考试，只能瞎蒙。\n\n![Image 4: 图片](https://mmbiz.qpic.cn/sz_mmbiz_png/XPuxCqAicMPPrp8FEjUFkmSzg0qABkdU8icHDBEiaRybSRtJBmGpHmmr1r728VwTQ64yzI1Pfzibshaob09ssib7rrA/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)\n\nRAG技术相当于给AI配了个随身资料库。具体操作分两步：\n\n1.  建索引：把企业私有的知识文档（比如产品手册）整理成可检索的数据库\n    \n\n![Image 5: 图片](https://mmbiz.qpic.cn/sz_mmbiz_png/XPuxCqAicMPPrp8FEjUFkmSzg0qABkdU80yUzB7RIo953kQRNLxvzn6GCAjPFASvmFcvj9JER1UrR4T5W8tmdGw/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)\n\n1.  查资料：每次回答问题前先查资料库，把相关资料喂给大模型当参考\n    \n\n![Image 6: 图片](https://mmbiz.qpic.cn/sz_mmbiz_png/XPuxCqAicMPPrp8FEjUFkmSzg0qABkdU8sibdt6xOTacnlFicxdFulCuSe73ZYvFiayxlr7IicDkXhha5WSoHaBYjMA/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)\n\n这招不仅减少AI瞎编的概率，还能像写论文一样给出引用来源。对企业来说，最大的好处是可以随时更新知识库，不用每次都重新训练大模型。\n\n**四、和AI沟通的艺术——提示词工程**\n\n想要让大模型好好干活，关键要会说\"提示词\"。这就像和学霸同事沟通：\n\n*   别问\"这个怎么做？\"（太笼统）\n    \n*   要问\"用Python写个爬虫，抓取某网站商品价格，存成CSV格式，给出代码示例\"\n    \n\n好的提示词应该包含：\n\n1.  明确指令（做什么）\n    \n2.  具体对象（对什么做）\n    \n3.  示例参考（最好有样版）\n    \n4.  格式要求（要写成什么样）\n    \n5.  异常处理（遇到问题怎么办）\n    \n\n举个真实案例：某旅游App用提示词优化后，生成的行程规划从\"建议参观景点\"变成\"推荐3个故宫周边人均100元以下的京菜馆，附地址和推荐菜\"——这才是用户真正需要的。\n\n![Image 7: 图片](https://mmbiz.qpic.cn/sz_mmbiz_png/XPuxCqAicMPPrp8FEjUFkmSzg0qABkdU8JXnTMaDtNZtRaBthQNTibOjwnA9jhx8pIMicVTSSXSCva7XSZFzdpjUQ/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)\n",
    "created_at": "2025-03-10T03:39:34Z",
    "updated_at": "2025-03-14T05:53:08Z",
    "labels": [],
    "url": "https://github.com/kaozb/ai-arctl/issues/3"
  },
  {
    "id": 5,
    "title": "程序员的 AI 开发第一课",
    "content": "\n\n*   从大模型、提示词到 API、LangChain 框架一站通关\n*   从 0 到 1，实现聊天机器人、RAG、Agent 等多种 AI 应用\n*   常见的 AI 应用开发的知识体系\n*   高手带路，掌握 AI 编程新模式\n\n课程介绍\n----\n\n**「极客时间 AIGC 未来教育系列课程」**\n\n无论你是否准备好，AI 时代已经到来，AI 技术也在融入千行百业，各种 AI 应用也如雨后春笋般不断涌现。\n\n然而，作为身为一个普通的程序员，你一定会心生疑问，我不是专业的 AI 程序员，工作上也只是普通的业务开发，根本看不到使用大模型的机会，也没有很强的学术功底，看不懂那些深奥的 AI 算法论文，该如何跟上时代步伐呢？\n\n如果你也有同样的困惑，那么《程序员的 AI 开发第一课》正是为你量身准备的。这门课里，我们邀请了拥有二十多年开发经验的郑晔老师，带你从普通开发的视角快速熟悉大模型，开启 AI 应用开发之旅。\n\n课程共分为三个部分。学完整门课程，后面的 AI 应用开发图景你就会了然于心，未来遇到 AI 相关的需求时也将迅速上手。\n\n![Image 8](https://static001.geekbang.org/resource/image/7b/fe/7b3b7640b96357c8530132096811e1fe.jpg?wh=2383x1820)\n\n**大模型基础篇**：从用户视角和技术视角梳理大模型基础知识，带你掌握和大模型沟通的方式，熟悉常用的提示技术，释放出大模型的更多潜能。\n\n**应用开发篇**：我们首先会学习 OpenAI API 和 LangChain，了解如何使用大模型的 API 进行编程以及常见的应用开发类型。在此基础上我们会进入应用开发的实战练习环节，从 0 到 1，实现聊天机器人、RAG、Agent 等多种 AI 应用。\n\n**模型篇**：学习当前比较有代表性的开源模型及模型微调方法，了解如何把更多模型能力整合到 AI 应用中。\n\n课程目录\n----\n",
    "created_at": "2025-03-10T07:04:39Z",
    "updated_at": "2025-03-14T05:51:31Z",
    "labels": [],
    "url": "https://github.com/kaozb/ai-arctl/issues/5"
  },
  {
    "id": 11,
    "title": "全世界最好的大语言模型资源汇总",
    "content": "\n\n#### Contents\n\n- [数据 Data](#数据-Data)\n- [微调 Fine-Tuning](#微调-Fine-Tuning)\n- [推理 Inference](#推理-Inference)\n- [评估 Evaluation](#评估-Evaluation)\n- [体验 Usage](#体验-Usage)\n- [知识库 RAG](#知识库-RAG)\n- [智能体 Agents](#智能体-Agents)\n- [搜索 Search](#搜索-Search)\n- [书籍 Book](#书籍-Book)\n- [课程 Course](#课程-Course)\n- [教程 Tutorial](#教程-Tutorial)\n- [论文 Paper](#论文-Paper)\n- [社区 Community](#社区-Community)\n- [Open o1](#Open-o1)\n- [Small Language Model](#Small-Language-Model)\n- [Small Vision Language Model](#Small-Vision-Language-Model)\n- [Tips](#tips)\n\n![](https://camo.githubusercontent.com/2722992d519a722218f896d5f5231d49f337aaff4514e78bd59ac935334e916a/68747470733a2f2f692e696d6775722e636f6d2f77617856496d762e706e67)\n\n## 数据 Data\n\n> [!NOTE]\n> \n> 此处命名为`数据`，但这里并没有提供具体数据集，而是提供了处理获取大规模数据的方法\n\n\n1. [AotoLabel](https://github.com/refuel-ai/autolabel): Label, clean and enrich text datasets with LLMs.\n2. [LabelLLM](https://github.com/opendatalab/LabelLLM): The Open-Source Data Annotation Platform.\n3. [data-juicer](https://github.com/modelscope/data-juicer): A one-stop data processing system to make data higher-quality, juicier, and more digestible for LLMs!\n4. [OmniParser](https://github.com/jf-tech/omniparser): a native Golang ETL streaming parser and transform library for CSV, JSON, XML, EDI, text, etc.\n5. [MinerU](https://github.com/opendatalab/MinerU): MinerU is a one-stop, open-source, high-quality data extraction tool, supports PDF/webpage/e-book extraction.\n6. [PDF-Extract-Kit](https://github.com/opendatalab/PDF-Extract-Kit): A Comprehensive Toolkit for High-Quality PDF Content Extraction.\n7. [Parsera](https://github.com/raznem/parsera): Lightweight library for scraping web-sites with LLMs.\n8. [Sparrow](https://github.com/katanaml/sparrow): Sparrow is an innovative open-source solution for efficient data extraction and processing from various documents and images.\n9. [Docling](https://github.com/DS4SD/docling): Get your documents ready for gen AI.\n10. [GOT-OCR2.0](https://github.com/Ucas-HaoranWei/GOT-OCR2.0): OCR Model.\n11. [LLM Decontaminator](https://github.com/lm-sys/llm-decontaminator): Rethinking Benchmark and Contamination for Language Models with Rephrased Samples.\n12. [DataTrove](https://github.com/huggingface/datatrove): DataTrove is a library to process, filter and deduplicate text data at a very large scale.\n13. [llm-swarm](https://github.com/huggingface/llm-swarm/tree/main/examples/textbooks): Generate large synthetic datasets like [Cosmopedia](https://huggingface.co/datasets/HuggingFaceTB/cosmopedia).\n14. [Distilabel](https://github.com/argilla-io/distilabel): Distilabel is a framework for synthetic data and AI feedback for engineers who need fast, reliable and scalable pipelines based on verified research papers.\n15. [Common-Crawl-Pipeline-Creator](https://huggingface.co/spaces/lhoestq/Common-Crawl-Pipeline-Creator): The Common Crawl Pipeline Creator.\n16. [Tabled](https://github.com/VikParuchuri/tabled): Detect and extract tables to markdown and csv.\n17. [Zerox](https://github.com/getomni-ai/zerox): Zero shot pdf OCR with gpt-4o-mini.\n18. [DocLayout-YOLO](https://github.com/opendatalab/DocLayout-YOLO): Enhancing Document Layout Analysis through Diverse Synthetic Data and Global-to-Local Adaptive Perception.\n19. [TensorZero](https://github.com/tensorzero/tensorzero): make LLMs improve through experience.\n20. [Promptwright](https://github.com/StacklokLabs/promptwright): Generate large synthetic data using a local LLM.\n21. [pdf-extract-api](https://github.com/CatchTheTornado/pdf-extract-api): Document (PDF) extraction and parse API using state of the art modern OCRs + Ollama supported models.\n22. [pdf2htmlEX](https://github.com/pdf2htmlEX/pdf2htmlEX): Convert PDF to HTML without losing text or format.\n23. [Extractous](https://github.com/yobix-ai/extractous): Fast and efficient unstructured data extraction. Written in Rust with bindings for many languages.\n24. [MegaParse](https://github.com/QuivrHQ/MegaParse): File Parser optimised for LLM Ingestion with no loss.\n25. [MarkItDown](https://github.com/microsoft/markitdown): Python tool for converting files and office documents to Markdown.\n26. [datasketch](https://github.com/ekzhu/datasketch): datasketch gives you probabilistic data structures that can process and search very large amount of data super fast, with little loss of accuracy.\n27. [semhash](https://github.com/MinishLab/semhash): lightweight and flexible tool for deduplicating datasets using semantic similarity.\n28. [ReaderLM-v2](https://huggingface.co/jinaai/ReaderLM-v2): a 1.5B parameter language model that converts raw HTML into beautifully formatted markdown or JSON.\n29. [Bespoke Curator](https://github.com/bespokelabsai/curator): Data Curation for Post-Training & Structured Data Extraction.\n30. [LangKit](https://github.com/whylabs/langkit): An open-source toolkit for monitoring Large Language Models (LLMs). Extracts signals from prompts & responses, ensuring safety & security.\n31. [Curator](https://github.com/bespokelabsai/curator): Synthetic Data curation for post-training and structured data extraction.\n32. [olmOCR](https://github.com/allenai/olmocr): A toolkit for training language models to work with PDF documents in the wild.\n\n<div align=\"right\">\n    <b><a href=\"#Contents\">↥ back to top</a></b>\n</div>\n\n## 微调 Fine-Tuning\n\n1. [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory): Unify Efficient Fine-Tuning of 100+ LLMs.\n2. [360-LLaMA-Factory](https://github.com/Qihoo360/360-LLaMA-Factory): Unify Efficient Fine-Tuning of 100+ LLMs. (add Sequence Parallelism for supporting long context training)\n4. [unsloth](https://github.com/unslothai/unsloth): 2-5X faster 80% less memory LLM finetuning.\n5. [TRL](https://huggingface.co/docs/trl/index): Transformer Reinforcement Learning.\n6. [Firefly](https://github.com/yangjianxin1/Firefly): Firefly: 大模型训练工具，支持训练数十种大模型\n7. [Xtuner](https://github.com/InternLM/xtuner): An efficient, flexible and full-featured toolkit for fine-tuning large models.\n8. [torchtune](https://github.com/pytorch/torchtune): A Native-PyTorch Library for LLM Fine-tuning.\n9. [Swift](https://github.com/modelscope/swift): Use PEFT or Full-parameter to finetune 200+ LLMs or 15+ MLLMs.\n10. [AutoTrain](https://huggingface.co/autotrain): A new way to automatically train, evaluate and deploy state-of-the-art Machine Learning models.\n11. [OpenRLHF](https://github.com/OpenLLMAI/OpenRLHF): An Easy-to-use, Scalable and High-performance RLHF Framework (Support 70B+ full tuning & LoRA & Mixtral & KTO).\n12. [Ludwig](https://github.com/ludwig-ai/ludwig): Low-code framework for building custom LLMs, neural networks, and other AI models.\n13. [mistral-finetune](https://github.com/mistralai/mistral-finetune): A light-weight codebase that enables memory-efficient and performant finetuning of Mistral's models.\n14. [aikit](https://github.com/sozercan/aikit): Fine-tune, build, and deploy open-source LLMs easily!\n15. [H2O-LLMStudio](https://github.com/h2oai/h2o-llmstudio): H2O LLM Studio - a framework and no-code GUI for fine-tuning LLMs.\n16. [LitGPT](https://github.com/Lightning-AI/litgpt): Pretrain, finetune, deploy 20+ LLMs on your own data. Uses state-of-the-art techniques: flash attention, FSDP, 4-bit, LoRA, and more.\n17. [LLMBox](https://github.com/RUCAIBox/LLMBox): A comprehensive library for implementing LLMs, including a unified training pipeline and comprehensive model evaluation.\n18. [PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP): Easy-to-use and powerful NLP and LLM library.\n19. [workbench-llamafactory](https://github.com/NVIDIA/workbench-llamafactory): This is an NVIDIA AI Workbench example project that demonstrates an end-to-end model development workflow using Llamafactory.\n20. [OpenRLHF](https://github.com/OpenLLMAI/OpenRLHF): An Easy-to-use, Scalable and High-performance RLHF Framework (70B+ PPO Full Tuning & Iterative DPO & LoRA & Mixtral).\n21. [TinyLLaVA Factory](https://github.com/TinyLLaVA/TinyLLaVA_Factory): A Framework of Small-scale Large Multimodal Models.\n22. [LLM-Foundry](https://github.com/mosaicml/llm-foundry): LLM training code for Databricks foundation models.\n23. [lmms-finetune](https://github.com/zjysteven/lmms-finetune): A unified codebase for finetuning (full, lora) large multimodal models, supporting llava-1.5, qwen-vl, llava-interleave, llava-next-video, phi3-v etc.\n24. [Simplifine](https://github.com/simplifine-llm/Simplifine): Simplifine lets you invoke LLM finetuning with just one line of code using any Hugging Face dataset or model.\n25. [Transformer Lab](https://github.com/transformerlab/transformerlab-app): Open Source Application for Advanced LLM Engineering: interact, train, fine-tune, and evaluate large language models on your own computer.\n26. [Liger-Kernel](https://github.com/linkedin/Liger-Kernel): Efficient Triton Kernels for LLM Training.\n27. [ChatLearn](https://github.com/alibaba/ChatLearn): A flexible and efficient training framework for large-scale alignment.\n28. [nanotron](https://github.com/huggingface/nanotron): Minimalistic large language model 3D-parallelism training.\n29. [Proxy Tuning](https://github.com/alisawuffles/proxy-tuning): Tuning Language Models by Proxy.\n30. [Effective LLM Alignment](https://github.com/VikhrModels/effective_llm_alignment/): Effective LLM Alignment Toolkit.\n31. [Autotrain-advanced](https://github.com/huggingface/autotrain-advanced)\n32. [Meta Lingua](https://github.com/facebookresearch/lingua): a lean, efficient, and easy-to-hack codebase to research LLMs.\n33. [Vision-LLM Alignemnt](https://github.com/NiuTrans/Vision-LLM-Alignment): This repository contains the code for SFT, RLHF, and DPO, designed for vision-based LLMs, including the LLaVA models and the LLaMA-3.2-vision models.\n34. [finetune-Qwen2-VL](https://github.com/zhangfaen/finetune-Qwen2-VL): Quick Start for Fine-tuning or continue pre-train Qwen2-VL Model.\n35. [Online-RLHF](https://github.com/RLHFlow/Online-RLHF): A recipe for online RLHF and online iterative DPO.\n36. [InternEvo](https://github.com/InternLM/InternEvo): an open-sourced lightweight training framework aims to support model pre-training without the need for extensive dependencies.\n37. [veRL](https://github.com/volcengine/verl): Volcano Engine Reinforcement Learning for LLM.\n38. [Axolotl](https://axolotl-ai-cloud.github.io/axolotl/): Axolotl is designed to work with YAML config files that contain everything you need to preprocess a dataset, train or fine-tune a model, run model inference or evaluation, and much more.\n39. [Oumi](https://github.com/oumi-ai/oumi): Everything you need to build state-of-the-art foundation models, end-to-end.\n40. [Kiln](https://github.com/Kiln-AI/Kiln): The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.\n41. [DeepSeek-671B-SFT-Guide](https://github.com/ScienceOne-AI/DeepSeek-671B-SFT-Guide): An open-source solution for full parameter fine-tuning of DeepSeek-V3/R1 671B, including complete code and scripts from training to inference, as well as some practical experiences and conclusions.\n\n<div align=\"right\">\n    <b><a href=\"#Contents\">↥ back to top</a></b>\n</div>\n\n## 推理 Inference\n\n1. [ollama](https://github.com/ollama/ollama): Get up and running with Llama 3, Mistral, Gemma, and other large language models.\n2. [Open WebUI](https://github.com/open-webui/open-webui): User-friendly WebUI for LLMs (Formerly Ollama WebUI).\n3. [Text Generation WebUI](https://github.com/oobabooga/text-generation-webui): A Gradio web UI for Large Language Models. Supports transformers, GPTQ, AWQ, EXL2, llama.cpp (GGUF), Llama models.\n4. [Xinference](https://github.com/xorbitsai/inference): A powerful and versatile library designed to serve language, speech recognition, and multimodal models.\n5. [LangChain](https://github.com/langchain-ai/langchain): Build context-aware reasoning applications.\n6. [LlamaIndex](https://github.com/run-llama/llama_index): A data framework for your LLM applications.\n7. [lobe-chat](https://github.com/lobehub/lobe-chat): an open-source, modern-design LLMs/AI chat framework. Supports Multi AI Providers, Multi-Modals (Vision/TTS) and plugin system.\n8. [TensorRT-LLM](https://github.com/NVIDIA/TensorRT-LLM): TensorRT-LLM provides users with an easy-to-use Python API to define Large Language Models (LLMs) and build TensorRT engines that contain state-of-the-art optimizations to perform inference efficiently on NVIDIA GPUs.\n9. [vllm](https://github.com/vllm-project/vllm): A high-throughput and memory-efficient inference and serving engine for LLMs.\n10. [LlamaChat](https://github.com/alexrozanski/LlamaChat): Chat with your favourite LLaMA models in a native macOS app.\n11. [NVIDIA ChatRTX](https://www.nvidia.com/en-us/ai-on-rtx/chatrtx/): ChatRTX is a demo app that lets you personalize a GPT large language model (LLM) connected to your own content—docs, notes, or other data.\n12. [LM Studio](https://lmstudio.ai/): Discover, download, and run local LLMs.\n13. [chat-with-mlx](https://github.com/qnguyen3/chat-with-mlx): Chat with your data natively on Apple Silicon using MLX Framework.\n14. [LLM Pricing](https://llmpricecheck.com/): Quickly Find the Perfect Large Language Models (LLM) API for Your Budget! Use Our Free Tool for Instant Access to the Latest Prices from Top Providers.\n15. [Open Interpreter](https://github.com/OpenInterpreter/open-interpreter): A natural language interface for computers.\n16. [Chat-ollama](https://github.com/sugarforever/chat-ollama): An open source chatbot based on LLMs. It supports a wide range of language models, and knowledge base management.\n17. [chat-ui](https://github.com/huggingface/chat-ui): Open source codebase powering the HuggingChat app.\n18. [MemGPT](https://github.com/cpacker/MemGPT): Create LLM agents with long-term memory and custom tools.\n19. [koboldcpp](https://github.com/LostRuins/koboldcpp): A simple one-file way to run various GGML and GGUF models with KoboldAI's UI.\n20. [LLMFarm](https://github.com/guinmoon/LLMFarm): llama and other large language models on iOS and MacOS offline using GGML library.\n21. [enchanted](https://github.com/AugustDev/enchanted): Enchanted is iOS and macOS app for chatting with private self hosted language models such as Llama2, Mistral or Vicuna using Ollama.\n22. [Flowise](https://github.com/FlowiseAI/Flowise): Drag & drop UI to build your customized LLM flow.\n23. [Jan](https://github.com/janhq/jan): Jan is an open source alternative to ChatGPT that runs 100% offline on your computer. Multiple engine support (llama.cpp, TensorRT-LLM).\n24. [LMDeploy](https://github.com/InternLM/lmdeploy): LMDeploy is a toolkit for compressing, deploying, and serving LLMs.\n25. [RouteLLM](https://github.com/lm-sys/RouteLLM): A framework for serving and evaluating LLM routers - save LLM costs without compromising quality!\n26. [MInference](https://github.com/microsoft/MInference): About\nTo speed up Long-context LLMs' inference, approximate and dynamic sparse calculate the attention, which reduces inference latency by up to 10x for pre-filling on an A100 while maintaining accuracy.\n27. [Mem0](https://github.com/mem0ai/mem0): The memory layer for Personalized AI.\n28. [SGLang](https://github.com/sgl-project/sglang): SGLang is yet another fast serving framework for large language models and vision language models.\n29. [AirLLM](https://github.com/lyogavin/airllm): AirLLM optimizes inference memory usage, allowing 70B large language models to run inference on a single 4GB GPU card without quantization, distillation and pruning. And you can run 405B Llama3.1 on 8GB vram now.\n30. [LLMHub](https://github.com/jmather/llmhub): LLMHub is a lightweight management platform designed to streamline the operation and interaction with various language models (LLMs).\n31. [YuanChat](https://github.com/IEIT-Yuan/YuanChat)\n32. [LiteLLM](https://github.com/BerriAI/litellm): Call all LLM APIs using the OpenAI format [Bedrock, Huggingface, VertexAI, TogetherAI, Azure, OpenAI, Groq etc.]\n33. [GuideLLM](https://github.com/neuralmagic/guidellm): GuideLLM is a powerful tool for evaluating and optimizing the deployment of large language models (LLMs).\n34. [LLM-Engines](https://github.com/jdf-prog/LLM-Engines): A unified inference engine for large language models (LLMs) including open-source models (VLLM, SGLang, Together) and commercial models (OpenAI, Mistral, Claude).\n35. [OARC](https://github.com/Leoleojames1/ollama_agent_roll_cage): ollama_agent_roll_cage (OARC) is a local python agent fusing ollama llm's with Coqui-TTS speech models, Keras classifiers, Llava vision, Whisper recognition, and more to create a unified chatbot agent for local, custom automation.\n36. [g1](https://github.com/bklieger-groq/g1): Using Llama-3.1 70b on Groq to create o1-like reasoning chains.\n37. [MemoryScope](https://github.com/modelscope/MemoryScope): MemoryScope provides LLM chatbots with powerful and flexible long-term memory capabilities, offering a framework for building such abilities.\n38. [OpenLLM](https://github.com/bentoml/OpenLLM): Run any open-source LLMs, such as Llama 3.1, Gemma, as OpenAI compatible API endpoint in the cloud.\n39. [Infinity](https://github.com/infiniflow/infinity): The AI-native database built for LLM applications, providing incredibly fast hybrid search of dense embedding, sparse embedding, tensor and full-text.\n40. [optillm](https://github.com/codelion/optillm): an OpenAI API compatible optimizing inference proxy which implements several state-of-the-art techniques that can improve the accuracy and performance of LLMs.\n41. [LLaMA Box](https://github.com/gpustack/llama-box): LLM inference server implementation based on llama.cpp.\n42. [ZhiLight](https://github.com/zhihu/ZhiLight): A highly optimized inference acceleration engine for Llama and its variants.\n43. [DashInfer](https://github.com/modelscope/dash-infer): DashInfer is a native LLM inference engine aiming to deliver industry-leading performance atop various hardware architectures.\n44. [LocalAI](https://github.com/mudler/LocalAI): The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI, running on consumer-grade hardware. No GPU required.\n45. [ktransformers](https://github.com/kvcache-ai/ktransformers): A Flexible Framework for Experiencing Cutting-edge LLM Inference Optimizations.\n46. [SkyPilot](https://github.com/skypilot-org/skypilot): Run AI and batch jobs on any infra (Kubernetes or 14+ clouds). Get unified execution, cost savings, and high GPU availability via a simple interface.\n\n\n<div align=\"right\">\n    <b><a href=\"#Contents\">↥ back to top</a></b>\n</div>\n\n## 评估 Evaluation\n\n1. [lm-evaluation-harness](https://github.com/EleutherAI/lm-evaluation-harness): A framework for few-shot evaluation of language models.\n2. [opencompass](https://github.com/open-compass/opencompass): OpenCompass is an LLM evaluation platform, supporting a wide range of models (Llama3, Mistral, InternLM2,GPT-4,LLaMa2, Qwen,GLM, Claude, etc) over 100+ datasets.\n3. [llm-comparator](https://github.com/PAIR-code/llm-comparator): LLM Comparator is an interactive data visualization tool for evaluating and analyzing LLM responses side-by-side, developed.\n4. [EvalScope](https://github.com/modelscope/evalscope)\n5. [Weave](https://weave-docs.wandb.ai/guides/core-types/evaluations): A lightweight toolkit for tracking and evaluating LLM applications.\n6. [MixEval](https://github.com/Psycoy/MixEval/): Deriving Wisdom of the Crowd from LLM Benchmark Mixtures.\n7. [Evaluation guidebook](https://github.com/huggingface/evaluation-guidebook): If you've ever wondered how to make sure an LLM performs well on your specific task, this guide is for you!\n8. [Ollama Benchmark](https://github.com/aidatatools/ollama-benchmark): LLM Benchmark for Throughput via Ollama (Local LLMs).\n9. [VLMEvalKit](https://github.com/open-compass/VLMEvalKit): Open-source evaluation toolkit of large vision-language models (LVLMs), support ~100 VLMs, 40+ benchmarks.\n10. [AGI-Eval](https://agi-eval.cn/mvp/home)\n11. [EvalScope](https://github.com/modelscope/evalscope): A streamlined and customizable framework for efficient large model evaluation and performance benchmarking.\n12. [DeepEval](https://github.com/confident-ai/deepeval): a simple-to-use, open-source LLM evaluation framework, for evaluating and testing large-language model systems.\n13. [Lighteval](https://github.com/huggingface/lighteval): Lighteval is your all-in-one toolkit for evaluating LLMs across multiple backends.\n\n`LLM API 服务平台`：\n1. [Groq](https://groq.com/)\n2. [硅基流动](https://cloud.siliconflow.cn/models)\n3. [火山引擎](https://www.volcengine.com/product/ark)\n4. [文心千帆](https://qianfan.cloud.baidu.com/)\n5. [DashScope](https://dashscope.aliyun.com/)\n6. [aisuite](https://github.com/andrewyng/aisuite)\n7. [DeerAPI](https://www.deerapi.com/)\n8. [Qwen-Chat](https://chat.qwenlm.ai/)\n9. [DeepSeek-v3](https://www.deepseek.com/)\n\n<div align=\"right\">\n    <b><a href=\"#Contents\">↥ back to top</a></b>\n</div>\n\n## 体验 Usage\n\n1. [LMSYS Chatbot Arena: Benchmarking LLMs in the Wild](https://arena.lmsys.org/)\n2. [CompassArena 司南大模型竞技场](https://modelscope.cn/studios/opencompass/CompassArena/summary)\n3. [琅琊榜](https://langyb.com/)\n4. [Huggingface Spaces](https://huggingface.co/spaces)\n5. [WiseModel Spaces](https://wisemodel.cn/spaces)\n6. [Poe](https://poe.com/)\n7. [林哥的大模型野榜](https://lyihub.com/)\n8. [OpenRouter](https://openrouter.ai/)\n9. [AnyChat](https://huggingface.co/spaces/akhaliq/anychat)\n\n<div align=\"right\">\n    <b><a href=\"#Contents\">↥ back to top</a></b>\n</div>\n\n## 知识库 RAG\n\n1. [AnythingLLM](https://github.com/Mintplex-Labs/anything-llm): The all-in-one AI app for any LLM with full RAG and AI Agent capabilites.\n2. [MaxKB](https://github.com/1Panel-dev/MaxKB): 基于 LLM 大语言模型的知识库问答系统。开箱即用，支持快速嵌入到第三方业务系统\n3. [RAGFlow](https://github.com/infiniflow/ragflow): An open-source RAG (Retrieval-Augmented Generation) engine based on deep document understanding.\n4. [Dify](https://github.com/langgenius/dify): An open-source LLM app development platform. Dify's intuitive interface combines AI workflow, RAG pipeline, agent capabilities, model management, observability features and more, letting you quickly go from prototype to production.\n5. [FastGPT](https://github.com/labring/FastGPT): A knowledge-based platform built on the LLM, offers out-of-the-box data processing and model invocation capabilities, allows for workflow orchestration through Flow visualization.\n6. [Langchain-Chatchat](https://github.com/chatchat-space/Langchain-Chatchat): 基于 Langchain 与 ChatGLM 等不同大语言模型的本地知识库问答\n7. [QAnything](https://github.com/netease-youdao/QAnything): Question and Answer based on Anything.\n8. [Quivr](https://github.com/QuivrHQ/quivr): A personal productivity assistant (RAG) ⚡️🤖 Chat with your docs (PDF, CSV, ...) & apps using Langchain, GPT 3.5 / 4 turbo, Private, Anthropic, VertexAI, Ollama, LLMs, Groq that you can share with users ! Local & Private alternative to OpenAI GPTs & ChatGPT powered by retrieval-augmented generation.\n9. [RAG-GPT](https://github.com/open-kf/rag-gpt): RAG-GPT, leveraging LLM and RAG technology, learns from user-customized knowledge bases to provide contextually relevant answers for a wide range of queries, ensuring rapid and accurate information retrieval.\n10. [Verba](https://github.com/weaviate/Verba): Retrieval Augmented Generation (RAG) chatbot powered by Weaviate.\n11. [FlashRAG](https://github.com/RUC-NLPIR/FlashRAG): A Python Toolkit for Efficient RAG Research.\n12. [GraphRAG](https://github.com/microsoft/graphrag): A modular graph-based Retrieval-Augmented Generation (RAG) system.\n13. [LightRAG](https://github.com/SylphAI-Inc/LightRAG): LightRAG helps developers with both building and optimizing Retriever-Agent-Generator pipelines.\n14. [GraphRAG-Ollama-UI](https://github.com/severian42/GraphRAG-Ollama-UI): GraphRAG using Ollama with Gradio UI and Extra Features.\n15. [nano-GraphRAG](https://github.com/gusye1234/nano-graphrag): A simple, easy-to-hack GraphRAG implementation.\n16. [RAG Techniques](https://github.com/NirDiamant/RAG_Techniques): This repository showcases various advanced techniques for Retrieval-Augmented Generation (RAG) systems. RAG systems combine information retrieval with generative models to provide accurate and contextually rich responses.\n17. [ragas](https://github.com/explodinggradients/ragas): Evaluation framework for your Retrieval Augmented Generation (RAG) pipelines.\n18. [kotaemon](https://github.com/Cinnamon/kotaemon): An open-source clean & customizable RAG UI for chatting with your documents. Built with both end users and developers in mind.\n19. [RAGapp](https://github.com/ragapp/ragapp): The easiest way to use Agentic RAG in any enterprise.\n20. [TurboRAG](https://github.com/MooreThreads/TurboRAG): Accelerating Retrieval-Augmented Generation with Precomputed KV Caches for Chunked Text.\n21. [LightRAG](https://github.com/HKUDS/LightRAG): Simple and Fast Retrieval-Augmented Generation.\n22. [TEN](https://github.com/TEN-framework/ten_framework): the Next-Gen AI-Agent Framework, the world's first truly real-time multimodal AI agent framework.\n23. [AutoRAG](https://github.com/Marker-Inc-Korea/AutoRAG): RAG AutoML tool for automatically finding an optimal RAG pipeline for your data.\n24. [KAG](https://github.com/OpenSPG/KAG): KAG is a knowledge-enhanced generation framework based on OpenSPG engine, which is used to build knowledge-enhanced rigorous decision-making and information retrieval knowledge services.\n25. [Fast-GraphRAG](https://github.com/circlemind-ai/fast-graphrag): RAG that intelligently adapts to your use case, data, and queries.\n26. [Tiny-GraphRAG](https://github.com/limafang/tiny-graphrag)\n27. [DB-GPT GraphRAG](https://github.com/eosphoros-ai/DB-GPT/tree/main/dbgpt/storage/knowledge_graph): DB-GPT GraphRAG integrates both triplet-based knowledge graphs and document structure graphs while leveraging community and document retrieval mechanisms to enhance RAG capabilities, achieving comparable performance while consuming only 50% of the tokens required by Microsoft's GraphRAG. Refer to the DB-GPT [Graph RAG User Manual](http://docs.dbgpt.cn/docs/cookbook/rag/graph_rag_app_develop/) for details.\n28. [Chonkie](https://github.com/bhavnicksm/chonkie): The no-nonsense RAG chunking library that's lightweight, lightning-fast, and ready to CHONK your texts.\n29. [RAGLite](https://github.com/superlinear-ai/raglite): RAGLite is a Python toolkit for Retrieval-Augmented Generation (RAG) with PostgreSQL or SQLite.\n30. [KAG](https://github.com/OpenSPG/KAG): KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.\n31. [CAG](https://github.com/hhhuang/CAG): CAG leverages the extended context windows of modern large language models (LLMs) by preloading all relevant resources into the model’s context and caching its runtime parameters.\n32. [MiniRAG](https://github.com/HKUDS/MiniRAG): an extremely simple retrieval-augmented generation framework that enables small models to achieve good RAG performance through heterogeneous graph indexing and lightweight topology-enhanced retrieval.\n33. [XRAG](https://github.com/DocAILab/XRAG): a benchmarking framework designed to evaluate the foundational components of advanced Retrieval-Augmented Generation (RAG) systems.\n\n<div align=\"right\">\n    <b><a href=\"#Contents\">↥ back to top</a></b>\n</div>\n\n## 智能体 Agents\n\n1. [AutoGen](https://github.com/microsoft/autogen): AutoGen is a framework that enables the development of LLM applications using multiple agents that can converse with each other to solve tasks. [AutoGen AIStudio](https://autogen-studio.com/)\n2. [CrewAI](https://github.com/joaomdmoura/crewAI): Framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.\n3. [Coze](https://www.coze.com/)\n4. [AgentGPT](https://github.com/reworkd/AgentGPT): Assemble, configure, and deploy autonomous AI Agents in your browser.\n5. [XAgent](https://github.com/OpenBMB/XAgent): An Autonomous LLM Agent for Complex Task Solving.\n6. [MobileAgent](https://github.com/X-PLUG/MobileAgent): The Powerful Mobile Device Operation Assistant Family.\n7. [Lagent](https://github.com/InternLM/lagent): A lightweight framework for building LLM-based agents.\n8. [Qwen-Agent](https://github.com/QwenLM/Qwen-Agent): Agent framework and applications built upon Qwen2, featuring Function Calling, Code Interpreter, RAG, and Chrome extension.\n9. [LinkAI](https://link-ai.tech/portal): 一站式 AI 智能体搭建平台\n10. [Baidu APPBuilder](https://appbuilder.cloud.baidu.com/)\n11. [agentUniverse](https://github.com/alipay/agentUniverse): agentUniverse is a LLM multi-agent framework that allows developers to easily build multi-agent applications. Furthermore, through the community, they can exchange and share practices of patterns across different domains.\n12. [LazyLLM](https://github.com/LazyAGI/LazyLLM): 低代码构建多Agent大模型应用的开发工具\n13. [AgentScope](https://github.com/modelscope/agentscope): Start building LLM-empowered multi-agent applications in an easier way.\n14. [MoA](https://github.com/togethercomputer/MoA): Mixture of Agents (MoA) is a novel approach that leverages the collective strengths of multiple LLMs to enhance performance, achieving state-of-the-art results.\n15. [Agently](https://github.com/Maplemx/Agently): AI Agent Application Development Framework.\n16. [OmAgent](https://github.com/om-ai-lab/OmAgent): A multimodal agent framework for solving complex tasks.\n17. [Tribe](https://github.com/StreetLamb/tribe): No code tool to rapidly build and coordinate multi-agent teams.\n18. [CAMEL](https://github.com/camel-ai/camel): First LLM multi-agent framework and an open-source community dedicated to finding the scaling law of agents.\n19. [PraisonAI](https://github.com/MervinPraison/PraisonAI/): PraisonAI application combines AutoGen and CrewAI or similar frameworks into a low-code solution for building and managing multi-agent LLM systems, focusing on simplicity, customisation, and efficient human-agent collaboration.\n20. [IoA](https://github.com/openbmb/ioa): An open-source framework for collaborative AI agents, enabling diverse, distributed agents to team up and tackle complex tasks through internet-like connectivity.\n21. [llama-agentic-system ](https://github.com/meta-llama/llama-agentic-system): Agentic components of the Llama Stack APIs.\n22. [Agent Zero](https://github.com/frdel/agent-zero): Agent Zero is not a predefined agentic framework. It is designed to be dynamic, organically growing, and learning as you use it.\n23. [Agents](https://github.com/aiwaves-cn/agents): An Open-source Framework for Data-centric, Self-evolving Autonomous Language Agents.\n24. [AgentScope](https://github.com/modelscope/agentscope): Start building LLM-empowered multi-agent applications in an easier way.\n25. [FastAgency](https://github.com/airtai/fastagency): The fastest way to bring multi-agent workflows to production.\n26. [Swarm](https://github.com/openai/swarm): Framework for building, orchestrating and deploying multi-agent systems. Managed by OpenAI Solutions team. Experimental framework.\n27. [Agent-S](https://github.com/simular-ai/Agent-S): an open agentic framework that uses computers like a human.\n28. [PydanticAI](https://github.com/pydantic/pydantic-ai): Agent Framework / shim to use Pydantic with LLMs.\n29. [Agentarium](https://github.com/Thytu/Agentarium): open-source framework for creating and managing simulations populated with AI-powered agents.\n30. [smolagents](https://github.com/huggingface/smolagents): a barebones library for agents. Agents write python code to call tools and orchestrate other agents.\n\n<div align=\"right\">\n    <b><a href=\"#Contents\">↥ back to top</a></b>\n</div>\n\n## 搜索 Search\n\n1. [OpenSearch GPT](https://github.com/supermemoryai/opensearch-ai): SearchGPT / Perplexity clone, but personalised for you.\n2. [MindSearch](https://github.com/InternLM/MindSearch): An LLM-based Multi-agent Framework of Web Search Engine (like Perplexity.ai Pro and SearchGPT).\n3. [nanoPerplexityAI](https://github.com/Yusuke710/nanoPerplexityAI): The simplest open-source implementation of perplexity.ai.\n4. [curiosity](https://github.com/jank/curiosity): Try to build a Perplexity-like user experience.\n5. [MiniPerplx](https://github.com/zaidmukaddam/miniperplx): A minimalistic AI-powered search engine that helps you find information on the internet.\n\n<div align=\"right\">\n    <b><a href=\"#Contents\">↥ back to top</a></b>\n</div>\n\n## 书籍 Book\n\n1. [《大规模语言模型：从理论到实践》](https://intro-llm.github.io/)\n2. [《大语言模型》](https://llmbook-zh.github.io/)\n3. [《动手学大模型Dive into LLMs》](https://github.com/Lordog/dive-into-llms)\n4. [《动手做AI Agent》](https://book.douban.com/subject/36884058/)\n5. [《Build a Large Language Model (From Scratch)》](https://github.com/rasbt/LLMs-from-scratch)\n6. [《多模态大模型》](https://github.com/HCPLab-SYSU/Book-of-MLM)\n7. [《Generative AI Handbook: A Roadmap for Learning Resources》](https://genai-handbook.github.io/)\n8. [《Understanding Deep Learning》](https://udlbook.github.io/udlbook/)\n9. [《Illustrated book to learn about Transformers & LLMs》](https://www.reddit.com/r/MachineLearning/comments/1ew1hws/p_illustrated_book_to_learn_about_transformers/)\n10. [《Building LLMs for Production: Enhancing LLM Abilities and Reliability with Prompting, Fine-Tuning, and RAG》](https://www.amazon.com/Building-LLMs-Production-Reliability-Fine-Tuning/dp/B0D4FFPFW8?crid=7OAXELUKGJE4&dib=eyJ2IjoiMSJ9.Qr3e3VSH8LSo_j1M7sV7GfS01q_W1LDYd2uGlvGJ8CW-t4DTlng6bSeOlZBryhp6HJN5K1HqWMVVgabU2wz2i9yLpy_AuaZN-raAEbenKx2NHtzZA3A4k-N7GpnldF1baCarA_V1CRF-aCdc9_3WSX7SaEzmpyDv22TTyltcKT74HAb2KiQqBGLhQS3cEAnzChcqGa1Xp-XhbMnplVwT7xZLApE3tGLhDOgi5GmSi9w.8SY_4NBEkm68YF4GwhDnz0r81ZB1d8jr-gK9IMJE5AE&dib_tag=se&keywords=building+llms+for+production&qid=1716376414&sprefix=building+llms+for+production,aps,101&sr=8-1&linkCode=sl1&tag=whatsai06-20&linkId=ee102fda07a0eb51710fcdd8b8d20c28&language=en_US&ref_=as_li_ss_tl)\n11. [《大型语言模型实战指南：应用实践与场景落地》](https://github.com/liucongg/LLMsBook)\n12. [《Hands-On Large Language Models》](https://github.com/handsOnLLM/Hands-On-Large-Language-Models)\n13. [《自然语言处理：大模型理论与实践》](https://nlp-book.swufenlp.group/)\n14. [《动手学强化学习》](https://hrl.boyuai.com/)\n15. [《面向开发者的LLM入门教程》](https://datawhalechina.github.io/llm-cookbook/#/)\n16. [《大模型基础》](https://github.com/ZJU-LLMs/Foundations-of-LLMs)\n17. [Taming LLMs: A Practical Guide to LLM Pitfalls with Open Source Software ](https://www.tamingllms.com/)\n18. [Foundations of Large Language Models](https://arxiv.org/abs/2501.09223)\n\n<div align=\"right\">\n    <b><a href=\"#Contents\">↥ back to top</a></b>\n</div>\n\n## 课程 Course\n\n> [LLM Resources Hub](https://llmresourceshub.vercel.app/)\n\n1. [斯坦福 CS224N: Natural Language Processing with Deep Learning](https://web.stanford.edu/class/cs224n/)\n2. [吴恩达: Generative AI for Everyone](https://www.deeplearning.ai/courses/generative-ai-for-everyone/)\n3. [吴恩达: LLM series of courses](https://learn.deeplearning.ai/)\n4. [ACL 2023 Tutorial: Retrieval-based Language Models and Applications](https://acl2023-retrieval-lm.github.io/)\n5. [llm-course: Course to get into Large Language Models (LLMs) with roadmaps and Colab notebooks.](https://github.com/mlabonne/llm-course)\n6. [微软: Generative AI for Beginners](https://github.com/microsoft/generative-ai-for-beginners)\n7. [微软: State of GPT](https://www.youtube.com/watch?v=bZQun8Y4L2A)\n8. [HuggingFace NLP Course](https://huggingface.co/learn/nlp-course/chapter1/1)\n9. [清华 NLP 刘知远团队大模型公开课](https://www.bilibili.com/video/BV1UG411p7zv/?vd_source=c739db1ebdd361d47af5a0b8497417db)\n10. [斯坦福 CS25: Transformers United V4](https://web.stanford.edu/class/cs25/)\n11. [斯坦福 CS324: Large Language Models](https://stanford-cs324.github.io/winter2022/)\n12. [普林斯顿 COS 597G (Fall 2022): Understanding Large Language Models](https://www.cs.princeton.edu/courses/archive/fall22/cos597G/)\n13. [约翰霍普金斯 CS 601.471/671 NLP: Self-supervised Models](https://self-supervised.cs.jhu.edu/sp2023/index.html)\n14. [李宏毅 GenAI课程](https://www.youtube.com/watch?v=yiY4nPOzJEg&list=PLJV_el3uVTsOePyfmkfivYZ7Rqr2nMk3W)\n15. [openai-cookbook](https://github.com/openai/openai-cookbook): Examples and guides for using the OpenAI API.\n16. [Hands on llms](https://github.com/iusztinpaul/hands-on-llms): Learn about LLM, LLMOps, and vector DBS for free by designing, training, and deploying a real-time financial advisor LLM system.\n17. [滑铁卢大学 CS 886: Recent Advances on Foundation Models](https://cs.uwaterloo.ca/~wenhuche/teaching/cs886/)\n18. [Mistral: Getting Started with Mistral](https://www.deeplearning.ai/short-courses/getting-started-with-mistral/)\n19. [斯坦福 CS25: Transformers United V4](https://web.stanford.edu/class/cs25/)\n20. [Coursera: Chatgpt 应用提示工程](https://www.coursera.org/learn/prompt-engineering)\n21. [LangGPT](https://github.com/langgptai/LangGPT): Empowering everyone to become a prompt expert!\n22. [mistralai-cookbook](https://github.com/mistralai/cookbook)\n23. [Introduction to Generative AI 2024 Spring](https://speech.ee.ntu.edu.tw/~hylee/genai/2024-spring.php)\n24. [build nanoGPT](https://github.com/karpathy/build-nanogpt): Video+code lecture on building nanoGPT from scratch.\n25. [LLM101n](https://github.com/karpathy/LLM101n): Let's build a Storyteller.\n26. [Knowledge Graphs for RAG](https://www.deeplearning.ai/short-courses/knowledge-graphs-rag/)\n27. [LLMs From Scratch (Datawhale Version)](https://github.com/datawhalechina/llms-from-scratch-cn)\n28. [OpenRAG](https://openrag.notion.site/Open-RAG-c41b2a4dcdea4527a7c1cd998e763595)\n29. [通往AGI之路](https://waytoagi.feishu.cn/wiki/QPe5w5g7UisbEkkow8XcDmOpn8e)\n30. [Andrej Karpathy - Neural Networks: Zero to Hero](https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ)\n31. [Interactive visualization of Transformer](https://poloclub.github.io/transformer-explainer/)\n32. [andysingal/llm-course](https://github.com/andysingal/llm-course)\n33. [LM-class](https://lm-class.org/lectures)\n34. [Google Advanced: Generative AI for Developers Learning Path](https://www.cloudskillsboost.google/paths/183)\n35. [Anthropics：Prompt Engineering Interactive Tutorial](https://github.com/anthropics/courses/tree/master/prompt_engineering_interactive_tutorial/Anthropic%201P)\n36. [LLMsBook](https://github.com/liucongg/LLMsBook)\n37. [Large Language Model Agents](https://llmagents-learning.org/f24)\n38. [Cohere LLM University](https://cohere.com/llmu)\n39. [LLMs and Transformers](https://www.ambujtewari.com/LLM-fall2024/)\n40. [Smol Vision](https://github.com/merveenoyan/smol-vision): Recipes for shrinking, optimizing, customizing cutting edge vision models.\n41. [Multimodal RAG: Chat with Videos](https://www.deeplearning.ai/short-courses/multimodal-rag-chat-with-videos/)\n42. [LLMs Interview Note](https://github.com/wdndev/llm_interview_note)\n43. [RAG++ : From POC to production](https://www.wandb.courses/courses/rag-in-production): Advanced RAG course.\n44. [Weights & Biases AI Academy](https://www.wandb.courses/pages/w-b-courses): Finetuning, building with LLMs, Structured outputs and more LLM courses.\n45. [Prompt Engineering & AI tutorials & Resources](https://promptengineering.org/)\n46. [Learn RAG From Scratch – Python AI Tutorial from a LangChain Engineer](https://www.youtube.com/watch?v=sVcwVQRHIc8)\n47. [LLM Evaluation: A Complete Course](https://www.comet.com/site/llm-course/)\n48. [HuggingFace Learn](https://huggingface.co/learn)\n49. [Andrej Karpathy: Deep Dive into LLMs like ChatGPT](https://www.youtube.com/watch?v=7xTGNNLPyMI)\n50. [LLM技术科普](https://github.com/karminski/one-small-step)\n\n<div align=\"right\">\n    <b><a href=\"#Contents\">↥ back to top</a></b>\n</div>\n\n## 教程 Tutorial\n\n1. [动手学大模型应用开发](https://datawhalechina.github.io/llm-universe/#/)\n2. [AI开发者频道](https://techdiylife.github.io/blog/blog_list.html)\n3. [B站：五里墩茶社](https://space.bilibili.com/615957867/?spm_id_from=333.999.0.0)\n4. [B站：木羽Cheney](https://space.bilibili.com/3537113897241540/?spm_id_from=333.999.0.0)\n5. [YTB：AI Anytime](https://www.youtube.com/channel/UC-zVytOQB62OwMhKRi0TDvg)\n6. [B站：漆妮妮](https://space.bilibili.com/1262370256/?spm_id_from=333.999.0.0)\n7. [Prompt Engineering Guide](https://www.promptingguide.ai/)\n8. [YTB: AI超元域](https://www.youtube.com/@AIsuperdomain)\n9. [B站：TechBeat人工智能社区](https://space.bilibili.com/209732435)\n10. [B站：黄益贺](https://space.bilibili.com/322961825)\n11. [B站：深度学习自然语言处理](https://space.bilibili.com/507524288)\n12. [LLM Visualization](https://bbycroft.net/llm)\n13. [知乎: 原石人类](https://www.zhihu.com/people/zhang-shi-tou-88-98/posts)\n14. [B站：小黑黑讲AI](https://space.bilibili.com/1963375439/?spm_id_from=333.999.0.0)\n15. [B站：面壁的车辆工程师](https://space.bilibili.com/669720247/?spm_id_from=333.999.0.0)\n16. [B站：AI老兵文哲](https://space.bilibili.com/472543316/?spm_id_from=333.999.0.0)\n17. [Large Language Models (LLMs) with Colab notebooks](https://mlabonne.github.io/blog/)\n18. [YTB：IBM Technology](https://www.youtube.com/@IBMTechnology)\n19. [YTB: Unify Reading Paper Group](https://www.youtube.com/playlist?list=PLwNuX3xB_tv91QvDXlW2TjrLGHW51uMul)\n20. [Chip Huyen](https://huyenchip.com/blog/)\n21. [How Much VRAM](https://github.com/AlexBodner/How_Much_VRAM)\n22. [Blog: 科学空间（苏剑林）](https://kexue.fm/)\n23. [YTB: Hyung Won Chung](https://www.youtube.com/watch?v=dbo3kNKPaUA)\n24. [Blog: Tejaswi kashyap](https://medium.com/@tejaswi_kashyap)\n25. [Blog: 小昇的博客](https://xiaosheng.blog/)\n26. [知乎: ybq](https://www.zhihu.com/people/ybq-29-32/posts)\n27. [W&B articles](https://wandb.ai/fully-connected)\n28. [Huggingface Blog](https://huggingface.co/blog/zh)\n29. [Blog: GbyAI](https://gby.ai/)\n30. [Blog: mlabonne](https://mlabonne.github.io/blog/)\n31. [LLM-Action](https://github.com/liguodongiot/llm-action)\n32. [Blog: Lil’Log (OponAI)](https://lilianweng.github.io/)\n33. [B站: 毛玉仁](https://space.bilibili.com/3546823125895398)\n34. [AI-Guide-and-Demos](https://github.com/Hoper-J/AI-Guide-and-Demos-zh_CN)\n35. [cnblog: 第七子](https://www.cnblogs.com/theseventhson)\n\n<div align=\"right\">\n    <b><a href=\"#Contents\">↥ back to top</a></b>\n</div>\n\n## 论文 Paper\n\n> [!NOTE]\n> 🤝[Huggingface Daily Papers](https://huggingface.co/papers)、[Cool Papers](https://papers.cool/)、[ML Papers Explained](https://github.com/dair-ai/ML-Papers-Explained)\n\n1. [Hermes-3-Technical-Report](https://nousresearch.com/wp-content/uploads/2024/08/Hermes-3-Technical-Report.pdf)\n2. [The Llama 3 Herd of Models](https://arxiv.org/abs/2407.21783)\n3. [Qwen Technical Report](https://arxiv.org/abs/2309.16609)\n4. [Qwen2 Technical Report](https://arxiv.org/abs/2407.10671)\n5. [Qwen2-vl Technical Report](https://arxiv.org/abs/2409.12191)\n6. [DeepSeek LLM: Scaling Open-Source Language Models with Longtermism](https://arxiv.org/abs/2401.02954)\n7. [DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model](https://arxiv.org/abs/2405.04434)\n8. [Baichuan 2: Open Large-scale Language Models](https://arxiv.org/abs/2309.10305)\n9. [DataComp-LM: In search of the next generation of training sets for language models](https://arxiv.org/abs/2406.11794)\n10. [OLMo: Accelerating the Science of Language Models](https://arxiv.org/abs/2402.00838)\n11. [MAP-Neo: Highly Capable and Transparent Bilingual Large Language Model Series](https://arxiv.org/abs/2405.19327)\n12. [Chinese Tiny LLM: Pretraining a Chinese-Centric Large Language Model](https://arxiv.org/abs/2404.04167)\n13. [Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone](https://arxiv.org/abs/2404.14219)\n14. [Jamba-1.5: Hybrid Transformer-Mamba Models at Scale](https://arxiv.org/abs/2408.12570v1)\n15. [Jamba: A Hybrid Transformer-Mamba Language Model](https://arxiv.org/abs/2403.19887)\n16. [Textbooks Are All You Need](https://arxiv.org/abs/2306.11644)\n17. [Unleashing the Power of Data Tsunami: A Comprehensive Survey on Data Assessment and Selection for Instruction Tuning of Language Models](https://arxiv.org/abs/2408.02085) `data`\n18. [OLMoE: Open Mixture-of-Experts Language Models](https://arxiv.org/abs/2409.02060)\n19. [Model Merging Paper](https://huggingface.co/collections/osanseviero/model-merging-65097893623330a3a51ead66)\n20. [Baichuan-Omni Technical Report](https://arxiv.org/abs/2410.08565)\n21. [1.5-Pints Technical Report: Pretraining in Days, Not Months – Your Language Model Thrives on Quality Data](https://arxiv.org/abs/2408.03506)\n22. [Baichuan Alignment Technical Report](https://arxiv.org/abs/2410.14940v1)\n23. [Hunyuan-Large: An Open-Source MoE Model with 52 Billion Activated Parameters by Tencent](https://arxiv.org/abs/2411.02265)\n24. [Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Multimodal Models](https://arxiv.org/abs/2409.17146)\n25. [TÜLU 3: Pushing Frontiers in Open Language Model Post-Training](https://arxiv.org/abs/2411.15124)\n26. [Phi-4 Technical Report](https://arxiv.org/abs/2412.08905)\n27. [Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling](https://arxiv.org/abs/2412.05271)\n28. [Qwen2.5 Technical Report](https://arxiv.org/abs/2412.15115)\n29. [YuLan-Mini: An Open Data-efficient Language Model](https://arxiv.org/abs/2412.17743)\n30. [An Introduction to Vision-Language Modeling](https://arxiv.org/abs/2405.17247)\n31. [DeepSeek V3 Technical Report](https://github.com/WangRongsheng/awesome-LLM-resourses/blob/main/docs/DeepSeek_V3.pdf)\n32. [2 OLMo 2 Furious](https://arxiv.org/abs/2501.00656)\n33. [Yi-Lightning Technical Report](https://arxiv.org/abs/2412.01253)\n34. [DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning](https://github.com/deepseek-ai/DeepSeek-R1)\n35. [KIMI K1.5](https://github.com/WangRongsheng/awesome-LLM-resourses/blob/main/docs/Kimi_k1.5.pdf)\n36. [Eagle 2: Building Post-Training Data Strategies from Scratch for Frontier Vision-Language Models](https://arxiv.org/abs/2501.14818)\n37. [Qwen2.5-VL Technical Report](https://arxiv.org/abs/2502.13923)\n38. [Baichuan-M1: Pushing the Medical Capability of Large Language Models](https://arxiv.org/abs/2502.12671)\n\n<div align=\"right\">\n    <b><a href=\"#Contents\">↥ back to top</a></b>\n</div>\n\n## 社区 Community\n\n1. [魔乐社区](https://modelers.cn/)\n2. [HuggingFace](https://huggingface.co/)\n3. [ModelScope](https://modelscope.cn/)\n4. [WiseModel](https://www.wisemodel.cn/)\n\n<div align=\"right\">\n    <b><a href=\"#Contents\">↥ back to top</a></b>\n</div>\n\n## Open o1\n\n> [!NOTE]\n> \n> 开放的技术是我们永恒的追求\n\n1. https://github.com/atfortes/Awesome-LLM-Reasoning\n2. https://github.com/hijkzzz/Awesome-LLM-Strawberry\n3. https://github.com/wjn1996/Awesome-LLM-Reasoning-Openai-o1-Survey\n4. https://github.com/srush/awesome-o1\n5. https://github.com/open-thought/system-2-research\n6. https://github.com/ninehills/blog/issues/121\n7. https://github.com/OpenSource-O1/Open-O1\n8. https://github.com/GAIR-NLP/O1-Journey\n9. https://github.com/marlaman/show-me\n10. https://github.com/bklieger-groq/g1\n11. https://github.com/Jaimboh/Llamaberry-Chain-of-Thought-Reasoning-in-AI\n12. https://github.com/pseudotensor/open-strawberry\n13. https://huggingface.co/collections/peakji/steiner-preview-6712c6987110ce932a44e9a6\n14. https://github.com/SimpleBerry/LLaMA-O1\n15. https://huggingface.co/collections/Skywork/skywork-o1-open-67453df58e12f6c3934738d0\n16. https://huggingface.co/collections/Qwen/qwq-674762b79b75eac01735070a\n17. https://github.com/SkyworkAI/skywork-o1-prm-inference\n18. https://github.com/RifleZhang/LLaVA-Reasoner-DPO\n19. https://github.com/ADaM-BJTU\n20. https://github.com/ADaM-BJTU/OpenRFT\n21. https://github.com/RUCAIBox/Slow_Thinking_with_LLMs\n22. https://github.com/richards199999/Thinking-Claude\n23. https://huggingface.co/AGI-0/Art-v0-3B\n24. https://huggingface.co/deepseek-ai/DeepSeek-R1\n25. https://huggingface.co/deepseek-ai/DeepSeek-R1-Zero\n26. https://github.com/huggingface/open-r1\n27. https://github.com/hkust-nlp/simpleRL-reason\n28. https://github.com/Jiayi-Pan/TinyZero\n29. https://github.com/baichuan-inc/Baichuan-M1-14B\n30. https://github.com/EvolvingLMMs-Lab/open-r1-multimodal\n31. https://github.com/open-thoughts/open-thoughts\n32. Mini-R1: https://www.philschmid.de/mini-deepseek-r1\n33. LLaMA-Berry: https://arxiv.org/abs/2410.02884\n34. MCTS-DPO: https://arxiv.org/abs/2405.00451\n35. OpenR: https://github.com/openreasoner/openr\n36. https://arxiv.org/abs/2410.02725\n37. LLaVA-o1: https://arxiv.org/abs/2411.10440\n38. Marco-o1: https://arxiv.org/abs/2411.14405\n39. OpenAI o1 report: https://openai.com/index/deliberative-alignment\n40. DRT-o1: https://github.com/krystalan/DRT-o1\n41. Virgo：https://arxiv.org/abs/2501.01904\n42. HuatuoGPT-o1：https://arxiv.org/abs/2412.18925\n43. o1 roadmap：https://arxiv.org/abs/2412.14135\n44. Mulberry：https://arxiv.org/abs/2412.18319\n45. https://arxiv.org/abs/2412.09413\n46. https://arxiv.org/abs/2501.02497\n47. Search-o1:https://arxiv.org/abs/2501.05366v1\n48. https://arxiv.org/abs/2501.18585\n49. https://github.com/simplescaling/s1\n50. https://github.com/Deep-Agent/R1-V\n51. https://github.com/StarRing2022/R1-Nature\n52. https://github.com/Unakar/Logic-RL\n53. https://github.com/datawhalechina/unlock-deepseek\n54. https://github.com/GAIR-NLP/LIMO\n55. https://github.com/Zeyi-Lin/easy-r1\n56. https://github.com/jackfsuia/nanoRLHF/tree/main/examples/r1-v0\n57. https://github.com/FanqingM/R1-Multimodal-Journey\n58. https://github.com/dhcode-cpp/X-R1\n59. https://github.com/agentica-project/deepscaler\n60. https://github.com/ZihanWang314/RAGEN\n61. https://github.com/sail-sg/oat-zero\n62. https://github.com/TideDra/lmm-r1\n63. https://github.com/FlagAI-Open/OpenSeek\n64. https://github.com/SwanHubX/ascend_r1_turtorial\n65. https://github.com/om-ai-lab/VLM-R1\n66. https://github.com/wizardlancet/diagnosis_zero\n67. https://github.com/lsdefine/simple_GRPO\n68. https://github.com/brendanhogan/DeepSeekRL-Extended\n69. https://github.com/Wang-Xiaodong1899/Open-R1-Video\n70. https://github.com/lsdefine/simple_GRPO\n71. https://github.com/Open-Reasoner-Zero/Open-Reasoner-Zero\n72. https://github.com/lucasjinreal/Namo-R1\n73. https://github.com/hiyouga/EasyR1\n74. https://github.com/Fancy-MLLM/R1-Onevision\n75. https://github.com/tulerfeng/Video-R1\n76. https://huggingface.co/qihoo360/TinyR1-32B-Preview\n77. https://github.com/facebookresearch/swe-rl\n78. https://github.com/turningpoint-ai/VisualThinker-R1-Zero\n79. https://github.com/yuyq96/R1-Vision\n80. https://github.com/sungatetop/deepseek-r1-vision\n81. https://huggingface.co/qihoo360/Light-R1-32B\n82. https://github.com/Liuziyu77/Visual-RFT\n83. https://github.com/Mohammadjafari80/GSM8K-RLVR\n84. https://github.com/ModalMinds/MM-EUREKA\n85. https://github.com/joey00072/nanoGRPO\n86. https://github.com/PeterGriffinJin/Search-R1\n87. https://openi.pcl.ac.cn/PCL-Reasoner/GRPO-Training-Suite\n88. https://github.com/dvlab-research/Seg-Zero\n\n<div align=\"right\">\n    <b><a href=\"#Contents\">↥ back to top</a></b>\n</div>\n\n## Small Language Model\n\n1. https://github.com/jiahe7ay/MINI_LLM\n2. https://github.com/jingyaogong/minimind\n3. https://github.com/DLLXW/baby-llama2-chinese\n4. https://github.com/charent/ChatLM-mini-Chinese\n5. https://github.com/wdndev/tiny-llm-zh\n6. https://github.com/Tongjilibo/build_MiniLLM_from_scratch\n7. https://github.com/jzhang38/TinyLlama\n8. https://github.com/AI-Study-Han/Zero-Chatgpt\n9. https://github.com/loubnabnl/nanotron-smol-cluster ([使用Cosmopedia训练cosmo-1b](https://huggingface.co/blog/zh/cosmopedia))\n10. https://github.com/charent/Phi2-mini-Chinese\n11. https://github.com/allenai/OLMo\n12. https://github.com/keeeeenw/MicroLlama\n13. https://github.com/Chinese-Tiny-LLM/Chinese-Tiny-LLM\n14. https://github.com/leeguandong/MiniLLaMA3\n15. https://github.com/Pints-AI/1.5-Pints\n16. https://github.com/zhanshijinwat/Steel-LLM\n17. https://github.com/RUC-GSAI/YuLan-Mini\n18. https://github.com/Om-Alve/smolGPT\n\n<div align=\"right\">\n    <b><a href=\"#Contents\">↥ back to top</a></b>\n</div>\n\n## Small Vision Language Model\n\n1. https://github.com/jingyaogong/minimind-v\n2. https://github.com/yuanzhoulvpi2017/zero_nlp/tree/main/train_llava\n3. https://github.com/AI-Study-Han/Zero-Qwen-VL\n4. https://github.com/Coobiw/MPP-LLaVA\n5. https://github.com/qnguyen3/nanoLLaVA\n6. https://github.com/TinyLLaVA/TinyLLaVA_Factory\n7. https://github.com/ZhangXJ199/TinyLLaVA-Video\n8. https://github.com/Emericen/tiny-qwen\n9. https://github.com/merveenoyan/smol-vision\n\n<div align=\"right\">\n    <b><a href=\"#Contents\">↥ back to top</a></b>\n</div>\n\n## Tips\n\n1. [What We Learned from a Year of Building with LLMs (Part I)](https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-i/)\n2. [What We Learned from a Year of Building with LLMs (Part II)](https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-ii/)\n3. [What We Learned from a Year of Building with LLMs (Part III): Strategy](https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-iii-strategy/)\n4. [轻松入门大语言模型（LLM）](https://www.bilibili.com/video/BV1pF4m1V7FB/?spm_id_from=333.999.0.0&vd_source=c739db1ebdd361d47af5a0b8497417db)\n5. [LLMs for Text Classification: A Guide to Supervised Learning](https://www.striveworks.com/blog/llms-for-text-classification-a-guide-to-supervised-learning)\n6. [Unsupervised Text Classification: Categorize Natural Language With LLMs](https://www.striveworks.com/blog/unsupervised-text-classification-how-to-use-llms-to-categorize-natural-language-data)\n7. [Text Classification With LLMs: A Roundup of the Best Methods](https://www.striveworks.com/blog/text-classification-with-llms-a-roundup-of-the-best-methods)\n8. [LLM Pricing](https://docs.google.com/spreadsheets/d/18GHPEBJzDbICmMStPVkNWA_hQHiWmLcqUdEJA1b4MJM/edit?gid=0#gid=0)\n9. [Uncensor any LLM with abliteration](https://huggingface.co/blog/mlabonne/abliteration)\n10. [Tiny LLM Universe](https://github.com/datawhalechina/tiny-universe)\n11. [Zero-Chatgpt](https://github.com/AI-Study-Han/Zero-Chatgpt)\n12. [Zero-Qwen-VL](https://github.com/AI-Study-Han/Zero-Qwen-VL)\n13. [finetune-Qwen2-VL](https://github.com/zhangfaen/finetune-Qwen2-VL)\n14. [MPP-LLaVA](https://github.com/Coobiw/MPP-LLaVA)\n15. [build_MiniLLM_from_scratch](https://github.com/Tongjilibo/build_MiniLLM_from_scratch)\n16. [Tiny LLM zh](https://github.com/wdndev/tiny-llm-zh)\n17. [MiniMind](https://github.com/jingyaogong/minimind): 3小时完全从0训练一个仅有26M的小参数GPT，最低仅需2G显卡即可推理训练.\n18. [LLM-Travel](https://github.com/Glanvery/LLM-Travel): 致力于深入理解、探讨以及实现与大模型相关的各种技术、原理和应用\n19. [Knowledge distillation: Teaching LLM's with synthetic data](https://wandb.ai/byyoung3/ML_NEWS3/reports/Knowledge-distillation-Teaching-LLM-s-with-synthetic-data--Vmlldzo5MTMyMzA2)\n20. [Part 1: Methods for adapting large language models](https://ai.meta.com/blog/adapting-large-language-models-llms/)\n21. [Part 2: To fine-tune or not to fine-tune](https://ai.meta.com/blog/when-to-fine-tune-llms-vs-other-techniques/)\n22. [Part 3: How to fine-tune: Focus on effective datasets](https://ai.meta.com/blog/how-to-fine-tune-llms-peft-dataset-curation/)\n23. [Reader-LM: Small Language Models for Cleaning and Converting HTML to Markdown](https://jina.ai/news/reader-lm-small-language-models-for-cleaning-and-converting-html-to-markdown/?nocache=1)\n24. [LLMs应用构建一年之心得](https://iangyan.github.io/2024/09/08/building-with-llms-part-1/)\n25. [LLM训练-pretrain](https://zhuanlan.zhihu.com/p/718354385)\n26. [pytorch-llama](https://github.com/hkproj/pytorch-llama): LLaMA 2 implemented from scratch in PyTorch.\n27. [Preference Optimization for Vision Language Models with TRL](https://huggingface.co/blog/dpo_vlm) 【[support model](https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModelForVision2Seq)】\n28. [Fine-tuning visual language models using SFTTrainer](https://huggingface.co/blog/vlms) 【[docs](https://huggingface.co/docs/trl/sft_trainer#extending-sfttrainer-for-vision-language-models)】\n29. [A Visual Guide to Mixture of Experts (MoE)](https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-mixture-of-experts)\n30. [Role-Playing in Large Language Models like ChatGPT](https://promptengineering.org/role-playing-in-large-language-models-like-chatgpt/)\n31. [Distributed Training Guide](https://github.com/LambdaLabsML/distributed-training-guide): Best practices & guides on how to write distributed pytorch training code.\n32. [Chat Templates](https://hf-mirror.com/blog/chat-templates)\n33. [Top 20+ RAG Interview Questions](https://www.analyticsvidhya.com/blog/2024/04/rag-interview-questions/)\n34. [LLM-Dojo 开源大模型学习场所，使用简洁且易阅读的代码构建模型训练框架](https://github.com/mst272/LLM-Dojo)\n35. [o1 isn’t a chat model (and that’s the point)](https://www.latent.space/p/o1-skill-issue)\n36. [Beam Search快速理解及代码解析](https://www.cnblogs.com/nickchen121/p/15499576.html)\n37. [基于 transformers 的 generate() 方法实现多样化文本生成：参数含义和算法原理解读](https://blog.csdn.net/muyao987/article/details/125917234)\n38. [The Ultra-Scale Playbook: Training LLMs on GPU Clusters](https://huggingface.co/spaces/nanotron/ultrascale-playbook)\n\n<div align=\"right\">\n    <b><a href=\"#Contents\">↥ back to top</a></b>\n</div>\n\n![](https://camo.githubusercontent.com/2722992d519a722218f896d5f5231d49f337aaff4514e78bd59ac935334e916a/68747470733a2f2f692e696d6775722e636f6d2f77617856496d762e706e67)\n\n如果你觉得本项目对你有帮助，欢迎引用：\n```bib\n@misc{wang2024llm,\n      title={awesome-LLM-resourses}, \n      author={Rongsheng Wang},\n      year={2024},\n      publisher = {GitHub},\n      journal = {GitHub repository},\n      howpublished = {\\url{https://github.com/WangRongsheng/awesome-LLM-resourses}},\n}\n```\n\n<!--\n[![Forkers repo roster for @WangRongsheng/awesome-LLM-resourses](https://reporoster.com/forks/WangRongsheng/awesome-LLM-resourses)](https://github.com/WangRongsheng/awesome-LLM-resourses/network/members)\n\n[![Stargazers repo roster for @WangRongsheng/awesome-LLM-resourses](https://reporoster.com/stars/WangRongsheng/awesome-LLM-resourses)](https://github.com/WangRongsheng/awesome-LLM-resourses/stargazers)\n-->\n\n[![Stargazers over time](https://starchart.cc/WangRongsheng/awesome-LLM-resourses.svg)](https://starchart.cc/WangRongsheng/awesome-LLM-resourses)\n\n",
    "created_at": "2025-03-11T06:31:44Z",
    "updated_at": "2025-03-14T05:28:32Z",
    "labels": [],
    "url": "https://github.com/kaozb/ai-arctl/issues/11"
  },
  {
    "id": 19,
    "title": "收藏的AI 开源资料",
    "content": "[通过思考模型(Thinking Model)和输出模型(Output Model)的协同工作，提供更深入、更全面的AI响应](https://github.com/lioensky/Mixlite)\n\n\n这 MCP 拆开来看，包含三个关键部分：\n**Model（模型）**：像现在超火的 GPT、Claude 这些 AI 模型都在这个范畴里。它们就像是聪明的大脑，能处理各种信息，给我们生\n成五花八门的内容。\n\n**Context（上下文）**：简单理解，就是给模型提供额外资料，帮助模型更精准地理解任务。打个比方，你想让模型写一篇关于某个特定活动的报道，那把活动的详细信息，比如时间、地点、流程等作为上下文提供给它，写出来的内容肯定更靠谱。\n\n**Protocol（协议）**：这是一种通用标准或规范，有了它，各种操作和交互才能有序进行。\n\n\n\n",
    "created_at": "2025-03-13T15:54:52Z",
    "updated_at": "2025-03-14T05:27:36Z",
    "labels": [
      "集合"
    ],
    "url": "https://github.com/kaozb/ai-arctl/issues/19"
  },
  {
    "id": 20,
    "title": "有关智能体/Agent，和上下文协议/MCP的一些概念，以及为什么它重要 | 人人都是产品经理",
    "content": "有关智能体/Agent，和上下文协议/MCP的一些概念，以及为什么它重要 | 人人都是产品经理\n\n\n《AI 学会使用工具了》\n\n2023年2月14日，报道自赛博禅心\n\n由于语言泛化，今天出现了很有趣的现象：「Agent 是什么」，这个问题没有了标准的定义。\n\n一个常见的观点是：Agent 是一种让 AI 以类似人的工作和思考方式，来完成一系列的任务。一个 Agent 可以是一个 Bot，也可以是多个 Bot 的协同。就像是职场里，简单的工作独立完成，复杂的工作协作完成一样。\n\n对于每个 Bot 来说，可能会包括：\n\n*   一个大脑：判断和规划行为，这里通常需要 GPT-4或更高水平的 LLM；\n*   眼睛和手：确认信息和使用外部工具，一般是各种插件/action/api；\n*   工作纪要：储存已经发生的事，通常的媒介是上下文窗口，或者一个 todo 文件，也或者数据库；\n*   行为SOP：明确这个 Agent 的身份、任务、目标和机制。这个 SOP 可能是用户给的，也可能是由其它 Bot 给出的。\n\n再具象一点，这里我从 GPTs 里截了个图：\n\n![Image 19](https://image.woshipm.com/2025/03/10/9641a046-fd93-11ef-bc4f-00163e09d72f.png)\n\nGPTs，通常被认为是由 OpenAI 设计的最简版的 Agent。默认情况下，只能进行单 Bot 交互：\n\n*   一个大脑：在 ChatGPT GPT Store 里，GPT-4 是唯一可选的 LLM；\n*   眼睛和手：可以在 Capabilities 里勾选由 OpenAI 提供的第一方能力，也可以通过Actions 来拓展更多的外部能力；\n*   工作纪要：一般来说就是对话记录，GPTs 可以回顾之前的对话，；\n*   行为SOP：存放在 Description, Instructions 以及 Knowledge 里。\n*   在这里，大脑链接眼睛和手，需要一种神经信号，代码里叫做协议。\n\n最早的协议是 OpenAI Plugin 协议，发布于 2 年前的差不多这个时候，定向邀请。\n\n之后 Anthropic 在去年发布了 MCP 协议，是公开版的\n\n![Image 20](https://image.woshipm.com/2025/03/10/96f8d86a-fd93-11ef-bc4f-00163e09d72f.png)\n\n当时我也做了个短评：\n\n> 类比来说，可理解为 Claude 桌面版的插件系统（类比 OAI 去年3月的发布），不同点在于：  \n> – Claude 的插件，暂还不能共享  \n> – 只能在「Claude 桌面版」（网页版不行）、「Zed」、「Cody」里面使用  \n> – 没有更新到接口（仍然没有正式的 Function Calling / JSON Mode / Sturctured Output）  \n> – 早期版本，很多东西还是饼，比如 Sampling  \n> 从进步角度，一定程度上解决了 Claude 不能输出结构化信息的问题：之前 Claude 想要结构化输出，只能 prompt + prefill + regex  \n> 公众号：赛博禅心  \n> 短评Claude 发布的 MCP 协议\n\n而下面，就让我们一起来看看这个 MCP 协议。\n\nNorah Sakal 写了一篇不错的介绍，宝玉进行了翻译\n\n![Image 21](https://image.woshipm.com/2025/03/10/9796bd82-fd93-11ef-bc4f-00163e09d72f.png)\n\n什么是模型上下文协议（MCP）？它如何比传统API更简单地集成AI？\n\nhttps://norahsakal.com/blog/mcp-vs-api-model-context-protocol-explained/\n\n模型上下文协议（Model Context Protocol，简称MCP） 是一种全新的开放协议，专门用于标准化地为大语言模型（LLMs）提供应用场景和数据背景。\n\n你可以把MCP想象成AI领域的“USB-C接口”，它能让不同的AI模型与外部工具和数据源轻松连接。\n\n本文将清晰地解释MCP的价值、工作原理，以及它与传统API的关键区别。\n\n什么是MCP？\n-------\n\n模型上下文协议（MCP） 就像是为AI模型量身定制的“USB-C接口”，可以标准化地连接AI系统与各类外部工具和数据源。\n\n![Image 22](https://image.woshipm.com/2025/03/10/984001e4-fd93-11ef-bc4f-00163e09d72f.png)\n\n什么是MCP？\n\n就像USB-C接口让你的电脑更容易连接各种设备一样，MCP让AI模型更简单地获取数据、工具与服务。\n\n为什么要用MCP，而不是传统的API？\n-------------------\n\n通常，AI系统想连接外部工具时，需要单独整合多个不同的API。每个API都有独立的代码、文档、认证方式、错误处理和后续维护，极大地增加了开发复杂度。\n\n### 为什么说传统API就像每扇门都有一把不同的钥匙？\n\n打个比方： API就像不同的门，每扇门都需要自己的钥匙和特定的规则。\n\n![Image 23](https://image.woshipm.com/2025/03/10/99016460-fd93-11ef-bc4f-00163e09d72f.png)\n\n为什么使用MCP而非传统API？\n\n传统的API要求开发者为每个服务或数据源单独编写代码和整合方案。\n\nMCP背后是谁？\n--------\n\nMCP最早由Anthropic ↗\\[1\\]公司开发，目的是帮助AI模型（如Claude）更容易地连接工具和数据源。\n\n但现在，MCP已经成为一个开放协议，越来越多的企业和开发者开始采用它，这也让它逐渐成为AI与工具互动的新标准。\n\n📌 想深入了解？可以访问官方的MCP规格文档 ↗\\[2\\]。\n\nMCP与API快速对比\n-----------\n\n![Image 24](https://image.woshipm.com/2025/03/12/edefd8d4-fef2-11ef-b61d-00163e09d72f.png)\n\nMCP与传统API关键区别：\n\n• 单一协议： MCP像一个统一接口，只要一次整合，就能连接多个服务。\n\n• 动态发现： AI模型能自动识别并使用可用的工具，不用提前写死每个接口。\n\n• 双向通信： MCP支持类似WebSockets的实时双向通信，模型不仅能查询数据，还能主动触发操作。\n\n为什么要有双向通信？\n\nMCP提供实时互动，模型能：\n\n• 拉取数据： 模型实时查询数据，如查看你的日历。\n\n• 触发操作： 模型主动向服务器发出指令，如重新安排会议或发送邮件。\n\nMCP如何工作：架构原理\n------------\n\nMCP采用简单的客户端-服务器架构：\n\n![Image 25](https://image.woshipm.com/2025/03/10/984001e4-fd93-11ef-bc4f-00163e09d72f.png)\n\nMCP的工作架构\n\n• MCP主机（Host）： 如Claude桌面应用或智能开发环境（IDE），需要访问外部数据或工具。\n\n• MCP客户端（Client）： 与MCP服务器建立一对一的稳定连接。\n\n• MCP服务器（Server）： 提供特定功能，连接本地或远程的数据源。\n\n• 本地数据源： 文件、数据库或服务。\n\n• 远程服务： 外部API或互联网服务。\n\n简单说，MCP像一座桥梁： 它本身不处理复杂逻辑，只负责协调AI模型与工具之间的信息流动。\n\n### 实际中的MCP客户端案例\n\n比如，一个Python脚本（client.py）作为MCP客户端，可以轻松连接MCP服务器，以控制Gmail、Slack或日历应用，无需每个工具单独编写代码。\n\nMCP应用案例：什么时候用它？\n---------------\n\n设想下面几个场景：\n\n**1\\. 旅行规划助手**\n\n• 使用 API 时： 分别为谷歌日历、邮件、机票预订写代码，繁琐而复杂。\n\n• 使用 MCP 时： AI助手直接通过MCP统一协议，查看日历、订机票、发邮件确认，无须单独整合每个工具。\n\n**2\\. 智能IDE（代码编辑器）**\n\n• 使用 API 时： 手动连接文件系统、版本管理、包管理和文档，耗时费力。\n\n• 使用 MCP 时： IDE 通过 MCP 一次连接所有功能，带来更丰富的上下文支持，更强大的智能建议。\n\n**3\\. 复杂的数据分析**\n\n• 使用 API 时： 人工管理与每个数据库、数据可视化工具的连接。\n\n• 使用 MCP 时： AI自动发现并连接多个数据库和可视化工具，通过统一的MCP接口轻松完成分析任务。\n\nMCP 的好处\n-------\n\n• 简化开发： 一次整合，多次复用，不再重复开发。\n\n• 灵活性强： 轻松切换AI模型或工具，无需复杂的重新配置。\n\n• 实时互动： 长连接保证数据实时更新。\n\n• 安全可靠： 内置标准化安全和权限控制。\n\n• 扩展性强： AI系统扩展时，只需连接新的MCP服务器。\n\n什么时候传统 API 更适合？\n---------------\n\n如果你的应用场景需要精准且严格受控的交互方式，那么传统API可能更合适。MCP提供广泛而灵活的动态能力，更适合需要上下文理解的场景，但不一定适用于严格受控的场合。\n\n传统API更合适的场景：\n\n• 需要细粒度控制、功能严格限制；\n\n• 更偏好紧耦合以提升性能；\n\n• 希望最大化交互的可预测性。\n\n如何开始使用MCP？\n----------\n\n快速集成MCP的步骤：\n\n1\\. 定义能力： 明确你的MCP服务器提供哪些功能。\n\n2\\. 实现MCP层： 按照协议标准进行开发。\n\n3\\. 选择通信方式： 本地连接（标准输入输出）或远程连接（如WebSockets）。\n\n4\\. 创建资源/工具： 开发或连接你的数据源和服务。\n\n5\\. 建立客户端连接： 与MCP服务器建立安全稳定的连接。\n\n总结\n--\n\n再次回顾什么是MCP：\n\n• MCP： 为AI模型统一连接数据与工具的标准接口。\n\n• API： 传统的方式，每个服务单独连接，开发更复杂。\n\n![Image 26](https://image.woshipm.com/2025/03/10/984001e4-fd93-11ef-bc4f-00163e09d72f.png)\n\n什么是MCP？\n\nMCP让AI与外部数据、工具的连接变得更加标准化和高效。\n\n结论\n--\n\nMCP不仅仅是另一种API，而是一个强大的连接框架，让AI应用能更智能、更动态地融入丰富的上下文环境，快速实现复杂的功能互动。\n\n",
    "created_at": "2025-03-14T03:24:10Z",
    "updated_at": "2025-03-14T05:27:00Z",
    "labels": [],
    "url": "https://github.com/kaozb/ai-arctl/issues/20"
  }
]